nohup: ignoring input
03/21/2023 10:35:53 - INFO - __main__ -   label_list: ['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'X', '[START]', '[END]'], length: 12
The number of samples: 4000
The number of images: 4000
The number of samples: 1000
The number of images: 1000
The number of samples: 3257
The number of images: 3257
03/21/2023 10:35:53 - INFO - root -   Constructing vocabulary for image caption
03/21/2023 10:35:54 - INFO - __main__ -    The size of vocabulary = 4736
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
03/21/2023 10:36:14 - INFO - __main__ -   Args: Namespace(adam_epsilon=1e-08, alpha=0.0001, bert_type='uncased', beta=0.0001, cls_init=0, crf_dropout=0.5, crf_learning_rate=0.0001, crop_size=224, cross_dropout=0.2, data_dir='/home/ubuntu/multimodal-fusion/baselines/UMT/data/twitter2015', device=device(type='cuda'), do_eval=True, do_predict=False, do_train=True, drop_last=True, eval_all_checkpoints=False, evaluate_during_training=True, gradient_accumulation_steps=1, hidden_size=768, id2label={0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC', 9: 'X', 10: '[START]', 11: '[END]'}, image_dir='/home/ubuntu/multimodal-fusion/datasets/IJCAI2019_data/twitter2015_images', image_dropout=0.0, label2id={'O': 0, 'B-MISC': 1, 'I-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-LOC': 7, 'I-LOC': 8, 'X': 9, '[START]': 10, '[END]': 11}, learning_rate=0.0001, load_image_checkpoint=False, load_text_checkpoint=False, local_rank=-1, logging_steps=100, markup='bio', max_grad_norm=1.0, max_seq_length=64, n_gpu=1, num_layers=6, num_train_epochs=10, num_workers=8, output_dir='../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/', per_gpu_eval_batch_size=40, per_gpu_train_batch_size=40, predict_checkpoints=0, replace_end=3, replace_start=1, resnet_pretrained_dir='../models/resnet152-b121ed2d.pth', save_steps=100, seed=42, sigma=1.0, skip_connection=True, task='twitter15', test_batch_size=1, text_dropout=0.0, theta=0.1, ti_crop_size=32, train_batch_size=40, use_quantile=True, use_xlmr=False, warmup_proportion=0.1, weight_decay=0.01)
03/21/2023 10:36:14 - INFO - __main__ -   Summary dir: ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/summary_1679366174
/home/ubuntu/.conda/envs/muse/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
03/21/2023 10:36:14 - INFO - __main__ -   ***** Running training *****
03/21/2023 10:36:14 - INFO - __main__ -     Num examples = 4000
03/21/2023 10:36:14 - INFO - __main__ -     Num Epochs = 10
03/21/2023 10:36:14 - INFO - __main__ -     Gradient Accumulation steps = 1
03/21/2023 10:36:14 - INFO - __main__ -     Total optimization steps = 1000

Epoch: 0/10
/home/ubuntu/multimodal-fusion/MuSE/code/models.py:1235: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:333.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
/home/ubuntu/.conda/envs/muse/lib/python3.7/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
[Training] 1/100 [..............................] - ETA: 6:43  [ loss=1.8292 ][Training] 2/100 [..............................] - ETA: 5:33  [ loss=1.7752 ][Training] 3/100 [..............................] - ETA: 4:43  [ loss=1.7758 ][Training] 4/100 [>.............................] - ETA: 4:18  [ loss=1.7922 ][Training] 5/100 [>.............................] - ETA: 4:00  [ loss=1.6113 ][Training] 6/100 [>.............................] - ETA: 3:47  [ loss=1.5062 ][Training] 7/100 [=>............................] - ETA: 3:37  [ loss=1.3924 ][Training] 8/100 [=>............................] - ETA: 3:30  [ loss=1.1156 ][Training] 9/100 [=>............................] - ETA: 3:23  [ loss=1.0457 ][Training] 10/100 [==>...........................] - ETA: 3:18  [ loss=0.9607 ][Training] 11/100 [==>...........................] - ETA: 3:14  [ loss=0.8800 ][Training] 12/100 [==>...........................] - ETA: 3:09  [ loss=0.8139 ][Training] 13/100 [==>...........................] - ETA: 3:05  [ loss=0.7513 ][Training] 14/100 [===>..........................] - ETA: 3:01  [ loss=0.6784 ][Training] 15/100 [===>..........................] - ETA: 2:58  [ loss=0.6822 ][Training] 16/100 [===>..........................] - ETA: 2:54  [ loss=0.6721 ][Training] 17/100 [====>.........................] - ETA: 2:51  [ loss=0.6899 ][Training] 18/100 [====>.........................] - ETA: 2:48  [ loss=0.6810 ][Training] 19/100 [====>.........................] - ETA: 2:45  [ loss=0.6694 ][Training] 20/100 [=====>........................] - ETA: 2:43  [ loss=0.6278 ][Training] 21/100 [=====>........................] - ETA: 2:42  [ loss=0.6117 ][Training] 22/100 [=====>........................] - ETA: 2:39  [ loss=0.6076 ][Training] 23/100 [=====>........................] - ETA: 2:37  [ loss=0.5643 ][Training] 24/100 [======>.......................] - ETA: 2:34  [ loss=0.4950 ][Training] 25/100 [======>.......................] - ETA: 2:31  [ loss=0.4330 ][Training] 26/100 [======>.......................] - ETA: 2:28  [ loss=0.3678 ][Training] 27/100 [=======>......................] - ETA: 2:26  [ loss=0.4095 ][Training] 28/100 [=======>......................] - ETA: 2:23  [ loss=0.3448 ][Training] 29/100 [=======>......................] - ETA: 2:21  [ loss=0.3540 ][Training] 30/100 [========>.....................] - ETA: 2:19  [ loss=0.3521 ][Training] 31/100 [========>.....................] - ETA: 2:16  [ loss=0.2790 ][Training] 32/100 [========>.....................] - ETA: 2:14  [ loss=0.3210 ][Training] 33/100 [========>.....................] - ETA: 2:12  [ loss=0.2486 ][Training] 34/100 [=========>....................] - ETA: 2:10  [ loss=0.2824 ][Training] 35/100 [=========>....................] - ETA: 2:07  [ loss=0.2606 ][Training] 36/100 [=========>....................] - ETA: 2:05  [ loss=0.2527 ][Training] 37/100 [==========>...................] - ETA: 2:03  [ loss=0.2700 ][Training] 38/100 [==========>...................] - ETA: 2:01  [ loss=0.2280 ][Training] 39/100 [==========>...................] - ETA: 1:59  [ loss=0.2591 ][Training] 40/100 [===========>..................] - ETA: 1:57  [ loss=0.2336 ][Training] 41/100 [===========>..................] - ETA: 1:54  [ loss=0.2651 ][Training] 42/100 [===========>..................] - ETA: 1:52  [ loss=0.2155 ][Training] 43/100 [===========>..................] - ETA: 1:50  [ loss=0.2267 ][Training] 44/100 [============>.................] - ETA: 1:48  [ loss=0.2080 ][Training] 45/100 [============>.................] - ETA: 1:46  [ loss=0.1724 ][Training] 46/100 [============>.................] - ETA: 1:44  [ loss=0.1660 ][Training] 47/100 [=============>................] - ETA: 1:42  [ loss=0.1948 ][Training] 48/100 [=============>................] - ETA: 1:40  [ loss=0.2020 ][Training] 49/100 [=============>................] - ETA: 1:38  [ loss=0.1871 ][Training] 50/100 [==============>...............] - ETA: 1:36  [ loss=0.1833 ][Training] 51/100 [==============>...............] - ETA: 1:34  [ loss=0.1763 ][Training] 52/100 [==============>...............] - ETA: 1:32  [ loss=0.1782 ][Training] 53/100 [==============>...............] - ETA: 1:30  [ loss=0.1644 ][Training] 54/100 [===============>..............] - ETA: 1:28  [ loss=0.1762 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.1629 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.1420 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.1517 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.1560 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.1553 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.1518 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.1260 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.1566 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.1415 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.1320 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.1472 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.1145 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.1139 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.1454 ][Training] 69/100 [===================>..........] - ETA: 59s  [ loss=0.1352 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.1288 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.1445 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.1282 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.1528 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.1004 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.1219 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.1006 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.1307 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.1099 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.1763 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.1266 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.1517 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.1111 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.1426 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.1096 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.1040 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0953 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.1120 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.1590 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.1315 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.1214 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.1181 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.1067 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.1228 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0967 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.1170 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.1045 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.1058 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.1013 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.1040 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.1420 ]
 
03/21/2023 10:39:23 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 10:39:23 - INFO - __main__ -     Num examples = 1000
03/21/2023 10:39:23 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 33s  [ loss=0.1154 ][Evaluating] 1/25 [>.............................] - ETA: 33s[Evaluating] 2/25 [=>............................] - ETA: 31s  [ loss=0.1112 ][Evaluating] 2/25 [=>............................] - ETA: 31s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.1056 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 27s  [ loss=0.0931 ][Evaluating] 4/25 [===>..........................] - ETA: 27s[Evaluating] 5/25 [=====>........................] - ETA: 26s  [ loss=0.1449 ][Evaluating] 5/25 [=====>........................] - ETA: 26s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.1063 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 23s  [ loss=0.1447 ][Evaluating] 7/25 [=======>......................] - ETA: 23s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.1016 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.0954 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 19s  [ loss=0.1019 ][Evaluating] 10/25 [===========>..................] - ETA: 19s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.1068 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0884 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 15s  [ loss=0.0972 ][Evaluating] 13/25 [==============>...............] - ETA: 15s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.0933 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1209 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 11s  [ loss=0.1166 ][Evaluating] 16/25 [==================>...........] - ETA: 11s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.0976 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.0962 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 7s  [ loss=0.1317 ][Evaluating] 19/25 [=====================>........] - ETA: 7s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0997 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1206 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 3s  [ loss=0.0819 ][Evaluating] 22/25 [=========================>....] - ETA: 3s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.0922 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.0986 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.1137 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 10:39:56 - INFO - __main__ -   

03/21/2023 10:39:56 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 10:39:56 - INFO - __main__ -    acc: 0.5870 - recall: 0.6567 - f1: 0.6199 - loss: 0.1070 
03/21/2023 10:39:56 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 10:39:56 - INFO - __main__ -   ******* LOC results ********
03/21/2023 10:39:56 - INFO - __main__ -    acc: 0.5513 - recall: 0.8640 - f1: 0.6731 
03/21/2023 10:39:56 - INFO - __main__ -   ******* MISC results ********
03/21/2023 10:39:56 - INFO - __main__ -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
03/21/2023 10:39:56 - INFO - __main__ -   ******* ORG results ********
03/21/2023 10:39:56 - INFO - __main__ -    acc: 0.3663 - recall: 0.2996 - f1: 0.3296 
03/21/2023 10:39:56 - INFO - __main__ -   ******* PER results ********
03/21/2023 10:39:56 - INFO - __main__ -    acc: 0.6918 - recall: 0.8822 - f1: 0.7755 
03/21/2023 10:39:58 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-100
03/21/2023 10:40:01 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-100
03/21/2023 10:40:01 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:40:05 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:40:05 - INFO - __main__ -   Saving best eval loss model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:40:10 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:40:10 - INFO - __main__ -   


Epoch: 1/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:54  [ loss=0.0991 ][Training] 2/100 [..............................] - ETA: 4:59  [ loss=0.1204 ][Training] 3/100 [..............................] - ETA: 4:19  [ loss=0.0979 ][Training] 4/100 [>.............................] - ETA: 3:56  [ loss=0.1110 ][Training] 5/100 [>.............................] - ETA: 3:42  [ loss=0.0926 ][Training] 6/100 [>.............................] - ETA: 3:32  [ loss=0.0972 ][Training] 7/100 [=>............................] - ETA: 3:23  [ loss=0.1063 ][Training] 8/100 [=>............................] - ETA: 3:17  [ loss=0.0909 ][Training] 9/100 [=>............................] - ETA: 3:12  [ loss=0.0946 ][Training] 10/100 [==>...........................] - ETA: 3:07  [ loss=0.0875 ][Training] 11/100 [==>...........................] - ETA: 3:04  [ loss=0.1011 ][Training] 12/100 [==>...........................] - ETA: 3:00  [ loss=0.0706 ][Training] 13/100 [==>...........................] - ETA: 2:57  [ loss=0.0917 ][Training] 14/100 [===>..........................] - ETA: 2:53  [ loss=0.0987 ][Training] 15/100 [===>..........................] - ETA: 2:50  [ loss=0.1142 ][Training] 16/100 [===>..........................] - ETA: 2:47  [ loss=0.0906 ][Training] 17/100 [====>.........................] - ETA: 2:44  [ loss=0.1061 ][Training] 18/100 [====>.........................] - ETA: 2:41  [ loss=0.1080 ][Training] 19/100 [====>.........................] - ETA: 2:38  [ loss=0.0944 ][Training] 20/100 [=====>........................] - ETA: 2:35  [ loss=0.1174 ][Training] 21/100 [=====>........................] - ETA: 2:33  [ loss=0.0958 ][Training] 22/100 [=====>........................] - ETA: 2:30  [ loss=0.0718 ][Training] 23/100 [=====>........................] - ETA: 2:29  [ loss=0.1008 ][Training] 24/100 [======>.......................] - ETA: 2:27  [ loss=0.0993 ][Training] 25/100 [======>.......................] - ETA: 2:24  [ loss=0.0740 ][Training] 26/100 [======>.......................] - ETA: 2:22  [ loss=0.0777 ][Training] 27/100 [=======>......................] - ETA: 2:20  [ loss=0.0840 ][Training] 28/100 [=======>......................] - ETA: 2:18  [ loss=0.1020 ][Training] 29/100 [=======>......................] - ETA: 2:16  [ loss=0.1160 ][Training] 30/100 [========>.....................] - ETA: 2:13  [ loss=0.0820 ][Training] 31/100 [========>.....................] - ETA: 2:11  [ loss=0.1257 ][Training] 32/100 [========>.....................] - ETA: 2:09  [ loss=0.1142 ][Training] 33/100 [========>.....................] - ETA: 2:07  [ loss=0.0898 ][Training] 34/100 [=========>....................] - ETA: 2:05  [ loss=0.0906 ][Training] 35/100 [=========>....................] - ETA: 2:03  [ loss=0.0793 ][Training] 36/100 [=========>....................] - ETA: 2:01  [ loss=0.0768 ][Training] 37/100 [==========>...................] - ETA: 1:59  [ loss=0.1033 ][Training] 38/100 [==========>...................] - ETA: 1:57  [ loss=0.0890 ][Training] 39/100 [==========>...................] - ETA: 1:55  [ loss=0.0919 ][Training] 40/100 [===========>..................] - ETA: 1:53  [ loss=0.0879 ][Training] 41/100 [===========>..................] - ETA: 1:51  [ loss=0.0777 ][Training] 42/100 [===========>..................] - ETA: 1:49  [ loss=0.0858 ][Training] 43/100 [===========>..................] - ETA: 1:47  [ loss=0.0772 ][Training] 44/100 [============>.................] - ETA: 1:45  [ loss=0.0873 ][Training] 45/100 [============>.................] - ETA: 1:43  [ loss=0.0928 ][Training] 46/100 [============>.................] - ETA: 1:41  [ loss=0.0798 ][Training] 47/100 [=============>................] - ETA: 1:39  [ loss=0.1110 ][Training] 48/100 [=============>................] - ETA: 1:37  [ loss=0.0806 ][Training] 49/100 [=============>................] - ETA: 1:35  [ loss=0.1092 ][Training] 50/100 [==============>...............] - ETA: 1:34  [ loss=0.0845 ][Training] 51/100 [==============>...............] - ETA: 1:32  [ loss=0.0966 ][Training] 52/100 [==============>...............] - ETA: 1:30  [ loss=0.0690 ][Training] 53/100 [==============>...............] - ETA: 1:28  [ loss=0.0720 ][Training] 54/100 [===============>..............] - ETA: 1:26  [ loss=0.0714 ][Training] 55/100 [===============>..............] - ETA: 1:24  [ loss=0.1058 ][Training] 56/100 [===============>..............] - ETA: 1:22  [ loss=0.0984 ][Training] 57/100 [================>.............] - ETA: 1:20  [ loss=0.0754 ][Training] 58/100 [================>.............] - ETA: 1:18  [ loss=0.0998 ][Training] 59/100 [================>.............] - ETA: 1:16  [ loss=0.1044 ][Training] 60/100 [=================>............] - ETA: 1:14  [ loss=0.0876 ][Training] 61/100 [=================>............] - ETA: 1:12  [ loss=0.0779 ][Training] 62/100 [=================>............] - ETA: 1:10  [ loss=0.0674 ][Training] 63/100 [=================>............] - ETA: 1:08  [ loss=0.0827 ][Training] 64/100 [==================>...........] - ETA: 1:07  [ loss=0.1071 ][Training] 65/100 [==================>...........] - ETA: 1:05  [ loss=0.0786 ][Training] 66/100 [==================>...........] - ETA: 1:03  [ loss=0.0955 ][Training] 67/100 [===================>..........] - ETA: 1:01  [ loss=0.0921 ][Training] 68/100 [===================>..........] - ETA: 59s  [ loss=0.0700 ][Training] 69/100 [===================>..........] - ETA: 57s  [ loss=0.0835 ][Training] 70/100 [====================>.........] - ETA: 55s  [ loss=0.0854 ][Training] 71/100 [====================>.........] - ETA: 53s  [ loss=0.0768 ][Training] 72/100 [====================>.........] - ETA: 51s  [ loss=0.0910 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.0956 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0711 ][Training] 75/100 [=====================>........] - ETA: 46s  [ loss=0.0765 ][Training] 76/100 [=====================>........] - ETA: 44s  [ loss=0.0744 ][Training] 77/100 [======================>.......] - ETA: 42s  [ loss=0.0924 ][Training] 78/100 [======================>.......] - ETA: 40s  [ loss=0.0944 ][Training] 79/100 [======================>.......] - ETA: 38s  [ loss=0.0734 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0870 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0722 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0804 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.0724 ][Training] 84/100 [========================>.....] - ETA: 29s  [ loss=0.0644 ][Training] 85/100 [========================>.....] - ETA: 27s  [ loss=0.0748 ][Training] 86/100 [========================>.....] - ETA: 25s  [ loss=0.0706 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0726 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0862 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0859 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0904 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0809 ][Training] 92/100 [==========================>...] - ETA: 14s  [ loss=0.0750 ][Training] 93/100 [==========================>...] - ETA: 12s  [ loss=0.0858 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.1003 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0933 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0985 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0853 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0747 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0679 ][Training] 100/100 [==============================] 1.8s/step  [ loss=0.0882 ]
 
03/21/2023 10:43:15 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 10:43:15 - INFO - __main__ -     Num examples = 1000
03/21/2023 10:43:15 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 34s  [ loss=0.0914 ][Evaluating] 1/25 [>.............................] - ETA: 34s[Evaluating] 2/25 [=>............................] - ETA: 30s  [ loss=0.0741 ][Evaluating] 2/25 [=>............................] - ETA: 31s[Evaluating] 3/25 [==>...........................] - ETA: 30s  [ loss=0.0819 ][Evaluating] 3/25 [==>...........................] - ETA: 30s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.0782 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.1008 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.0781 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.1142 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.0763 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.0721 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.0777 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.0800 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0643 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 15s  [ loss=0.0909 ][Evaluating] 13/25 [==============>...............] - ETA: 15s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.0718 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1108 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 11s  [ loss=0.0866 ][Evaluating] 16/25 [==================>...........] - ETA: 11s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.0847 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.0796 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 7s  [ loss=0.0823 ][Evaluating] 19/25 [=====================>........] - ETA: 7s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0713 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.0944 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 3s  [ loss=0.0698 ][Evaluating] 22/25 [=========================>....] - ETA: 3s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.0819 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.0867 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.0899 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 10:43:48 - INFO - __main__ -   

03/21/2023 10:43:48 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 10:43:48 - INFO - __main__ -    acc: 0.7358 - recall: 0.7158 - f1: 0.7257 - loss: 0.0836 
03/21/2023 10:43:48 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 10:43:48 - INFO - __main__ -   ******* LOC results ********
03/21/2023 10:43:48 - INFO - __main__ -    acc: 0.7383 - recall: 0.8487 - f1: 0.7897 
03/21/2023 10:43:48 - INFO - __main__ -   ******* MISC results ********
03/21/2023 10:43:48 - INFO - __main__ -    acc: 0.4715 - recall: 0.2636 - f1: 0.3382 
03/21/2023 10:43:48 - INFO - __main__ -   ******* ORG results ********
03/21/2023 10:43:48 - INFO - __main__ -    acc: 0.6462 - recall: 0.5101 - f1: 0.5701 
03/21/2023 10:43:48 - INFO - __main__ -   ******* PER results ********
03/21/2023 10:43:48 - INFO - __main__ -    acc: 0.8193 - recall: 0.8623 - f1: 0.8402 
03/21/2023 10:43:49 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-200
03/21/2023 10:43:53 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-200
03/21/2023 10:43:53 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:44:12 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:44:12 - INFO - __main__ -   Saving best eval loss model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:44:40 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:44:40 - INFO - __main__ -   


Epoch: 2/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:39  [ loss=0.0829 ][Training] 2/100 [..............................] - ETA: 4:53  [ loss=0.0772 ][Training] 3/100 [..............................] - ETA: 4:16  [ loss=0.0655 ][Training] 4/100 [>.............................] - ETA: 3:57  [ loss=0.0610 ][Training] 5/100 [>.............................] - ETA: 3:43  [ loss=0.0612 ][Training] 6/100 [>.............................] - ETA: 3:33  [ loss=0.0599 ][Training] 7/100 [=>............................] - ETA: 3:26  [ loss=0.0564 ][Training] 8/100 [=>............................] - ETA: 3:19  [ loss=0.0610 ][Training] 9/100 [=>............................] - ETA: 3:14  [ loss=0.0643 ][Training] 10/100 [==>...........................] - ETA: 3:09  [ loss=0.0560 ][Training] 11/100 [==>...........................] - ETA: 3:04  [ loss=0.0469 ][Training] 12/100 [==>...........................] - ETA: 3:00  [ loss=0.0752 ][Training] 13/100 [==>...........................] - ETA: 2:57  [ loss=0.0640 ][Training] 14/100 [===>..........................] - ETA: 2:54  [ loss=0.0467 ][Training] 15/100 [===>..........................] - ETA: 2:51  [ loss=0.0517 ][Training] 16/100 [===>..........................] - ETA: 2:48  [ loss=0.0797 ][Training] 17/100 [====>.........................] - ETA: 2:45  [ loss=0.0532 ][Training] 18/100 [====>.........................] - ETA: 2:43  [ loss=0.0566 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=0.0538 ][Training] 20/100 [=====>........................] - ETA: 2:37  [ loss=0.0542 ][Training] 21/100 [=====>........................] - ETA: 2:35  [ loss=0.0592 ][Training] 22/100 [=====>........................] - ETA: 2:32  [ loss=0.0561 ][Training] 23/100 [=====>........................] - ETA: 2:30  [ loss=0.0511 ][Training] 24/100 [======>.......................] - ETA: 2:27  [ loss=0.0492 ][Training] 25/100 [======>.......................] - ETA: 2:25  [ loss=0.0498 ][Training] 26/100 [======>.......................] - ETA: 2:23  [ loss=0.0638 ][Training] 27/100 [=======>......................] - ETA: 2:21  [ loss=0.0576 ][Training] 28/100 [=======>......................] - ETA: 2:18  [ loss=0.0599 ][Training] 29/100 [=======>......................] - ETA: 2:16  [ loss=0.0490 ][Training] 30/100 [========>.....................] - ETA: 2:15  [ loss=0.0734 ][Training] 31/100 [========>.....................] - ETA: 2:12  [ loss=0.0526 ][Training] 32/100 [========>.....................] - ETA: 2:10  [ loss=0.0751 ][Training] 33/100 [========>.....................] - ETA: 2:08  [ loss=0.0831 ][Training] 34/100 [=========>....................] - ETA: 2:06  [ loss=0.0591 ][Training] 35/100 [=========>....................] - ETA: 2:04  [ loss=0.0605 ][Training] 36/100 [=========>....................] - ETA: 2:02  [ loss=0.0556 ][Training] 37/100 [==========>...................] - ETA: 1:59  [ loss=0.0632 ][Training] 38/100 [==========>...................] - ETA: 1:57  [ loss=0.0663 ][Training] 39/100 [==========>...................] - ETA: 1:55  [ loss=0.0524 ][Training] 40/100 [===========>..................] - ETA: 1:53  [ loss=0.0498 ][Training] 41/100 [===========>..................] - ETA: 1:51  [ loss=0.0554 ][Training] 42/100 [===========>..................] - ETA: 1:49  [ loss=0.0552 ][Training] 43/100 [===========>..................] - ETA: 1:47  [ loss=0.0581 ][Training] 44/100 [============>.................] - ETA: 1:45  [ loss=0.0626 ][Training] 45/100 [============>.................] - ETA: 1:44  [ loss=0.0638 ][Training] 46/100 [============>.................] - ETA: 1:42  [ loss=0.0711 ][Training] 47/100 [=============>................] - ETA: 1:40  [ loss=0.0679 ][Training] 48/100 [=============>................] - ETA: 1:38  [ loss=0.0605 ][Training] 49/100 [=============>................] - ETA: 1:36  [ loss=0.0738 ][Training] 50/100 [==============>...............] - ETA: 1:34  [ loss=0.0570 ][Training] 51/100 [==============>...............] - ETA: 1:32  [ loss=0.0696 ][Training] 52/100 [==============>...............] - ETA: 1:30  [ loss=0.0793 ][Training] 53/100 [==============>...............] - ETA: 1:28  [ loss=0.0569 ][Training] 54/100 [===============>..............] - ETA: 1:26  [ loss=0.0661 ][Training] 55/100 [===============>..............] - ETA: 1:25  [ loss=0.0571 ][Training] 56/100 [===============>..............] - ETA: 1:23  [ loss=0.0675 ][Training] 57/100 [================>.............] - ETA: 1:21  [ loss=0.0626 ][Training] 58/100 [================>.............] - ETA: 1:19  [ loss=0.0531 ][Training] 59/100 [================>.............] - ETA: 1:17  [ loss=0.0619 ][Training] 60/100 [=================>............] - ETA: 1:15  [ loss=0.0640 ][Training] 61/100 [=================>............] - ETA: 1:13  [ loss=0.0533 ][Training] 62/100 [=================>............] - ETA: 1:11  [ loss=0.0819 ][Training] 63/100 [=================>............] - ETA: 1:09  [ loss=0.0406 ][Training] 64/100 [==================>...........] - ETA: 1:07  [ loss=0.0652 ][Training] 65/100 [==================>...........] - ETA: 1:05  [ loss=0.0577 ][Training] 66/100 [==================>...........] - ETA: 1:03  [ loss=0.0619 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.0645 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.0486 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.0672 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.0587 ][Training] 71/100 [====================>.........] - ETA: 54s  [ loss=0.0598 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.0494 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.0582 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0530 ][Training] 75/100 [=====================>........] - ETA: 46s  [ loss=0.0689 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.0588 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.0645 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.0648 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.0653 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0620 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0653 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0630 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.0587 ][Training] 84/100 [========================>.....] - ETA: 29s  [ loss=0.0628 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.0631 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0475 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0608 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0748 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0623 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0618 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0483 ][Training] 92/100 [==========================>...] - ETA: 14s  [ loss=0.0580 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.0502 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0583 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0665 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0487 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0504 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0568 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0749 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0453 ]
 
03/21/2023 10:47:47 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 10:47:47 - INFO - __main__ -     Num examples = 1000
03/21/2023 10:47:47 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 38s  [ loss=0.1001 ][Evaluating] 1/25 [>.............................] - ETA: 38s[Evaluating] 2/25 [=>............................] - ETA: 33s  [ loss=0.0772 ][Evaluating] 2/25 [=>............................] - ETA: 33s[Evaluating] 3/25 [==>...........................] - ETA: 30s  [ loss=0.0876 ][Evaluating] 3/25 [==>...........................] - ETA: 30s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.0738 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.1051 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.0856 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.1110 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.0805 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.0766 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.0816 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.0802 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0743 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.0876 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.0878 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1235 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1072 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.0873 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.0933 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.0851 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0724 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.0987 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.0771 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.0820 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1021 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.0907 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 10:48:21 - INFO - __main__ -   

03/21/2023 10:48:21 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 10:48:21 - INFO - __main__ -    acc: 0.7137 - recall: 0.7411 - f1: 0.7272 - loss: 0.0891 
03/21/2023 10:48:21 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 10:48:21 - INFO - __main__ -   ******* LOC results ********
03/21/2023 10:48:21 - INFO - __main__ -    acc: 0.7927 - recall: 0.8276 - f1: 0.8097 
03/21/2023 10:48:21 - INFO - __main__ -   ******* MISC results ********
03/21/2023 10:48:21 - INFO - __main__ -    acc: 0.3761 - recall: 0.3727 - f1: 0.3744 
03/21/2023 10:48:21 - INFO - __main__ -   ******* ORG results ********
03/21/2023 10:48:21 - INFO - __main__ -    acc: 0.6055 - recall: 0.6275 - f1: 0.6163 
03/21/2023 10:48:21 - INFO - __main__ -   ******* PER results ********
03/21/2023 10:48:21 - INFO - __main__ -    acc: 0.8141 - recall: 0.8569 - f1: 0.8350 
03/21/2023 10:48:22 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-300
03/21/2023 10:48:25 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-300
03/21/2023 10:48:25 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:48:44 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:48:44 - INFO - __main__ -   


Epoch: 3/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:11  [ loss=0.0464 ][Training] 2/100 [..............................] - ETA: 4:34  [ loss=0.0550 ][Training] 3/100 [..............................] - ETA: 4:00  [ loss=0.0405 ][Training] 4/100 [>.............................] - ETA: 3:42  [ loss=0.0478 ][Training] 5/100 [>.............................] - ETA: 3:31  [ loss=0.0386 ][Training] 6/100 [>.............................] - ETA: 3:23  [ loss=0.0495 ][Training] 7/100 [=>............................] - ETA: 3:17  [ loss=0.0409 ][Training] 8/100 [=>............................] - ETA: 3:12  [ loss=0.0506 ][Training] 9/100 [=>............................] - ETA: 3:08  [ loss=0.0449 ][Training] 10/100 [==>...........................] - ETA: 3:05  [ loss=0.0516 ][Training] 11/100 [==>...........................] - ETA: 3:01  [ loss=0.0466 ][Training] 12/100 [==>...........................] - ETA: 2:59  [ loss=0.0495 ][Training] 13/100 [==>...........................] - ETA: 2:56  [ loss=0.0426 ][Training] 14/100 [===>..........................] - ETA: 2:53  [ loss=0.0513 ][Training] 15/100 [===>..........................] - ETA: 2:50  [ loss=0.0439 ][Training] 16/100 [===>..........................] - ETA: 2:48  [ loss=0.0503 ][Training] 17/100 [====>.........................] - ETA: 2:45  [ loss=0.0440 ][Training] 18/100 [====>.........................] - ETA: 2:43  [ loss=0.0454 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=0.0473 ][Training] 20/100 [=====>........................] - ETA: 2:38  [ loss=0.0497 ][Training] 21/100 [=====>........................] - ETA: 2:35  [ loss=0.0469 ][Training] 22/100 [=====>........................] - ETA: 2:33  [ loss=0.0471 ][Training] 23/100 [=====>........................] - ETA: 2:30  [ loss=0.0396 ][Training] 24/100 [======>.......................] - ETA: 2:28  [ loss=0.0436 ][Training] 25/100 [======>.......................] - ETA: 2:26  [ loss=0.0372 ][Training] 26/100 [======>.......................] - ETA: 2:23  [ loss=0.0410 ][Training] 27/100 [=======>......................] - ETA: 2:21  [ loss=0.0388 ][Training] 28/100 [=======>......................] - ETA: 2:19  [ loss=0.0418 ][Training] 29/100 [=======>......................] - ETA: 2:16  [ loss=0.0464 ][Training] 30/100 [========>.....................] - ETA: 2:14  [ loss=0.0430 ][Training] 31/100 [========>.....................] - ETA: 2:12  [ loss=0.0382 ][Training] 32/100 [========>.....................] - ETA: 2:10  [ loss=0.0367 ][Training] 33/100 [========>.....................] - ETA: 2:08  [ loss=0.0421 ][Training] 34/100 [=========>....................] - ETA: 2:06  [ loss=0.0580 ][Training] 35/100 [=========>....................] - ETA: 2:04  [ loss=0.0422 ][Training] 36/100 [=========>....................] - ETA: 2:02  [ loss=0.0444 ][Training] 37/100 [==========>...................] - ETA: 2:00  [ loss=0.0436 ][Training] 38/100 [==========>...................] - ETA: 1:58  [ loss=0.0505 ][Training] 39/100 [==========>...................] - ETA: 1:56  [ loss=0.0455 ][Training] 40/100 [===========>..................] - ETA: 1:54  [ loss=0.0440 ][Training] 41/100 [===========>..................] - ETA: 1:52  [ loss=0.0339 ][Training] 42/100 [===========>..................] - ETA: 1:50  [ loss=0.0541 ][Training] 43/100 [===========>..................] - ETA: 1:48  [ loss=0.0464 ][Training] 44/100 [============>.................] - ETA: 1:46  [ loss=0.0409 ][Training] 45/100 [============>.................] - ETA: 1:44  [ loss=0.0401 ][Training] 46/100 [============>.................] - ETA: 1:42  [ loss=0.0483 ][Training] 47/100 [=============>................] - ETA: 1:40  [ loss=0.0507 ][Training] 48/100 [=============>................] - ETA: 1:38  [ loss=0.0517 ][Training] 49/100 [=============>................] - ETA: 1:36  [ loss=0.0420 ][Training] 50/100 [==============>...............] - ETA: 1:34  [ loss=0.0402 ][Training] 51/100 [==============>...............] - ETA: 1:32  [ loss=0.0433 ][Training] 52/100 [==============>...............] - ETA: 1:30  [ loss=0.0553 ][Training] 53/100 [==============>...............] - ETA: 1:28  [ loss=0.0431 ][Training] 54/100 [===============>..............] - ETA: 1:26  [ loss=0.0410 ][Training] 55/100 [===============>..............] - ETA: 1:25  [ loss=0.0411 ][Training] 56/100 [===============>..............] - ETA: 1:23  [ loss=0.0464 ][Training] 57/100 [================>.............] - ETA: 1:21  [ loss=0.0494 ][Training] 58/100 [================>.............] - ETA: 1:19  [ loss=0.0504 ][Training] 59/100 [================>.............] - ETA: 1:17  [ loss=0.0414 ][Training] 60/100 [=================>............] - ETA: 1:15  [ loss=0.0474 ][Training] 61/100 [=================>............] - ETA: 1:13  [ loss=0.0400 ][Training] 62/100 [=================>............] - ETA: 1:11  [ loss=0.0375 ][Training] 63/100 [=================>............] - ETA: 1:09  [ loss=0.0417 ][Training] 64/100 [==================>...........] - ETA: 1:07  [ loss=0.0462 ][Training] 65/100 [==================>...........] - ETA: 1:05  [ loss=0.0461 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.0433 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.0466 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.0455 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.0434 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.0514 ][Training] 71/100 [====================>.........] - ETA: 54s  [ loss=0.0472 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.0553 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.0420 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0539 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.0428 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.0403 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.0504 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.0550 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.0357 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0420 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0427 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0441 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.0435 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.0468 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.0458 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0467 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0454 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0489 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0499 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0359 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0509 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.0453 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.0529 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0424 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0405 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0480 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0422 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0477 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0483 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0373 ]
 
03/21/2023 10:51:52 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 10:51:52 - INFO - __main__ -     Num examples = 1000
03/21/2023 10:51:52 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 34s  [ loss=0.1227 ][Evaluating] 1/25 [>.............................] - ETA: 35s[Evaluating] 2/25 [=>............................] - ETA: 31s  [ loss=0.0802 ][Evaluating] 2/25 [=>............................] - ETA: 31s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.0906 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.0757 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.1316 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.0878 ][Evaluating] 6/25 [======>.......................] - ETA: 26s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.1382 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 23s  [ loss=0.0903 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.0938 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.0953 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.0923 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0784 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.0937 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.0879 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1363 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1039 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.1008 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.0844 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.1014 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0704 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1033 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.0874 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.0962 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1055 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.0900 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 10:52:26 - INFO - __main__ -   

03/21/2023 10:52:26 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 10:52:26 - INFO - __main__ -    acc: 0.6978 - recall: 0.7476 - f1: 0.7218 - loss: 0.0975 
03/21/2023 10:52:26 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 10:52:26 - INFO - __main__ -   ******* LOC results ********
03/21/2023 10:52:26 - INFO - __main__ -    acc: 0.7895 - recall: 0.8333 - f1: 0.8108 
03/21/2023 10:52:26 - INFO - __main__ -   ******* MISC results ********
03/21/2023 10:52:26 - INFO - __main__ -    acc: 0.3523 - recall: 0.3091 - f1: 0.3293 
03/21/2023 10:52:26 - INFO - __main__ -   ******* ORG results ********
03/21/2023 10:52:26 - INFO - __main__ -    acc: 0.5169 - recall: 0.6802 - f1: 0.5874 
03/21/2023 10:52:26 - INFO - __main__ -   ******* PER results ********
03/21/2023 10:52:26 - INFO - __main__ -    acc: 0.8265 - recall: 0.8714 - f1: 0.8483 
03/21/2023 10:52:28 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-400
03/21/2023 10:52:30 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-400
03/21/2023 10:52:31 - INFO - __main__ -   


Epoch: 4/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:18  [ loss=0.0432 ][Training] 2/100 [..............................] - ETA: 4:04  [ loss=0.0345 ][Training] 3/100 [..............................] - ETA: 3:39  [ loss=0.0395 ][Training] 4/100 [>.............................] - ETA: 3:26  [ loss=0.0457 ][Training] 5/100 [>.............................] - ETA: 3:17  [ loss=0.0389 ][Training] 6/100 [>.............................] - ETA: 3:11  [ loss=0.0402 ][Training] 7/100 [=>............................] - ETA: 3:06  [ loss=0.0306 ][Training] 8/100 [=>............................] - ETA: 3:02  [ loss=0.0371 ][Training] 9/100 [=>............................] - ETA: 2:58  [ loss=0.0376 ][Training] 10/100 [==>...........................] - ETA: 2:55  [ loss=0.0386 ][Training] 11/100 [==>...........................] - ETA: 2:52  [ loss=0.0410 ][Training] 12/100 [==>...........................] - ETA: 2:50  [ loss=0.0331 ][Training] 13/100 [==>...........................] - ETA: 2:47  [ loss=0.0331 ][Training] 14/100 [===>..........................] - ETA: 2:44  [ loss=0.0439 ][Training] 15/100 [===>..........................] - ETA: 2:44  [ loss=0.0355 ][Training] 16/100 [===>..........................] - ETA: 2:41  [ loss=0.0327 ][Training] 17/100 [====>.........................] - ETA: 2:39  [ loss=0.0422 ][Training] 18/100 [====>.........................] - ETA: 2:37  [ loss=0.0330 ][Training] 19/100 [====>.........................] - ETA: 2:34  [ loss=0.0383 ][Training] 20/100 [=====>........................] - ETA: 2:32  [ loss=0.0372 ][Training] 21/100 [=====>........................] - ETA: 2:30  [ loss=0.0335 ][Training] 22/100 [=====>........................] - ETA: 2:28  [ loss=0.0335 ][Training] 23/100 [=====>........................] - ETA: 2:26  [ loss=0.0363 ][Training] 24/100 [======>.......................] - ETA: 2:23  [ loss=0.0360 ][Training] 25/100 [======>.......................] - ETA: 2:21  [ loss=0.0498 ][Training] 26/100 [======>.......................] - ETA: 2:19  [ loss=0.0421 ][Training] 27/100 [=======>......................] - ETA: 2:17  [ loss=0.0357 ][Training] 28/100 [=======>......................] - ETA: 2:15  [ loss=0.0306 ][Training] 29/100 [=======>......................] - ETA: 2:13  [ loss=0.0419 ][Training] 30/100 [========>.....................] - ETA: 2:12  [ loss=0.0332 ][Training] 31/100 [========>.....................] - ETA: 2:10  [ loss=0.0351 ][Training] 32/100 [========>.....................] - ETA: 2:08  [ loss=0.0363 ][Training] 33/100 [========>.....................] - ETA: 2:06  [ loss=0.0361 ][Training] 34/100 [=========>....................] - ETA: 2:04  [ loss=0.0301 ][Training] 35/100 [=========>....................] - ETA: 2:02  [ loss=0.0363 ][Training] 36/100 [=========>....................] - ETA: 2:00  [ loss=0.0318 ][Training] 37/100 [==========>...................] - ETA: 1:58  [ loss=0.0341 ][Training] 38/100 [==========>...................] - ETA: 1:56  [ loss=0.0442 ][Training] 39/100 [==========>...................] - ETA: 1:54  [ loss=0.0361 ][Training] 40/100 [===========>..................] - ETA: 1:52  [ loss=0.0296 ][Training] 41/100 [===========>..................] - ETA: 1:50  [ loss=0.0357 ][Training] 42/100 [===========>..................] - ETA: 1:48  [ loss=0.0393 ][Training] 43/100 [===========>..................] - ETA: 1:46  [ loss=0.0365 ][Training] 44/100 [============>.................] - ETA: 1:44  [ loss=0.0375 ][Training] 45/100 [============>.................] - ETA: 1:42  [ loss=0.0389 ][Training] 46/100 [============>.................] - ETA: 1:40  [ loss=0.0320 ][Training] 47/100 [=============>................] - ETA: 1:38  [ loss=0.0337 ][Training] 48/100 [=============>................] - ETA: 1:36  [ loss=0.0380 ][Training] 49/100 [=============>................] - ETA: 1:34  [ loss=0.0324 ][Training] 50/100 [==============>...............] - ETA: 1:32  [ loss=0.0318 ][Training] 51/100 [==============>...............] - ETA: 1:30  [ loss=0.0399 ][Training] 52/100 [==============>...............] - ETA: 1:28  [ loss=0.0386 ][Training] 53/100 [==============>...............] - ETA: 1:27  [ loss=0.0374 ][Training] 54/100 [===============>..............] - ETA: 1:25  [ loss=0.0331 ][Training] 55/100 [===============>..............] - ETA: 1:23  [ loss=0.0353 ][Training] 56/100 [===============>..............] - ETA: 1:21  [ loss=0.0420 ][Training] 57/100 [================>.............] - ETA: 1:19  [ loss=0.0351 ][Training] 58/100 [================>.............] - ETA: 1:17  [ loss=0.0398 ][Training] 59/100 [================>.............] - ETA: 1:15  [ loss=0.0355 ][Training] 60/100 [=================>............] - ETA: 1:14  [ loss=0.0418 ][Training] 61/100 [=================>............] - ETA: 1:12  [ loss=0.0363 ][Training] 62/100 [=================>............] - ETA: 1:10  [ loss=0.0376 ][Training] 63/100 [=================>............] - ETA: 1:08  [ loss=0.0342 ][Training] 64/100 [==================>...........] - ETA: 1:06  [ loss=0.0337 ][Training] 65/100 [==================>...........] - ETA: 1:04  [ loss=0.0386 ][Training] 66/100 [==================>...........] - ETA: 1:02  [ loss=0.0404 ][Training] 67/100 [===================>..........] - ETA: 1:01  [ loss=0.0331 ][Training] 68/100 [===================>..........] - ETA: 59s  [ loss=0.0321 ][Training] 69/100 [===================>..........] - ETA: 57s  [ loss=0.0392 ][Training] 70/100 [====================>.........] - ETA: 55s  [ loss=0.0371 ][Training] 71/100 [====================>.........] - ETA: 53s  [ loss=0.0359 ][Training] 72/100 [====================>.........] - ETA: 51s  [ loss=0.0341 ][Training] 73/100 [====================>.........] - ETA: 49s  [ loss=0.0320 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0386 ][Training] 75/100 [=====================>........] - ETA: 46s  [ loss=0.0364 ][Training] 76/100 [=====================>........] - ETA: 44s  [ loss=0.0326 ][Training] 77/100 [======================>.......] - ETA: 42s  [ loss=0.0302 ][Training] 78/100 [======================>.......] - ETA: 40s  [ loss=0.0420 ][Training] 79/100 [======================>.......] - ETA: 38s  [ loss=0.0329 ][Training] 80/100 [=======================>......] - ETA: 36s  [ loss=0.0324 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0337 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0317 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.0340 ][Training] 84/100 [========================>.....] - ETA: 29s  [ loss=0.0359 ][Training] 85/100 [========================>.....] - ETA: 27s  [ loss=0.0323 ][Training] 86/100 [========================>.....] - ETA: 25s  [ loss=0.0360 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0367 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0342 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0328 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0390 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0358 ][Training] 92/100 [==========================>...] - ETA: 14s  [ loss=0.0355 ][Training] 93/100 [==========================>...] - ETA: 12s  [ loss=0.0296 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0288 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0325 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0347 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0441 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0384 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0362 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0421 ]
 
03/21/2023 10:55:36 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 10:55:36 - INFO - __main__ -     Num examples = 1000
03/21/2023 10:55:36 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 35s  [ loss=0.1383 ][Evaluating] 1/25 [>.............................] - ETA: 35s[Evaluating] 2/25 [=>............................] - ETA: 32s  [ loss=0.0818 ][Evaluating] 2/25 [=>............................] - ETA: 32s[Evaluating] 3/25 [==>...........................] - ETA: 30s  [ loss=0.1015 ][Evaluating] 3/25 [==>...........................] - ETA: 30s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.0857 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.1441 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.0948 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.1389 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.1027 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.0899 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.0973 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.1001 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0810 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.0979 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.0863 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1453 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1150 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.1136 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.0933 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.0989 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0753 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1238 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.0901 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.1033 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1182 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.0970 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 10:56:09 - INFO - __main__ -   

03/21/2023 10:56:09 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 10:56:09 - INFO - __main__ -    acc: 0.7262 - recall: 0.7541 - f1: 0.7399 - loss: 0.1046 
03/21/2023 10:56:09 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 10:56:09 - INFO - __main__ -   ******* LOC results ********
03/21/2023 10:56:09 - INFO - __main__ -    acc: 0.7880 - recall: 0.8544 - f1: 0.8199 
03/21/2023 10:56:09 - INFO - __main__ -   ******* MISC results ********
03/21/2023 10:56:09 - INFO - __main__ -    acc: 0.4167 - recall: 0.4318 - f1: 0.4241 
03/21/2023 10:56:09 - INFO - __main__ -   ******* ORG results ********
03/21/2023 10:56:09 - INFO - __main__ -    acc: 0.6667 - recall: 0.5344 - f1: 0.5933 
03/21/2023 10:56:09 - INFO - __main__ -   ******* PER results ********
03/21/2023 10:56:09 - INFO - __main__ -    acc: 0.8043 - recall: 0.8859 - f1: 0.8431 
03/21/2023 10:56:10 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-500
03/21/2023 10:56:13 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-500
03/21/2023 10:56:13 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:56:31 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 10:56:32 - INFO - __main__ -   


Epoch: 5/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:36  [ loss=0.0362 ][Training] 2/100 [..............................] - ETA: 4:13  [ loss=0.0290 ][Training] 3/100 [..............................] - ETA: 3:44  [ loss=0.0279 ][Training] 4/100 [>.............................] - ETA: 3:30  [ loss=0.0327 ][Training] 5/100 [>.............................] - ETA: 3:21  [ loss=0.0331 ][Training] 6/100 [>.............................] - ETA: 3:16  [ loss=0.0350 ][Training] 7/100 [=>............................] - ETA: 3:12  [ loss=0.0334 ][Training] 8/100 [=>............................] - ETA: 3:07  [ loss=0.0288 ][Training] 9/100 [=>............................] - ETA: 3:04  [ loss=0.0304 ][Training] 10/100 [==>...........................] - ETA: 3:01  [ loss=0.0321 ][Training] 11/100 [==>...........................] - ETA: 2:59  [ loss=0.0330 ][Training] 12/100 [==>...........................] - ETA: 2:56  [ loss=0.0263 ][Training] 13/100 [==>...........................] - ETA: 2:53  [ loss=0.0280 ][Training] 14/100 [===>..........................] - ETA: 2:50  [ loss=0.0336 ][Training] 15/100 [===>..........................] - ETA: 2:47  [ loss=0.0302 ][Training] 16/100 [===>..........................] - ETA: 2:44  [ loss=0.0314 ][Training] 17/100 [====>.........................] - ETA: 2:42  [ loss=0.0277 ][Training] 18/100 [====>.........................] - ETA: 2:39  [ loss=0.0328 ][Training] 19/100 [====>.........................] - ETA: 2:37  [ loss=0.0316 ][Training] 20/100 [=====>........................] - ETA: 2:35  [ loss=0.0294 ][Training] 21/100 [=====>........................] - ETA: 2:32  [ loss=0.0284 ][Training] 22/100 [=====>........................] - ETA: 2:30  [ loss=0.0379 ][Training] 23/100 [=====>........................] - ETA: 2:28  [ loss=0.0289 ][Training] 24/100 [======>.......................] - ETA: 2:26  [ loss=0.0331 ][Training] 25/100 [======>.......................] - ETA: 2:24  [ loss=0.0317 ][Training] 26/100 [======>.......................] - ETA: 2:21  [ loss=0.0255 ][Training] 27/100 [=======>......................] - ETA: 2:19  [ loss=0.0305 ][Training] 28/100 [=======>......................] - ETA: 2:17  [ loss=0.0327 ][Training] 29/100 [=======>......................] - ETA: 2:15  [ loss=0.0350 ][Training] 30/100 [========>.....................] - ETA: 2:13  [ loss=0.0279 ][Training] 31/100 [========>.....................] - ETA: 2:11  [ loss=0.0290 ][Training] 32/100 [========>.....................] - ETA: 2:09  [ loss=0.0304 ][Training] 33/100 [========>.....................] - ETA: 2:07  [ loss=0.0317 ][Training] 34/100 [=========>....................] - ETA: 2:05  [ loss=0.0313 ][Training] 35/100 [=========>....................] - ETA: 2:03  [ loss=0.0298 ][Training] 36/100 [=========>....................] - ETA: 2:01  [ loss=0.0322 ][Training] 37/100 [==========>...................] - ETA: 1:59  [ loss=0.0310 ][Training] 38/100 [==========>...................] - ETA: 1:57  [ loss=0.0313 ][Training] 39/100 [==========>...................] - ETA: 1:55  [ loss=0.0274 ][Training] 40/100 [===========>..................] - ETA: 1:53  [ loss=0.0279 ][Training] 41/100 [===========>..................] - ETA: 1:51  [ loss=0.0361 ][Training] 42/100 [===========>..................] - ETA: 1:49  [ loss=0.0393 ][Training] 43/100 [===========>..................] - ETA: 1:47  [ loss=0.0336 ][Training] 44/100 [============>.................] - ETA: 1:45  [ loss=0.0276 ][Training] 45/100 [============>.................] - ETA: 1:43  [ loss=0.0360 ][Training] 46/100 [============>.................] - ETA: 1:41  [ loss=0.0280 ][Training] 47/100 [=============>................] - ETA: 1:39  [ loss=0.0326 ][Training] 48/100 [=============>................] - ETA: 1:37  [ loss=0.0290 ][Training] 49/100 [=============>................] - ETA: 1:35  [ loss=0.0308 ][Training] 50/100 [==============>...............] - ETA: 1:33  [ loss=0.0312 ][Training] 51/100 [==============>...............] - ETA: 1:32  [ loss=0.0292 ][Training] 52/100 [==============>...............] - ETA: 1:30  [ loss=0.0355 ][Training] 53/100 [==============>...............] - ETA: 1:28  [ loss=0.0319 ][Training] 54/100 [===============>..............] - ETA: 1:26  [ loss=0.0288 ][Training] 55/100 [===============>..............] - ETA: 1:24  [ loss=0.0331 ][Training] 56/100 [===============>..............] - ETA: 1:22  [ loss=0.0300 ][Training] 57/100 [================>.............] - ETA: 1:20  [ loss=0.0321 ][Training] 58/100 [================>.............] - ETA: 1:18  [ loss=0.0314 ][Training] 59/100 [================>.............] - ETA: 1:16  [ loss=0.0288 ][Training] 60/100 [=================>............] - ETA: 1:15  [ loss=0.0285 ][Training] 61/100 [=================>............] - ETA: 1:13  [ loss=0.0421 ][Training] 62/100 [=================>............] - ETA: 1:11  [ loss=0.0309 ][Training] 63/100 [=================>............] - ETA: 1:09  [ loss=0.0299 ][Training] 64/100 [==================>...........] - ETA: 1:07  [ loss=0.0314 ][Training] 65/100 [==================>...........] - ETA: 1:05  [ loss=0.0242 ][Training] 66/100 [==================>...........] - ETA: 1:03  [ loss=0.0296 ][Training] 67/100 [===================>..........] - ETA: 1:01  [ loss=0.0282 ][Training] 68/100 [===================>..........] - ETA: 59s  [ loss=0.0313 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.0310 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.0334 ][Training] 71/100 [====================>.........] - ETA: 54s  [ loss=0.0261 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.0295 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.0303 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0283 ][Training] 75/100 [=====================>........] - ETA: 46s  [ loss=0.0328 ][Training] 76/100 [=====================>........] - ETA: 44s  [ loss=0.0324 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.0326 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.0335 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.0274 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0344 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0283 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0301 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.0320 ][Training] 84/100 [========================>.....] - ETA: 29s  [ loss=0.0304 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.0299 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0368 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0288 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0271 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0291 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0302 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0278 ][Training] 92/100 [==========================>...] - ETA: 14s  [ loss=0.0347 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.0294 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0345 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0413 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0363 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0344 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0324 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0366 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0297 ]
 
03/21/2023 10:59:39 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 10:59:39 - INFO - __main__ -     Num examples = 1000
03/21/2023 10:59:39 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 32s  [ loss=0.1399 ][Evaluating] 1/25 [>.............................] - ETA: 32s[Evaluating] 2/25 [=>............................] - ETA: 31s  [ loss=0.0815 ][Evaluating] 2/25 [=>............................] - ETA: 31s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.1069 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.0885 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.1535 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.1106 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.1563 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.1108 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.0902 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.1021 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.1073 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0929 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.1102 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.0896 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1585 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1285 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.1106 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.0929 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.1101 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0849 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1411 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.0908 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.0979 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1201 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.1055 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 11:00:13 - INFO - __main__ -   

03/21/2023 11:00:13 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 11:00:13 - INFO - __main__ -    acc: 0.7288 - recall: 0.7378 - f1: 0.7333 - loss: 0.1112 
03/21/2023 11:00:13 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 11:00:13 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:00:13 - INFO - __main__ -    acc: 0.8041 - recall: 0.8180 - f1: 0.8110 
03/21/2023 11:00:13 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:00:13 - INFO - __main__ -    acc: 0.3962 - recall: 0.3818 - f1: 0.3889 
03/21/2023 11:00:13 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:00:13 - INFO - __main__ -    acc: 0.6076 - recall: 0.5830 - f1: 0.5950 
03/21/2023 11:00:13 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:00:13 - INFO - __main__ -    acc: 0.8310 - recall: 0.8732 - f1: 0.8516 
03/21/2023 11:00:14 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-600
03/21/2023 11:00:17 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-600
03/21/2023 11:00:17 - INFO - __main__ -   


Epoch: 6/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:02  [ loss=0.0272 ][Training] 2/100 [..............................] - ETA: 4:30  [ loss=0.0259 ][Training] 3/100 [..............................] - ETA: 3:58  [ loss=0.0269 ][Training] 4/100 [>.............................] - ETA: 3:39  [ loss=0.0321 ][Training] 5/100 [>.............................] - ETA: 3:29  [ loss=0.0261 ][Training] 6/100 [>.............................] - ETA: 3:21  [ loss=0.0262 ][Training] 7/100 [=>............................] - ETA: 3:15  [ loss=0.0294 ][Training] 8/100 [=>............................] - ETA: 3:10  [ loss=0.0348 ][Training] 9/100 [=>............................] - ETA: 3:06  [ loss=0.0308 ][Training] 10/100 [==>...........................] - ETA: 3:02  [ loss=0.0310 ][Training] 11/100 [==>...........................] - ETA: 2:58  [ loss=0.0250 ][Training] 12/100 [==>...........................] - ETA: 2:55  [ loss=0.0290 ][Training] 13/100 [==>...........................] - ETA: 2:52  [ loss=0.0267 ][Training] 14/100 [===>..........................] - ETA: 2:49  [ loss=0.0267 ][Training] 15/100 [===>..........................] - ETA: 2:47  [ loss=0.0323 ][Training] 16/100 [===>..........................] - ETA: 2:46  [ loss=0.0257 ][Training] 17/100 [====>.........................] - ETA: 2:44  [ loss=0.0330 ][Training] 18/100 [====>.........................] - ETA: 2:41  [ loss=0.0311 ][Training] 19/100 [====>.........................] - ETA: 2:39  [ loss=0.0350 ][Training] 20/100 [=====>........................] - ETA: 2:37  [ loss=0.0295 ][Training] 21/100 [=====>........................] - ETA: 2:34  [ loss=0.0331 ][Training] 22/100 [=====>........................] - ETA: 2:32  [ loss=0.0282 ][Training] 23/100 [=====>........................] - ETA: 2:30  [ loss=0.0278 ][Training] 24/100 [======>.......................] - ETA: 2:28  [ loss=0.0304 ][Training] 25/100 [======>.......................] - ETA: 2:26  [ loss=0.0289 ][Training] 26/100 [======>.......................] - ETA: 2:24  [ loss=0.0278 ][Training] 27/100 [=======>......................] - ETA: 2:21  [ loss=0.0270 ][Training] 28/100 [=======>......................] - ETA: 2:19  [ loss=0.0286 ][Training] 29/100 [=======>......................] - ETA: 2:17  [ loss=0.0276 ][Training] 30/100 [========>.....................] - ETA: 2:15  [ loss=0.0253 ][Training] 31/100 [========>.....................] - ETA: 2:13  [ loss=0.0329 ][Training] 32/100 [========>.....................] - ETA: 2:11  [ loss=0.0334 ][Training] 33/100 [========>.....................] - ETA: 2:09  [ loss=0.0259 ][Training] 34/100 [=========>....................] - ETA: 2:07  [ loss=0.0278 ][Training] 35/100 [=========>....................] - ETA: 2:05  [ loss=0.0289 ][Training] 36/100 [=========>....................] - ETA: 2:02  [ loss=0.0295 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.0280 ][Training] 38/100 [==========>...................] - ETA: 1:58  [ loss=0.0276 ][Training] 39/100 [==========>...................] - ETA: 1:56  [ loss=0.0301 ][Training] 40/100 [===========>..................] - ETA: 1:54  [ loss=0.0255 ][Training] 41/100 [===========>..................] - ETA: 1:52  [ loss=0.0252 ][Training] 42/100 [===========>..................] - ETA: 1:50  [ loss=0.0278 ][Training] 43/100 [===========>..................] - ETA: 1:48  [ loss=0.0272 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.0261 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.0279 ][Training] 46/100 [============>.................] - ETA: 1:43  [ loss=0.0265 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.0253 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.0359 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.0264 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.0302 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.0291 ][Training] 52/100 [==============>...............] - ETA: 1:31  [ loss=0.0290 ][Training] 53/100 [==============>...............] - ETA: 1:29  [ loss=0.0307 ][Training] 54/100 [===============>..............] - ETA: 1:27  [ loss=0.0271 ][Training] 55/100 [===============>..............] - ETA: 1:25  [ loss=0.0346 ][Training] 56/100 [===============>..............] - ETA: 1:23  [ loss=0.0275 ][Training] 57/100 [================>.............] - ETA: 1:21  [ loss=0.0248 ][Training] 58/100 [================>.............] - ETA: 1:19  [ loss=0.0274 ][Training] 59/100 [================>.............] - ETA: 1:17  [ loss=0.0291 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.0270 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.0262 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.0289 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.0268 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.0298 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.0285 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.0270 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.0280 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.0315 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.0300 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.0355 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.0285 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.0282 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.0279 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.0274 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.0343 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.0285 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.0320 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.0271 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.0325 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0284 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0287 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0272 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.0341 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.0303 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.0284 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0282 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0301 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0349 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0282 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0328 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0297 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.0244 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.0297 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0292 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0253 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0301 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0286 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0287 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0249 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0330 ]
 
03/21/2023 11:03:25 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 11:03:25 - INFO - __main__ -     Num examples = 1000
03/21/2023 11:03:25 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 34s  [ loss=0.1445 ][Evaluating] 1/25 [>.............................] - ETA: 34s[Evaluating] 2/25 [=>............................] - ETA: 31s  [ loss=0.0860 ][Evaluating] 2/25 [=>............................] - ETA: 31s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.1074 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.1041 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 26s  [ loss=0.1741 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.1069 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 23s  [ loss=0.1703 ][Evaluating] 7/25 [=======>......................] - ETA: 23s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.1051 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 20s  [ loss=0.0933 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 19s  [ loss=0.1267 ][Evaluating] 10/25 [===========>..................] - ETA: 19s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.1046 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0914 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 15s  [ loss=0.1238 ][Evaluating] 13/25 [==============>...............] - ETA: 15s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.0960 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1702 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1219 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.1229 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.1011 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.1215 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0831 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1382 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.0975 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.1164 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1320 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.1015 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 11:03:59 - INFO - __main__ -   

03/21/2023 11:03:59 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 11:03:59 - INFO - __main__ -    acc: 0.7346 - recall: 0.7508 - f1: 0.7426 - loss: 0.1176 
03/21/2023 11:03:59 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 11:03:59 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:03:59 - INFO - __main__ -    acc: 0.7762 - recall: 0.8506 - f1: 0.8117 
03/21/2023 11:03:59 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:03:59 - INFO - __main__ -    acc: 0.4503 - recall: 0.3909 - f1: 0.4185 
03/21/2023 11:03:59 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:03:59 - INFO - __main__ -    acc: 0.6198 - recall: 0.6073 - f1: 0.6135 
03/21/2023 11:03:59 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:03:59 - INFO - __main__ -    acc: 0.8368 - recall: 0.8641 - f1: 0.8503 
03/21/2023 11:04:01 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-700
03/21/2023 11:04:04 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-700
03/21/2023 11:04:04 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 11:04:22 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 11:04:22 - INFO - __main__ -   


Epoch: 7/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:11  [ loss=0.0298 ][Training] 2/100 [..............................] - ETA: 4:05  [ loss=0.0273 ][Training] 3/100 [..............................] - ETA: 3:40  [ loss=0.0265 ][Training] 4/100 [>.............................] - ETA: 3:26  [ loss=0.0290 ][Training] 5/100 [>.............................] - ETA: 3:18  [ loss=0.0291 ][Training] 6/100 [>.............................] - ETA: 3:14  [ loss=0.0342 ][Training] 7/100 [=>............................] - ETA: 3:08  [ loss=0.0252 ][Training] 8/100 [=>............................] - ETA: 3:04  [ loss=0.0299 ][Training] 9/100 [=>............................] - ETA: 3:01  [ loss=0.0275 ][Training] 10/100 [==>...........................] - ETA: 2:57  [ loss=0.0274 ][Training] 11/100 [==>...........................] - ETA: 2:53  [ loss=0.0269 ][Training] 12/100 [==>...........................] - ETA: 2:50  [ loss=0.0256 ][Training] 13/100 [==>...........................] - ETA: 2:47  [ loss=0.0260 ][Training] 14/100 [===>..........................] - ETA: 2:44  [ loss=0.0261 ][Training] 15/100 [===>..........................] - ETA: 2:42  [ loss=0.0276 ][Training] 16/100 [===>..........................] - ETA: 2:40  [ loss=0.0296 ][Training] 17/100 [====>.........................] - ETA: 2:38  [ loss=0.0267 ][Training] 18/100 [====>.........................] - ETA: 2:36  [ loss=0.0296 ][Training] 19/100 [====>.........................] - ETA: 2:34  [ loss=0.0284 ][Training] 20/100 [=====>........................] - ETA: 2:31  [ loss=0.0293 ][Training] 21/100 [=====>........................] - ETA: 2:29  [ loss=0.0268 ][Training] 22/100 [=====>........................] - ETA: 2:27  [ loss=0.0314 ][Training] 23/100 [=====>........................] - ETA: 2:24  [ loss=0.0267 ][Training] 24/100 [======>.......................] - ETA: 2:22  [ loss=0.0270 ][Training] 25/100 [======>.......................] - ETA: 2:20  [ loss=0.0244 ][Training] 26/100 [======>.......................] - ETA: 2:18  [ loss=0.0233 ][Training] 27/100 [=======>......................] - ETA: 2:16  [ loss=0.0284 ][Training] 28/100 [=======>......................] - ETA: 2:14  [ loss=0.0257 ][Training] 29/100 [=======>......................] - ETA: 2:12  [ loss=0.0292 ][Training] 30/100 [========>.....................] - ETA: 2:10  [ loss=0.0276 ][Training] 31/100 [========>.....................] - ETA: 2:08  [ loss=0.0265 ][Training] 32/100 [========>.....................] - ETA: 2:06  [ loss=0.0247 ][Training] 33/100 [========>.....................] - ETA: 2:05  [ loss=0.0270 ][Training] 34/100 [=========>....................] - ETA: 2:03  [ loss=0.0284 ][Training] 35/100 [=========>....................] - ETA: 2:01  [ loss=0.0258 ][Training] 36/100 [=========>....................] - ETA: 1:59  [ loss=0.0266 ][Training] 37/100 [==========>...................] - ETA: 1:57  [ loss=0.0244 ][Training] 38/100 [==========>...................] - ETA: 1:55  [ loss=0.0272 ][Training] 39/100 [==========>...................] - ETA: 1:53  [ loss=0.0274 ][Training] 40/100 [===========>..................] - ETA: 1:51  [ loss=0.0289 ][Training] 41/100 [===========>..................] - ETA: 1:50  [ loss=0.0240 ][Training] 42/100 [===========>..................] - ETA: 1:48  [ loss=0.0277 ][Training] 43/100 [===========>..................] - ETA: 1:46  [ loss=0.0247 ][Training] 44/100 [============>.................] - ETA: 1:44  [ loss=0.0287 ][Training] 45/100 [============>.................] - ETA: 1:42  [ loss=0.0258 ][Training] 46/100 [============>.................] - ETA: 1:40  [ loss=0.0274 ][Training] 47/100 [=============>................] - ETA: 1:38  [ loss=0.0279 ][Training] 48/100 [=============>................] - ETA: 1:37  [ loss=0.0242 ][Training] 49/100 [=============>................] - ETA: 1:35  [ loss=0.0269 ][Training] 50/100 [==============>...............] - ETA: 1:33  [ loss=0.0261 ][Training] 51/100 [==============>...............] - ETA: 1:31  [ loss=0.0243 ][Training] 52/100 [==============>...............] - ETA: 1:29  [ loss=0.0290 ][Training] 53/100 [==============>...............] - ETA: 1:27  [ loss=0.0272 ][Training] 54/100 [===============>..............] - ETA: 1:25  [ loss=0.0285 ][Training] 55/100 [===============>..............] - ETA: 1:23  [ loss=0.0261 ][Training] 56/100 [===============>..............] - ETA: 1:21  [ loss=0.0253 ][Training] 57/100 [================>.............] - ETA: 1:19  [ loss=0.0307 ][Training] 58/100 [================>.............] - ETA: 1:18  [ loss=0.0257 ][Training] 59/100 [================>.............] - ETA: 1:16  [ loss=0.0262 ][Training] 60/100 [=================>............] - ETA: 1:14  [ loss=0.0253 ][Training] 61/100 [=================>............] - ETA: 1:12  [ loss=0.0266 ][Training] 62/100 [=================>............] - ETA: 1:10  [ loss=0.0286 ][Training] 63/100 [=================>............] - ETA: 1:08  [ loss=0.0264 ][Training] 64/100 [==================>...........] - ETA: 1:06  [ loss=0.0295 ][Training] 65/100 [==================>...........] - ETA: 1:05  [ loss=0.0288 ][Training] 66/100 [==================>...........] - ETA: 1:03  [ loss=0.0253 ][Training] 67/100 [===================>..........] - ETA: 1:01  [ loss=0.0253 ][Training] 68/100 [===================>..........] - ETA: 59s  [ loss=0.0235 ][Training] 69/100 [===================>..........] - ETA: 57s  [ loss=0.0266 ][Training] 70/100 [====================>.........] - ETA: 55s  [ loss=0.0369 ][Training] 71/100 [====================>.........] - ETA: 53s  [ loss=0.0269 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.0275 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.0252 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0268 ][Training] 75/100 [=====================>........] - ETA: 46s  [ loss=0.0261 ][Training] 76/100 [=====================>........] - ETA: 44s  [ loss=0.0296 ][Training] 77/100 [======================>.......] - ETA: 42s  [ loss=0.0268 ][Training] 78/100 [======================>.......] - ETA: 40s  [ loss=0.0284 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.0282 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0277 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0292 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0270 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.0294 ][Training] 84/100 [========================>.....] - ETA: 29s  [ loss=0.0271 ][Training] 85/100 [========================>.....] - ETA: 27s  [ loss=0.0262 ][Training] 86/100 [========================>.....] - ETA: 25s  [ loss=0.0260 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0303 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0290 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0264 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0234 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0249 ][Training] 92/100 [==========================>...] - ETA: 14s  [ loss=0.0271 ][Training] 93/100 [==========================>...] - ETA: 12s  [ loss=0.0250 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0300 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0245 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0279 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0250 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0281 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0278 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0278 ]
 
03/21/2023 11:07:28 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 11:07:28 - INFO - __main__ -     Num examples = 1000
03/21/2023 11:07:28 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 35s  [ loss=0.1484 ][Evaluating] 1/25 [>.............................] - ETA: 36s[Evaluating] 2/25 [=>............................] - ETA: 33s  [ loss=0.0919 ][Evaluating] 2/25 [=>............................] - ETA: 33s[Evaluating] 3/25 [==>...........................] - ETA: 32s  [ loss=0.1103 ][Evaluating] 3/25 [==>...........................] - ETA: 32s[Evaluating] 4/25 [===>..........................] - ETA: 30s  [ loss=0.1016 ][Evaluating] 4/25 [===>..........................] - ETA: 30s[Evaluating] 5/25 [=====>........................] - ETA: 29s  [ loss=0.1797 ][Evaluating] 5/25 [=====>........................] - ETA: 29s[Evaluating] 6/25 [======>.......................] - ETA: 28s  [ loss=0.1129 ][Evaluating] 6/25 [======>.......................] - ETA: 28s[Evaluating] 7/25 [=======>......................] - ETA: 26s  [ loss=0.1742 ][Evaluating] 7/25 [=======>......................] - ETA: 26s[Evaluating] 8/25 [========>.....................] - ETA: 25s  [ loss=0.1161 ][Evaluating] 8/25 [========>.....................] - ETA: 25s[Evaluating] 9/25 [=========>....................] - ETA: 23s  [ loss=0.0964 ][Evaluating] 9/25 [=========>....................] - ETA: 23s[Evaluating] 10/25 [===========>..................] - ETA: 21s  [ loss=0.1221 ][Evaluating] 10/25 [===========>..................] - ETA: 21s[Evaluating] 11/25 [============>.................] - ETA: 20s  [ loss=0.1078 ][Evaluating] 11/25 [============>.................] - ETA: 20s[Evaluating] 12/25 [=============>................] - ETA: 19s  [ loss=0.0983 ][Evaluating] 12/25 [=============>................] - ETA: 19s[Evaluating] 13/25 [==============>...............] - ETA: 17s  [ loss=0.1200 ][Evaluating] 13/25 [==============>...............] - ETA: 17s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.1040 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 14s  [ loss=0.1734 ][Evaluating] 15/25 [=================>............] - ETA: 14s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1260 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 11s  [ loss=0.1257 ][Evaluating] 17/25 [===================>..........] - ETA: 11s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.1049 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.1253 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 7s  [ loss=0.0892 ][Evaluating] 20/25 [=======================>......] - ETA: 7s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1337 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.0984 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.1079 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1350 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.1038 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 11:08:03 - INFO - __main__ -   

03/21/2023 11:08:03 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 11:08:03 - INFO - __main__ -    acc: 0.7263 - recall: 0.7508 - f1: 0.7384 - loss: 0.1203 
03/21/2023 11:08:03 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 11:08:03 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:08:03 - INFO - __main__ -    acc: 0.7841 - recall: 0.8487 - f1: 0.8151 
03/21/2023 11:08:03 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:08:03 - INFO - __main__ -    acc: 0.4362 - recall: 0.3727 - f1: 0.4020 
03/21/2023 11:08:03 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:08:03 - INFO - __main__ -    acc: 0.5875 - recall: 0.6113 - f1: 0.5992 
03/21/2023 11:08:03 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:08:03 - INFO - __main__ -    acc: 0.8250 - recall: 0.8714 - f1: 0.8476 
03/21/2023 11:08:04 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-800
03/21/2023 11:08:07 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-800
03/21/2023 11:08:07 - INFO - __main__ -   


Epoch: 8/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:35  [ loss=0.0271 ][Training] 2/100 [..............................] - ETA: 4:47  [ loss=0.0319 ][Training] 3/100 [..............................] - ETA: 4:10  [ loss=0.0217 ][Training] 4/100 [>.............................] - ETA: 3:51  [ loss=0.0256 ][Training] 5/100 [>.............................] - ETA: 3:37  [ loss=0.0275 ][Training] 6/100 [>.............................] - ETA: 3:28  [ loss=0.0304 ][Training] 7/100 [=>............................] - ETA: 3:21  [ loss=0.0259 ][Training] 8/100 [=>............................] - ETA: 3:15  [ loss=0.0269 ][Training] 9/100 [=>............................] - ETA: 3:10  [ loss=0.0254 ][Training] 10/100 [==>...........................] - ETA: 3:06  [ loss=0.0238 ][Training] 11/100 [==>...........................] - ETA: 3:02  [ loss=0.0268 ][Training] 12/100 [==>...........................] - ETA: 2:59  [ loss=0.0279 ][Training] 13/100 [==>...........................] - ETA: 2:56  [ loss=0.0240 ][Training] 14/100 [===>..........................] - ETA: 2:53  [ loss=0.0278 ][Training] 15/100 [===>..........................] - ETA: 2:50  [ loss=0.0263 ][Training] 16/100 [===>..........................] - ETA: 2:47  [ loss=0.0276 ][Training] 17/100 [====>.........................] - ETA: 2:46  [ loss=0.0270 ][Training] 18/100 [====>.........................] - ETA: 2:43  [ loss=0.0268 ][Training] 19/100 [====>.........................] - ETA: 2:41  [ loss=0.0272 ][Training] 20/100 [=====>........................] - ETA: 2:38  [ loss=0.0250 ][Training] 21/100 [=====>........................] - ETA: 2:36  [ loss=0.0281 ][Training] 22/100 [=====>........................] - ETA: 2:35  [ loss=0.0243 ][Training] 23/100 [=====>........................] - ETA: 2:33  [ loss=0.0282 ][Training] 24/100 [======>.......................] - ETA: 2:31  [ loss=0.0243 ][Training] 25/100 [======>.......................] - ETA: 2:29  [ loss=0.0274 ][Training] 26/100 [======>.......................] - ETA: 2:26  [ loss=0.0272 ][Training] 27/100 [=======>......................] - ETA: 2:24  [ loss=0.0247 ][Training] 28/100 [=======>......................] - ETA: 2:21  [ loss=0.0276 ][Training] 29/100 [=======>......................] - ETA: 2:19  [ loss=0.0251 ][Training] 30/100 [========>.....................] - ETA: 2:17  [ loss=0.0256 ][Training] 31/100 [========>.....................] - ETA: 2:15  [ loss=0.0269 ][Training] 32/100 [========>.....................] - ETA: 2:12  [ loss=0.0265 ][Training] 33/100 [========>.....................] - ETA: 2:10  [ loss=0.0289 ][Training] 34/100 [=========>....................] - ETA: 2:08  [ loss=0.0229 ][Training] 35/100 [=========>....................] - ETA: 2:06  [ loss=0.0265 ][Training] 36/100 [=========>....................] - ETA: 2:04  [ loss=0.0245 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.0285 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.0260 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.0254 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.0276 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.0236 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.0256 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.0273 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.0252 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.0264 ][Training] 46/100 [============>.................] - ETA: 1:44  [ loss=0.0283 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.0231 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.0266 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.0256 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.0261 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.0266 ][Training] 52/100 [==============>...............] - ETA: 1:31  [ loss=0.0261 ][Training] 53/100 [==============>...............] - ETA: 1:30  [ loss=0.0230 ][Training] 54/100 [===============>..............] - ETA: 1:28  [ loss=0.0243 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.0243 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.0281 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.0249 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.0256 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.0244 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.0332 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.0292 ][Training] 62/100 [=================>............] - ETA: 1:13  [ loss=0.0305 ][Training] 63/100 [=================>............] - ETA: 1:11  [ loss=0.0254 ][Training] 64/100 [==================>...........] - ETA: 1:09  [ loss=0.0262 ][Training] 65/100 [==================>...........] - ETA: 1:07  [ loss=0.0274 ][Training] 66/100 [==================>...........] - ETA: 1:05  [ loss=0.0295 ][Training] 67/100 [===================>..........] - ETA: 1:03  [ loss=0.0259 ][Training] 68/100 [===================>..........] - ETA: 1:01  [ loss=0.0263 ][Training] 69/100 [===================>..........] - ETA: 59s  [ loss=0.0288 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.0255 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.0267 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.0262 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.0248 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.0244 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.0334 ][Training] 76/100 [=====================>........] - ETA: 46s  [ loss=0.0254 ][Training] 77/100 [======================>.......] - ETA: 44s  [ loss=0.0263 ][Training] 78/100 [======================>.......] - ETA: 42s  [ loss=0.0240 ][Training] 79/100 [======================>.......] - ETA: 40s  [ loss=0.0252 ][Training] 80/100 [=======================>......] - ETA: 38s  [ loss=0.0256 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.0240 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.0272 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.0251 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.0244 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.0252 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0267 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0257 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0250 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0267 ][Training] 90/100 [==========================>...] - ETA: 19s  [ loss=0.0269 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.0242 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.0239 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.0276 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0260 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0266 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0274 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0273 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0286 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0240 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0265 ]
 
03/21/2023 11:11:16 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 11:11:16 - INFO - __main__ -     Num examples = 1000
03/21/2023 11:11:16 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 36s  [ loss=0.1573 ][Evaluating] 1/25 [>.............................] - ETA: 36s[Evaluating] 2/25 [=>............................] - ETA: 32s  [ loss=0.0945 ][Evaluating] 2/25 [=>............................] - ETA: 32s[Evaluating] 3/25 [==>...........................] - ETA: 30s  [ loss=0.1122 ][Evaluating] 3/25 [==>...........................] - ETA: 30s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.0981 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 26s  [ loss=0.1811 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.1115 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.1695 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.1170 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.1035 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.1240 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.1131 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.0997 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.1234 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.1028 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1722 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.1321 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.1239 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.1036 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.1289 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0934 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1388 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.1024 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.1189 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1367 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.1086 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 11:11:50 - INFO - __main__ -   

03/21/2023 11:11:50 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 11:11:50 - INFO - __main__ -    acc: 0.7344 - recall: 0.7573 - f1: 0.7457 - loss: 0.1227 
03/21/2023 11:11:50 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 11:11:50 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:11:50 - INFO - __main__ -    acc: 0.7996 - recall: 0.8487 - f1: 0.8234 
03/21/2023 11:11:50 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:11:50 - INFO - __main__ -    acc: 0.4174 - recall: 0.4136 - f1: 0.4155 
03/21/2023 11:11:50 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:11:50 - INFO - __main__ -    acc: 0.6507 - recall: 0.6032 - f1: 0.6261 
03/21/2023 11:11:50 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:11:50 - INFO - __main__ -    acc: 0.8231 - recall: 0.8768 - f1: 0.8491 
03/21/2023 11:11:51 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-900
03/21/2023 11:11:54 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-900
03/21/2023 11:11:54 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 11:12:13 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 11:12:13 - INFO - __main__ -   


Epoch: 9/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:20  [ loss=0.0262 ][Training] 2/100 [..............................] - ETA: 4:09  [ loss=0.0263 ][Training] 3/100 [..............................] - ETA: 3:42  [ loss=0.0268 ][Training] 4/100 [>.............................] - ETA: 3:29  [ loss=0.0237 ][Training] 5/100 [>.............................] - ETA: 3:22  [ loss=0.0257 ][Training] 6/100 [>.............................] - ETA: 3:16  [ loss=0.0229 ][Training] 7/100 [=>............................] - ETA: 3:11  [ loss=0.0254 ][Training] 8/100 [=>............................] - ETA: 3:11  [ loss=0.0284 ][Training] 9/100 [=>............................] - ETA: 3:07  [ loss=0.0298 ][Training] 10/100 [==>...........................] - ETA: 3:03  [ loss=0.0254 ][Training] 11/100 [==>...........................] - ETA: 3:00  [ loss=0.0229 ][Training] 12/100 [==>...........................] - ETA: 2:56  [ loss=0.0223 ][Training] 13/100 [==>...........................] - ETA: 2:53  [ loss=0.0248 ][Training] 14/100 [===>..........................] - ETA: 2:50  [ loss=0.0289 ][Training] 15/100 [===>..........................] - ETA: 2:47  [ loss=0.0230 ][Training] 16/100 [===>..........................] - ETA: 2:45  [ loss=0.0247 ][Training] 17/100 [====>.........................] - ETA: 2:42  [ loss=0.0241 ][Training] 18/100 [====>.........................] - ETA: 2:40  [ loss=0.0245 ][Training] 19/100 [====>.........................] - ETA: 2:37  [ loss=0.0260 ][Training] 20/100 [=====>........................] - ETA: 2:35  [ loss=0.0285 ][Training] 21/100 [=====>........................] - ETA: 2:32  [ loss=0.0258 ][Training] 22/100 [=====>........................] - ETA: 2:30  [ loss=0.0259 ][Training] 23/100 [=====>........................] - ETA: 2:28  [ loss=0.0277 ][Training] 24/100 [======>.......................] - ETA: 2:26  [ loss=0.0244 ][Training] 25/100 [======>.......................] - ETA: 2:23  [ loss=0.0246 ][Training] 26/100 [======>.......................] - ETA: 2:21  [ loss=0.0260 ][Training] 27/100 [=======>......................] - ETA: 2:19  [ loss=0.0281 ][Training] 28/100 [=======>......................] - ETA: 2:17  [ loss=0.0274 ][Training] 29/100 [=======>......................] - ETA: 2:15  [ loss=0.0259 ][Training] 30/100 [========>.....................] - ETA: 2:13  [ loss=0.0287 ][Training] 31/100 [========>.....................] - ETA: 2:10  [ loss=0.0266 ][Training] 32/100 [========>.....................] - ETA: 2:08  [ loss=0.0268 ][Training] 33/100 [========>.....................] - ETA: 2:06  [ loss=0.0257 ][Training] 34/100 [=========>....................] - ETA: 2:05  [ loss=0.0261 ][Training] 35/100 [=========>....................] - ETA: 2:03  [ loss=0.0264 ][Training] 36/100 [=========>....................] - ETA: 2:01  [ loss=0.0269 ][Training] 37/100 [==========>...................] - ETA: 1:59  [ loss=0.0279 ][Training] 38/100 [==========>...................] - ETA: 1:57  [ loss=0.0230 ][Training] 39/100 [==========>...................] - ETA: 1:55  [ loss=0.0246 ][Training] 40/100 [===========>..................] - ETA: 1:53  [ loss=0.0257 ][Training] 41/100 [===========>..................] - ETA: 1:51  [ loss=0.0278 ][Training] 42/100 [===========>..................] - ETA: 1:49  [ loss=0.0266 ][Training] 43/100 [===========>..................] - ETA: 1:47  [ loss=0.0253 ][Training] 44/100 [============>.................] - ETA: 1:45  [ loss=0.0253 ][Training] 45/100 [============>.................] - ETA: 1:43  [ loss=0.0255 ][Training] 46/100 [============>.................] - ETA: 1:41  [ loss=0.0276 ][Training] 47/100 [=============>................] - ETA: 1:39  [ loss=0.0277 ][Training] 48/100 [=============>................] - ETA: 1:37  [ loss=0.0255 ][Training] 49/100 [=============>................] - ETA: 1:36  [ loss=0.0267 ][Training] 50/100 [==============>...............] - ETA: 1:34  [ loss=0.0242 ][Training] 51/100 [==============>...............] - ETA: 1:32  [ loss=0.0269 ][Training] 52/100 [==============>...............] - ETA: 1:30  [ loss=0.0246 ][Training] 53/100 [==============>...............] - ETA: 1:28  [ loss=0.0254 ][Training] 54/100 [===============>..............] - ETA: 1:26  [ loss=0.0260 ][Training] 55/100 [===============>..............] - ETA: 1:24  [ loss=0.0244 ][Training] 56/100 [===============>..............] - ETA: 1:22  [ loss=0.0250 ][Training] 57/100 [================>.............] - ETA: 1:20  [ loss=0.0274 ][Training] 58/100 [================>.............] - ETA: 1:18  [ loss=0.0255 ][Training] 59/100 [================>.............] - ETA: 1:17  [ loss=0.0237 ][Training] 60/100 [=================>............] - ETA: 1:15  [ loss=0.0256 ][Training] 61/100 [=================>............] - ETA: 1:13  [ loss=0.0270 ][Training] 62/100 [=================>............] - ETA: 1:11  [ loss=0.0267 ][Training] 63/100 [=================>............] - ETA: 1:09  [ loss=0.0267 ][Training] 64/100 [==================>...........] - ETA: 1:07  [ loss=0.0263 ][Training] 65/100 [==================>...........] - ETA: 1:05  [ loss=0.0236 ][Training] 66/100 [==================>...........] - ETA: 1:03  [ loss=0.0270 ][Training] 67/100 [===================>..........] - ETA: 1:01  [ loss=0.0256 ][Training] 68/100 [===================>..........] - ETA: 59s  [ loss=0.0268 ][Training] 69/100 [===================>..........] - ETA: 57s  [ loss=0.0269 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.0274 ][Training] 71/100 [====================>.........] - ETA: 54s  [ loss=0.0268 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.0269 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.0261 ][Training] 74/100 [=====================>........] - ETA: 48s  [ loss=0.0250 ][Training] 75/100 [=====================>........] - ETA: 46s  [ loss=0.0251 ][Training] 76/100 [=====================>........] - ETA: 44s  [ loss=0.0249 ][Training] 77/100 [======================>.......] - ETA: 42s  [ loss=0.0260 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.0265 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.0275 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.0263 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.0244 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.0260 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.0261 ][Training] 84/100 [========================>.....] - ETA: 29s  [ loss=0.0236 ][Training] 85/100 [========================>.....] - ETA: 27s  [ loss=0.0291 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.0224 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.0286 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.0231 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.0286 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.0257 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.0260 ][Training] 92/100 [==========================>...] - ETA: 14s  [ loss=0.0241 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.0265 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.0244 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.0288 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.0274 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.0268 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.0247 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.0252 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.0219 ]
 
03/21/2023 11:15:19 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 11:15:19 - INFO - __main__ -     Num examples = 1000
03/21/2023 11:15:19 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 31s  [ loss=0.1552 ][Evaluating] 1/25 [>.............................] - ETA: 31s[Evaluating] 2/25 [=>............................] - ETA: 29s  [ loss=0.0945 ][Evaluating] 2/25 [=>............................] - ETA: 29s[Evaluating] 3/25 [==>...........................] - ETA: 28s  [ loss=0.1099 ][Evaluating] 3/25 [==>...........................] - ETA: 28s[Evaluating] 4/25 [===>..........................] - ETA: 26s  [ loss=0.1026 ][Evaluating] 4/25 [===>..........................] - ETA: 26s[Evaluating] 5/25 [=====>........................] - ETA: 25s  [ loss=0.1837 ][Evaluating] 5/25 [=====>........................] - ETA: 25s[Evaluating] 6/25 [======>.......................] - ETA: 24s  [ loss=0.1134 ][Evaluating] 6/25 [======>.......................] - ETA: 24s[Evaluating] 7/25 [=======>......................] - ETA: 23s  [ loss=0.1789 ][Evaluating] 7/25 [=======>......................] - ETA: 23s[Evaluating] 8/25 [========>.....................] - ETA: 21s  [ loss=0.1189 ][Evaluating] 8/25 [========>.....................] - ETA: 21s[Evaluating] 9/25 [=========>....................] - ETA: 20s  [ loss=0.1014 ][Evaluating] 9/25 [=========>....................] - ETA: 20s[Evaluating] 10/25 [===========>..................] - ETA: 19s  [ loss=0.1263 ][Evaluating] 10/25 [===========>..................] - ETA: 19s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.1140 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.1010 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 15s  [ loss=0.1243 ][Evaluating] 13/25 [==============>...............] - ETA: 15s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.1038 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.1786 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 11s  [ loss=0.1329 ][Evaluating] 16/25 [==================>...........] - ETA: 11s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.1272 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.1059 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 7s  [ loss=0.1314 ][Evaluating] 19/25 [=====================>........] - ETA: 7s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.0929 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.1396 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 3s  [ loss=0.1012 ][Evaluating] 22/25 [=========================>....] - ETA: 3s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.1172 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.1394 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.1091 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 11:15:52 - INFO - __main__ -   

03/21/2023 11:15:52 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 11:15:52 - INFO - __main__ -    acc: 0.7350 - recall: 0.7541 - f1: 0.7444 - loss: 0.1241 
03/21/2023 11:15:52 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 11:15:52 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:15:52 - INFO - __main__ -    acc: 0.7993 - recall: 0.8467 - f1: 0.8223 
03/21/2023 11:15:52 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:15:52 - INFO - __main__ -    acc: 0.4500 - recall: 0.4091 - f1: 0.4286 
03/21/2023 11:15:52 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:15:52 - INFO - __main__ -    acc: 0.6040 - recall: 0.6113 - f1: 0.6076 
03/21/2023 11:15:52 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:15:52 - INFO - __main__ -    acc: 0.8287 - recall: 0.8678 - f1: 0.8478 
03/21/2023 11:15:54 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-1000
03/21/2023 11:15:56 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/checkpoint-1000
03/21/2023 11:15:56 - INFO - __main__ -   

03/21/2023 11:15:56 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 11:16:15 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.0001_beta0.0001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr1e-4_clr1e-4_uncased_cd0.2_last/
03/21/2023 11:16:17 - INFO - __main__ -   Test on best eval model
03/21/2023 11:16:19 - INFO - __main__ -   ***** Running evaluation test best *****
03/21/2023 11:16:19 - INFO - __main__ -     Num examples = 3257
03/21/2023 11:16:19 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/81 [..............................] - ETA: 2:14  [ loss=0.1390 ][Evaluating] 1/81 [..............................] - ETA: 2:15[Evaluating] 2/81 [..............................] - ETA: 2:02  [ loss=0.1138 ][Evaluating] 2/81 [..............................] - ETA: 2:03[Evaluating] 3/81 [>.............................] - ETA: 1:55  [ loss=0.1416 ][Evaluating] 3/81 [>.............................] - ETA: 1:55[Evaluating] 4/81 [>.............................] - ETA: 1:53  [ loss=0.1033 ][Evaluating] 4/81 [>.............................] - ETA: 1:54[Evaluating] 5/81 [>.............................] - ETA: 1:51  [ loss=0.0973 ][Evaluating] 5/81 [>.............................] - ETA: 1:51[Evaluating] 6/81 [=>............................] - ETA: 1:49  [ loss=0.1422 ][Evaluating] 6/81 [=>............................] - ETA: 1:49[Evaluating] 7/81 [=>............................] - ETA: 1:47  [ loss=0.1630 ][Evaluating] 7/81 [=>............................] - ETA: 1:47[Evaluating] 8/81 [=>............................] - ETA: 1:48  [ loss=0.0934 ][Evaluating] 8/81 [=>............................] - ETA: 1:48[Evaluating] 9/81 [==>...........................] - ETA: 1:44  [ loss=0.1226 ][Evaluating] 9/81 [==>...........................] - ETA: 1:49[Evaluating] 10/81 [==>...........................] - ETA: 1:46  [ loss=0.1207 ][Evaluating] 10/81 [==>...........................] - ETA: 1:46[Evaluating] 11/81 [===>..........................] - ETA: 1:45  [ loss=0.1617 ][Evaluating] 11/81 [===>..........................] - ETA: 1:45[Evaluating] 12/81 [===>..........................] - ETA: 1:43  [ loss=0.1450 ][Evaluating] 12/81 [===>..........................] - ETA: 1:43[Evaluating] 13/81 [===>..........................] - ETA: 1:44  [ loss=0.1116 ][Evaluating] 13/81 [===>..........................] - ETA: 1:44[Evaluating] 14/81 [====>.........................] - ETA: 1:42  [ loss=0.1428 ][Evaluating] 14/81 [====>.........................] - ETA: 1:42[Evaluating] 15/81 [====>.........................] - ETA: 1:40  [ loss=0.1015 ][Evaluating] 15/81 [====>.........................] - ETA: 1:40[Evaluating] 16/81 [====>.........................] - ETA: 1:37  [ loss=0.1303 ][Evaluating] 16/81 [====>.........................] - ETA: 1:37[Evaluating] 17/81 [=====>........................] - ETA: 1:35  [ loss=0.1490 ][Evaluating] 17/81 [=====>........................] - ETA: 1:35[Evaluating] 18/81 [=====>........................] - ETA: 1:33  [ loss=0.0999 ][Evaluating] 18/81 [=====>........................] - ETA: 1:33[Evaluating] 19/81 [======>.......................] - ETA: 1:31  [ loss=0.1320 ][Evaluating] 19/81 [======>.......................] - ETA: 1:31[Evaluating] 20/81 [======>.......................] - ETA: 1:29  [ loss=0.0999 ][Evaluating] 20/81 [======>.......................] - ETA: 1:29[Evaluating] 21/81 [======>.......................] - ETA: 1:27  [ loss=0.1306 ][Evaluating] 21/81 [======>.......................] - ETA: 1:27[Evaluating] 22/81 [=======>......................] - ETA: 1:25  [ loss=0.1489 ][Evaluating] 22/81 [=======>......................] - ETA: 1:25[Evaluating] 23/81 [=======>......................] - ETA: 1:23  [ loss=0.0869 ][Evaluating] 23/81 [=======>......................] - ETA: 1:23[Evaluating] 24/81 [=======>......................] - ETA: 1:21  [ loss=0.1648 ][Evaluating] 24/81 [=======>......................] - ETA: 1:21[Evaluating] 25/81 [========>.....................] - ETA: 1:20  [ loss=0.1188 ][Evaluating] 25/81 [========>.....................] - ETA: 1:20[Evaluating] 26/81 [========>.....................] - ETA: 1:18  [ loss=0.1217 ][Evaluating] 26/81 [========>.....................] - ETA: 1:18[Evaluating] 27/81 [=========>....................] - ETA: 1:16  [ loss=0.1144 ][Evaluating] 27/81 [=========>....................] - ETA: 1:16[Evaluating] 28/81 [=========>....................] - ETA: 1:15  [ loss=0.1205 ][Evaluating] 28/81 [=========>....................] - ETA: 1:15[Evaluating] 29/81 [=========>....................] - ETA: 1:13  [ loss=0.1083 ][Evaluating] 29/81 [=========>....................] - ETA: 1:13[Evaluating] 30/81 [==========>...................] - ETA: 1:12  [ loss=0.1215 ][Evaluating] 30/81 [==========>...................] - ETA: 1:12[Evaluating] 31/81 [==========>...................] - ETA: 1:10  [ loss=0.1184 ][Evaluating] 31/81 [==========>...................] - ETA: 1:10[Evaluating] 32/81 [==========>...................] - ETA: 1:08  [ loss=0.0782 ][Evaluating] 32/81 [==========>...................] - ETA: 1:08[Evaluating] 33/81 [===========>..................] - ETA: 1:07  [ loss=0.0994 ][Evaluating] 33/81 [===========>..................] - ETA: 1:07[Evaluating] 34/81 [===========>..................] - ETA: 1:05  [ loss=0.1206 ][Evaluating] 34/81 [===========>..................] - ETA: 1:05[Evaluating] 35/81 [===========>..................] - ETA: 1:04  [ loss=0.1573 ][Evaluating] 35/81 [===========>..................] - ETA: 1:04[Evaluating] 36/81 [============>.................] - ETA: 1:02  [ loss=0.1385 ][Evaluating] 36/81 [============>.................] - ETA: 1:02[Evaluating] 37/81 [============>.................] - ETA: 1:01  [ loss=0.1471 ][Evaluating] 37/81 [============>.................] - ETA: 1:01[Evaluating] 38/81 [=============>................] - ETA: 59s  [ loss=0.1137 ][Evaluating] 38/81 [=============>................] - ETA: 59s[Evaluating] 39/81 [=============>................] - ETA: 58s  [ loss=0.1539 ][Evaluating] 39/81 [=============>................] - ETA: 58s[Evaluating] 40/81 [=============>................] - ETA: 57s  [ loss=0.1131 ][Evaluating] 40/81 [=============>................] - ETA: 57s[Evaluating] 41/81 [==============>...............] - ETA: 55s  [ loss=0.0870 ][Evaluating] 41/81 [==============>...............] - ETA: 55s[Evaluating] 42/81 [==============>...............] - ETA: 54s  [ loss=0.1207 ][Evaluating] 42/81 [==============>...............] - ETA: 54s[Evaluating] 43/81 [==============>...............] - ETA: 52s  [ loss=0.1368 ][Evaluating] 43/81 [==============>...............] - ETA: 52s[Evaluating] 44/81 [===============>..............] - ETA: 51s  [ loss=0.0844 ][Evaluating] 44/81 [===============>..............] - ETA: 51s[Evaluating] 45/81 [===============>..............] - ETA: 49s  [ loss=0.1140 ][Evaluating] 45/81 [===============>..............] - ETA: 49s[Evaluating] 46/81 [================>.............] - ETA: 48s  [ loss=0.1181 ][Evaluating] 46/81 [================>.............] - ETA: 48s[Evaluating] 47/81 [================>.............] - ETA: 46s  [ loss=0.1192 ][Evaluating] 47/81 [================>.............] - ETA: 47s[Evaluating] 48/81 [================>.............] - ETA: 45s  [ loss=0.1150 ][Evaluating] 48/81 [================>.............] - ETA: 45s[Evaluating] 49/81 [=================>............] - ETA: 44s  [ loss=0.1052 ][Evaluating] 49/81 [=================>............] - ETA: 44s[Evaluating] 50/81 [=================>............] - ETA: 42s  [ loss=0.1130 ][Evaluating] 50/81 [=================>............] - ETA: 42s[Evaluating] 51/81 [=================>............] - ETA: 41s  [ loss=0.1743 ][Evaluating] 51/81 [=================>............] - ETA: 41s[Evaluating] 52/81 [==================>...........] - ETA: 40s  [ loss=0.0840 ][Evaluating] 52/81 [==================>...........] - ETA: 40s[Evaluating] 53/81 [==================>...........] - ETA: 38s  [ loss=0.1460 ][Evaluating] 53/81 [==================>...........] - ETA: 38s[Evaluating] 54/81 [===================>..........] - ETA: 37s  [ loss=0.1283 ][Evaluating] 54/81 [===================>..........] - ETA: 37s[Evaluating] 55/81 [===================>..........] - ETA: 36s  [ loss=0.1208 ][Evaluating] 55/81 [===================>..........] - ETA: 36s[Evaluating] 56/81 [===================>..........] - ETA: 34s  [ loss=0.1116 ][Evaluating] 56/81 [===================>..........] - ETA: 34s[Evaluating] 57/81 [====================>.........] - ETA: 33s  [ loss=0.1219 ][Evaluating] 57/81 [====================>.........] - ETA: 33s[Evaluating] 58/81 [====================>.........] - ETA: 31s  [ loss=0.1007 ][Evaluating] 58/81 [====================>.........] - ETA: 31s[Evaluating] 59/81 [====================>.........] - ETA: 30s  [ loss=0.1501 ][Evaluating] 59/81 [====================>.........] - ETA: 30s[Evaluating] 60/81 [=====================>........] - ETA: 28s  [ loss=0.0987 ][Evaluating] 60/81 [=====================>........] - ETA: 28s[Evaluating] 61/81 [=====================>........] - ETA: 27s  [ loss=0.1278 ][Evaluating] 61/81 [=====================>........] - ETA: 27s[Evaluating] 62/81 [=====================>........] - ETA: 26s  [ loss=0.1108 ][Evaluating] 62/81 [=====================>........] - ETA: 26s[Evaluating] 63/81 [======================>.......] - ETA: 24s  [ loss=0.1184 ][Evaluating] 63/81 [======================>.......] - ETA: 24s[Evaluating] 64/81 [======================>.......] - ETA: 23s  [ loss=0.0690 ][Evaluating] 64/81 [======================>.......] - ETA: 23s[Evaluating] 65/81 [=======================>......] - ETA: 21s  [ loss=0.1438 ][Evaluating] 65/81 [=======================>......] - ETA: 21s[Evaluating] 66/81 [=======================>......] - ETA: 20s  [ loss=0.1255 ][Evaluating] 66/81 [=======================>......] - ETA: 20s[Evaluating] 67/81 [=======================>......] - ETA: 19s  [ loss=0.1347 ][Evaluating] 67/81 [=======================>......] - ETA: 19s[Evaluating] 68/81 [========================>.....] - ETA: 17s  [ loss=0.0979 ][Evaluating] 68/81 [========================>.....] - ETA: 17s[Evaluating] 69/81 [========================>.....] - ETA: 16s  [ loss=0.0941 ][Evaluating] 69/81 [========================>.....] - ETA: 16s[Evaluating] 70/81 [========================>.....] - ETA: 15s  [ loss=0.1281 ][Evaluating] 70/81 [========================>.....] - ETA: 15s[Evaluating] 71/81 [=========================>....] - ETA: 13s  [ loss=0.1513 ][Evaluating] 71/81 [=========================>....] - ETA: 13s[Evaluating] 72/81 [=========================>....] - ETA: 12s  [ loss=0.1922 ][Evaluating] 72/81 [=========================>....] - ETA: 12s[Evaluating] 73/81 [==========================>...] - ETA: 10s  [ loss=0.1117 ][Evaluating] 73/81 [==========================>...] - ETA: 10s[Evaluating] 74/81 [==========================>...] - ETA: 9s  [ loss=0.1007 ][Evaluating] 74/81 [==========================>...] - ETA: 9s[Evaluating] 75/81 [==========================>...] - ETA: 8s  [ loss=0.1499 ][Evaluating] 75/81 [==========================>...] - ETA: 8s[Evaluating] 76/81 [===========================>..] - ETA: 6s  [ loss=0.1382 ][Evaluating] 76/81 [===========================>..] - ETA: 6s[Evaluating] 77/81 [===========================>..] - ETA: 5s  [ loss=0.1107 ][Evaluating] 77/81 [===========================>..] - ETA: 5s[Evaluating] 78/81 [===========================>..] - ETA: 4s  [ loss=0.0735 ][Evaluating] 78/81 [===========================>..] - ETA: 4s[Evaluating] 79/81 [============================>.] - ETA: 2s  [ loss=0.1156 ][Evaluating] 79/81 [============================>.] - ETA: 2s[Evaluating] 80/81 [============================>.] - ETA: 1s  [ loss=0.1305 ][Evaluating] 80/81 [============================>.] - ETA: 1s[Evaluating] 81/81 [==============================] 1.4s/step  [ loss=0.1055 ]
[Evaluating] 81/81 [==============================] 1.4s/step
03/21/2023 11:18:10 - INFO - __main__ -   

03/21/2023 11:18:10 - INFO - __main__ -   ***** Eval results test best *****
03/21/2023 11:18:10 - INFO - __main__ -    acc: 0.7367 - recall: 0.7606 - f1: 0.7485 - loss: 0.1218 
03/21/2023 11:18:10 - INFO - __main__ -   ***** Entity results test best *****
03/21/2023 11:18:10 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:18:10 - INFO - __main__ -    acc: 0.8032 - recall: 0.8528 - f1: 0.8273 
03/21/2023 11:18:10 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:18:10 - INFO - __main__ -    acc: 0.3995 - recall: 0.4208 - f1: 0.4098 
03/21/2023 11:18:10 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:18:10 - INFO - __main__ -    acc: 0.6421 - recall: 0.5945 - f1: 0.6174 
03/21/2023 11:18:10 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:18:10 - INFO - __main__ -    acc: 0.8468 - recall: 0.8857 - f1: 0.8658 
03/21/2023 11:18:10 - INFO - __main__ -   Test on best eval loss model
03/21/2023 11:18:12 - INFO - __main__ -   ***** Running evaluation test best_loss *****
03/21/2023 11:18:12 - INFO - __main__ -     Num examples = 3257
03/21/2023 11:18:12 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/81 [..............................] - ETA: 1:46  [ loss=0.0966 ][Evaluating] 1/81 [..............................] - ETA: 1:47[Evaluating] 2/81 [..............................] - ETA: 1:43  [ loss=0.0748 ][Evaluating] 2/81 [..............................] - ETA: 1:43[Evaluating] 3/81 [>.............................] - ETA: 1:42  [ loss=0.0863 ][Evaluating] 3/81 [>.............................] - ETA: 1:42[Evaluating] 4/81 [>.............................] - ETA: 1:40  [ loss=0.0694 ][Evaluating] 4/81 [>.............................] - ETA: 1:41[Evaluating] 5/81 [>.............................] - ETA: 1:39  [ loss=0.0763 ][Evaluating] 5/81 [>.............................] - ETA: 1:39[Evaluating] 6/81 [=>............................] - ETA: 1:38  [ loss=0.0999 ][Evaluating] 6/81 [=>............................] - ETA: 1:38[Evaluating] 7/81 [=>............................] - ETA: 1:37  [ loss=0.1085 ][Evaluating] 7/81 [=>............................] - ETA: 1:37[Evaluating] 8/81 [=>............................] - ETA: 1:36  [ loss=0.0690 ][Evaluating] 8/81 [=>............................] - ETA: 1:36[Evaluating] 9/81 [==>...........................] - ETA: 1:35  [ loss=0.0797 ][Evaluating] 9/81 [==>...........................] - ETA: 1:35[Evaluating] 10/81 [==>...........................] - ETA: 1:34  [ loss=0.0845 ][Evaluating] 10/81 [==>...........................] - ETA: 1:34[Evaluating] 11/81 [===>..........................] - ETA: 1:33  [ loss=0.1002 ][Evaluating] 11/81 [===>..........................] - ETA: 1:33[Evaluating] 12/81 [===>..........................] - ETA: 1:31  [ loss=0.0961 ][Evaluating] 12/81 [===>..........................] - ETA: 1:31[Evaluating] 13/81 [===>..........................] - ETA: 1:30  [ loss=0.0697 ][Evaluating] 13/81 [===>..........................] - ETA: 1:30[Evaluating] 14/81 [====>.........................] - ETA: 1:29  [ loss=0.1020 ][Evaluating] 14/81 [====>.........................] - ETA: 1:29[Evaluating] 15/81 [====>.........................] - ETA: 1:27  [ loss=0.0671 ][Evaluating] 15/81 [====>.........................] - ETA: 1:27[Evaluating] 16/81 [====>.........................] - ETA: 1:26  [ loss=0.0834 ][Evaluating] 16/81 [====>.........................] - ETA: 1:26[Evaluating] 17/81 [=====>........................] - ETA: 1:24  [ loss=0.0947 ][Evaluating] 17/81 [=====>........................] - ETA: 1:25[Evaluating] 18/81 [=====>........................] - ETA: 1:23  [ loss=0.0688 ][Evaluating] 18/81 [=====>........................] - ETA: 1:23[Evaluating] 19/81 [======>.......................] - ETA: 1:22  [ loss=0.0880 ][Evaluating] 19/81 [======>.......................] - ETA: 1:22[Evaluating] 20/81 [======>.......................] - ETA: 1:21  [ loss=0.0778 ][Evaluating] 20/81 [======>.......................] - ETA: 1:21[Evaluating] 21/81 [======>.......................] - ETA: 1:20  [ loss=0.0926 ][Evaluating] 21/81 [======>.......................] - ETA: 1:20[Evaluating] 22/81 [=======>......................] - ETA: 1:19  [ loss=0.0860 ][Evaluating] 22/81 [=======>......................] - ETA: 1:19[Evaluating] 23/81 [=======>......................] - ETA: 1:17  [ loss=0.0862 ][Evaluating] 23/81 [=======>......................] - ETA: 1:17[Evaluating] 24/81 [=======>......................] - ETA: 1:16  [ loss=0.0984 ][Evaluating] 24/81 [=======>......................] - ETA: 1:16[Evaluating] 25/81 [========>.....................] - ETA: 1:15  [ loss=0.0715 ][Evaluating] 25/81 [========>.....................] - ETA: 1:15[Evaluating] 26/81 [========>.....................] - ETA: 1:13  [ loss=0.0770 ][Evaluating] 26/81 [========>.....................] - ETA: 1:13[Evaluating] 27/81 [=========>....................] - ETA: 1:12  [ loss=0.0797 ][Evaluating] 27/81 [=========>....................] - ETA: 1:12[Evaluating] 28/81 [=========>....................] - ETA: 1:10  [ loss=0.0804 ][Evaluating] 28/81 [=========>....................] - ETA: 1:10[Evaluating] 29/81 [=========>....................] - ETA: 1:09  [ loss=0.0846 ][Evaluating] 29/81 [=========>....................] - ETA: 1:09[Evaluating] 30/81 [==========>...................] - ETA: 1:08  [ loss=0.0866 ][Evaluating] 30/81 [==========>...................] - ETA: 1:08[Evaluating] 31/81 [==========>...................] - ETA: 1:06  [ loss=0.0777 ][Evaluating] 31/81 [==========>...................] - ETA: 1:06[Evaluating] 32/81 [==========>...................] - ETA: 1:05  [ loss=0.0707 ][Evaluating] 32/81 [==========>...................] - ETA: 1:05[Evaluating] 33/81 [===========>..................] - ETA: 1:04  [ loss=0.0730 ][Evaluating] 33/81 [===========>..................] - ETA: 1:04[Evaluating] 34/81 [===========>..................] - ETA: 1:02  [ loss=0.0848 ][Evaluating] 34/81 [===========>..................] - ETA: 1:02[Evaluating] 35/81 [===========>..................] - ETA: 1:01  [ loss=0.0899 ][Evaluating] 35/81 [===========>..................] - ETA: 1:01[Evaluating] 36/81 [============>.................] - ETA: 1:00  [ loss=0.0969 ][Evaluating] 36/81 [============>.................] - ETA: 1:00[Evaluating] 37/81 [============>.................] - ETA: 58s  [ loss=0.0853 ][Evaluating] 37/81 [============>.................] - ETA: 58s[Evaluating] 38/81 [=============>................] - ETA: 57s  [ loss=0.0871 ][Evaluating] 38/81 [=============>................] - ETA: 57s[Evaluating] 39/81 [=============>................] - ETA: 55s  [ loss=0.0890 ][Evaluating] 39/81 [=============>................] - ETA: 55s[Evaluating] 40/81 [=============>................] - ETA: 54s  [ loss=0.0813 ][Evaluating] 40/81 [=============>................] - ETA: 54s[Evaluating] 41/81 [==============>...............] - ETA: 53s  [ loss=0.0807 ][Evaluating] 41/81 [==============>...............] - ETA: 53s[Evaluating] 42/81 [==============>...............] - ETA: 51s  [ loss=0.0911 ][Evaluating] 42/81 [==============>...............] - ETA: 51s[Evaluating] 43/81 [==============>...............] - ETA: 50s  [ loss=0.0983 ][Evaluating] 43/81 [==============>...............] - ETA: 50s[Evaluating] 44/81 [===============>..............] - ETA: 49s  [ loss=0.0577 ][Evaluating] 44/81 [===============>..............] - ETA: 49s[Evaluating] 45/81 [===============>..............] - ETA: 47s  [ loss=0.0691 ][Evaluating] 45/81 [===============>..............] - ETA: 47s[Evaluating] 46/81 [================>.............] - ETA: 46s  [ loss=0.0798 ][Evaluating] 46/81 [================>.............] - ETA: 46s[Evaluating] 47/81 [================>.............] - ETA: 45s  [ loss=0.0808 ][Evaluating] 47/81 [================>.............] - ETA: 45s[Evaluating] 48/81 [================>.............] - ETA: 44s  [ loss=0.0850 ][Evaluating] 48/81 [================>.............] - ETA: 44s[Evaluating] 49/81 [=================>............] - ETA: 42s  [ loss=0.0802 ][Evaluating] 49/81 [=================>............] - ETA: 42s[Evaluating] 50/81 [=================>............] - ETA: 41s  [ loss=0.0774 ][Evaluating] 50/81 [=================>............] - ETA: 41s[Evaluating] 51/81 [=================>............] - ETA: 40s  [ loss=0.1070 ][Evaluating] 51/81 [=================>............] - ETA: 40s[Evaluating] 52/81 [==================>...........] - ETA: 39s  [ loss=0.0717 ][Evaluating] 52/81 [==================>...........] - ETA: 39s[Evaluating] 53/81 [==================>...........] - ETA: 37s  [ loss=0.0748 ][Evaluating] 53/81 [==================>...........] - ETA: 37s[Evaluating] 54/81 [===================>..........] - ETA: 36s  [ loss=0.0818 ][Evaluating] 54/81 [===================>..........] - ETA: 36s[Evaluating] 55/81 [===================>..........] - ETA: 35s  [ loss=0.0846 ][Evaluating] 55/81 [===================>..........] - ETA: 35s[Evaluating] 56/81 [===================>..........] - ETA: 33s  [ loss=0.0870 ][Evaluating] 56/81 [===================>..........] - ETA: 33s[Evaluating] 57/81 [====================>.........] - ETA: 32s  [ loss=0.0781 ][Evaluating] 57/81 [====================>.........] - ETA: 32s[Evaluating] 58/81 [====================>.........] - ETA: 31s  [ loss=0.0681 ][Evaluating] 58/81 [====================>.........] - ETA: 31s[Evaluating] 59/81 [====================>.........] - ETA: 29s  [ loss=0.0819 ][Evaluating] 59/81 [====================>.........] - ETA: 29s[Evaluating] 60/81 [=====================>........] - ETA: 28s  [ loss=0.0767 ][Evaluating] 60/81 [=====================>........] - ETA: 28s[Evaluating] 61/81 [=====================>........] - ETA: 27s  [ loss=0.0925 ][Evaluating] 61/81 [=====================>........] - ETA: 27s[Evaluating] 62/81 [=====================>........] - ETA: 25s  [ loss=0.0888 ][Evaluating] 62/81 [=====================>........] - ETA: 25s[Evaluating] 63/81 [======================>.......] - ETA: 24s  [ loss=0.0748 ][Evaluating] 63/81 [======================>.......] - ETA: 24s[Evaluating] 64/81 [======================>.......] - ETA: 23s  [ loss=0.0569 ][Evaluating] 64/81 [======================>.......] - ETA: 23s[Evaluating] 65/81 [=======================>......] - ETA: 21s  [ loss=0.0869 ][Evaluating] 65/81 [=======================>......] - ETA: 21s[Evaluating] 66/81 [=======================>......] - ETA: 20s  [ loss=0.0864 ][Evaluating] 66/81 [=======================>......] - ETA: 20s[Evaluating] 67/81 [=======================>......] - ETA: 18s  [ loss=0.0801 ][Evaluating] 67/81 [=======================>......] - ETA: 18s[Evaluating] 68/81 [========================>.....] - ETA: 17s  [ loss=0.0772 ][Evaluating] 68/81 [========================>.....] - ETA: 17s[Evaluating] 69/81 [========================>.....] - ETA: 16s  [ loss=0.0695 ][Evaluating] 69/81 [========================>.....] - ETA: 16s[Evaluating] 70/81 [========================>.....] - ETA: 14s  [ loss=0.0835 ][Evaluating] 70/81 [========================>.....] - ETA: 14s[Evaluating] 71/81 [=========================>....] - ETA: 13s  [ loss=0.1081 ][Evaluating] 71/81 [=========================>....] - ETA: 13s[Evaluating] 72/81 [=========================>....] - ETA: 12s  [ loss=0.1107 ][Evaluating] 72/81 [=========================>....] - ETA: 12s[Evaluating] 73/81 [==========================>...] - ETA: 10s  [ loss=0.0853 ][Evaluating] 73/81 [==========================>...] - ETA: 10s[Evaluating] 74/81 [==========================>...] - ETA: 9s  [ loss=0.0792 ][Evaluating] 74/81 [==========================>...] - ETA: 9s[Evaluating] 75/81 [==========================>...] - ETA: 8s  [ loss=0.0920 ][Evaluating] 75/81 [==========================>...] - ETA: 8s[Evaluating] 76/81 [===========================>..] - ETA: 6s  [ loss=0.0824 ][Evaluating] 76/81 [===========================>..] - ETA: 6s[Evaluating] 77/81 [===========================>..] - ETA: 5s  [ loss=0.0750 ][Evaluating] 77/81 [===========================>..] - ETA: 5s[Evaluating] 78/81 [===========================>..] - ETA: 4s  [ loss=0.0569 ][Evaluating] 78/81 [===========================>..] - ETA: 4s[Evaluating] 79/81 [============================>.] - ETA: 2s  [ loss=0.0786 ][Evaluating] 79/81 [============================>.] - ETA: 2s[Evaluating] 80/81 [============================>.] - ETA: 1s  [ loss=0.0813 ][Evaluating] 80/81 [============================>.] - ETA: 1s[Evaluating] 81/81 [==============================] 1.3s/step  [ loss=0.0767 ]
[Evaluating] 81/81 [==============================] 1.3s/step
03/21/2023 11:20:01 - INFO - __main__ -   

03/21/2023 11:20:01 - INFO - __main__ -   ***** Eval results test best_loss *****
03/21/2023 11:20:01 - INFO - __main__ -    acc: 0.7431 - recall: 0.7298 - f1: 0.7364 - loss: 0.0828 
03/21/2023 11:20:01 - INFO - __main__ -   ***** Entity results test best_loss *****
03/21/2023 11:20:01 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:20:01 - INFO - __main__ -    acc: 0.7487 - recall: 0.8682 - f1: 0.8041 
03/21/2023 11:20:01 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:20:01 - INFO - __main__ -    acc: 0.4172 - recall: 0.2651 - f1: 0.3242 
03/21/2023 11:20:01 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:20:01 - INFO - __main__ -    acc: 0.6863 - recall: 0.5443 - f1: 0.6071 
03/21/2023 11:20:01 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:20:01 - INFO - __main__ -    acc: 0.8359 - recall: 0.8702 - f1: 0.8527 
03/21/2023 11:20:01 - INFO - __main__ -   Test on last eval model
03/21/2023 11:20:02 - INFO - __main__ -   ***** Running evaluation test last *****
03/21/2023 11:20:02 - INFO - __main__ -     Num examples = 3257
03/21/2023 11:20:02 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/81 [..............................] - ETA: 1:50  [ loss=0.1425 ][Evaluating] 1/81 [..............................] - ETA: 1:51[Evaluating] 2/81 [..............................] - ETA: 1:45  [ loss=0.1124 ][Evaluating] 2/81 [..............................] - ETA: 1:45[Evaluating] 3/81 [>.............................] - ETA: 1:42  [ loss=0.1446 ][Evaluating] 3/81 [>.............................] - ETA: 1:43[Evaluating] 4/81 [>.............................] - ETA: 1:42  [ loss=0.1036 ][Evaluating] 4/81 [>.............................] - ETA: 1:43[Evaluating] 5/81 [>.............................] - ETA: 1:41  [ loss=0.0987 ][Evaluating] 5/81 [>.............................] - ETA: 1:41[Evaluating] 6/81 [=>............................] - ETA: 1:40  [ loss=0.1415 ][Evaluating] 6/81 [=>............................] - ETA: 1:40[Evaluating] 7/81 [=>............................] - ETA: 1:39  [ loss=0.1668 ][Evaluating] 7/81 [=>............................] - ETA: 1:39[Evaluating] 8/81 [=>............................] - ETA: 1:38  [ loss=0.0928 ][Evaluating] 8/81 [=>............................] - ETA: 1:38[Evaluating] 9/81 [==>...........................] - ETA: 1:36  [ loss=0.1191 ][Evaluating] 9/81 [==>...........................] - ETA: 1:36[Evaluating] 10/81 [==>...........................] - ETA: 1:35  [ loss=0.1216 ][Evaluating] 10/81 [==>...........................] - ETA: 1:35[Evaluating] 11/81 [===>..........................] - ETA: 1:34  [ loss=0.1634 ][Evaluating] 11/81 [===>..........................] - ETA: 1:34[Evaluating] 12/81 [===>..........................] - ETA: 1:33  [ loss=0.1451 ][Evaluating] 12/81 [===>..........................] - ETA: 1:33[Evaluating] 13/81 [===>..........................] - ETA: 1:31  [ loss=0.1125 ][Evaluating] 13/81 [===>..........................] - ETA: 1:31[Evaluating] 14/81 [====>.........................] - ETA: 1:30  [ loss=0.1455 ][Evaluating] 14/81 [====>.........................] - ETA: 1:30[Evaluating] 15/81 [====>.........................] - ETA: 1:28  [ loss=0.0998 ][Evaluating] 15/81 [====>.........................] - ETA: 1:28[Evaluating] 16/81 [====>.........................] - ETA: 1:26  [ loss=0.1304 ][Evaluating] 16/81 [====>.........................] - ETA: 1:26[Evaluating] 17/81 [=====>........................] - ETA: 1:25  [ loss=0.1514 ][Evaluating] 17/81 [=====>........................] - ETA: 1:25[Evaluating] 18/81 [=====>........................] - ETA: 1:24  [ loss=0.0979 ][Evaluating] 18/81 [=====>........................] - ETA: 1:24[Evaluating] 19/81 [======>.......................] - ETA: 1:23  [ loss=0.1330 ][Evaluating] 19/81 [======>.......................] - ETA: 1:23[Evaluating] 20/81 [======>.......................] - ETA: 1:21  [ loss=0.1021 ][Evaluating] 20/81 [======>.......................] - ETA: 1:21[Evaluating] 21/81 [======>.......................] - ETA: 1:20  [ loss=0.1311 ][Evaluating] 21/81 [======>.......................] - ETA: 1:20[Evaluating] 22/81 [=======>......................] - ETA: 1:18  [ loss=0.1523 ][Evaluating] 22/81 [=======>......................] - ETA: 1:19[Evaluating] 23/81 [=======>......................] - ETA: 1:17  [ loss=0.0880 ][Evaluating] 23/81 [=======>......................] - ETA: 1:17[Evaluating] 24/81 [=======>......................] - ETA: 1:16  [ loss=0.1671 ][Evaluating] 24/81 [=======>......................] - ETA: 1:16[Evaluating] 25/81 [========>.....................] - ETA: 1:14  [ loss=0.1221 ][Evaluating] 25/81 [========>.....................] - ETA: 1:14[Evaluating] 26/81 [========>.....................] - ETA: 1:13  [ loss=0.1208 ][Evaluating] 26/81 [========>.....................] - ETA: 1:13[Evaluating] 27/81 [=========>....................] - ETA: 1:12  [ loss=0.1169 ][Evaluating] 27/81 [=========>....................] - ETA: 1:12[Evaluating] 28/81 [=========>....................] - ETA: 1:11  [ loss=0.1220 ][Evaluating] 28/81 [=========>....................] - ETA: 1:11[Evaluating] 29/81 [=========>....................] - ETA: 1:09  [ loss=0.1096 ][Evaluating] 29/81 [=========>....................] - ETA: 1:09[Evaluating] 30/81 [==========>...................] - ETA: 1:08  [ loss=0.1224 ][Evaluating] 30/81 [==========>...................] - ETA: 1:08[Evaluating] 31/81 [==========>...................] - ETA: 1:06  [ loss=0.1237 ][Evaluating] 31/81 [==========>...................] - ETA: 1:06[Evaluating] 32/81 [==========>...................] - ETA: 1:05  [ loss=0.0794 ][Evaluating] 32/81 [==========>...................] - ETA: 1:05[Evaluating] 33/81 [===========>..................] - ETA: 1:04  [ loss=0.1022 ][Evaluating] 33/81 [===========>..................] - ETA: 1:04[Evaluating] 34/81 [===========>..................] - ETA: 1:02  [ loss=0.1192 ][Evaluating] 34/81 [===========>..................] - ETA: 1:02[Evaluating] 35/81 [===========>..................] - ETA: 1:01  [ loss=0.1586 ][Evaluating] 35/81 [===========>..................] - ETA: 1:01[Evaluating] 36/81 [============>.................] - ETA: 59s  [ loss=0.1429 ][Evaluating] 36/81 [============>.................] - ETA: 59s[Evaluating] 37/81 [============>.................] - ETA: 58s  [ loss=0.1552 ][Evaluating] 37/81 [============>.................] - ETA: 58s[Evaluating] 38/81 [=============>................] - ETA: 57s  [ loss=0.1148 ][Evaluating] 38/81 [=============>................] - ETA: 57s[Evaluating] 39/81 [=============>................] - ETA: 55s  [ loss=0.1561 ][Evaluating] 39/81 [=============>................] - ETA: 55s[Evaluating] 40/81 [=============>................] - ETA: 54s  [ loss=0.1152 ][Evaluating] 40/81 [=============>................] - ETA: 54s[Evaluating] 41/81 [==============>...............] - ETA: 53s  [ loss=0.0863 ][Evaluating] 41/81 [==============>...............] - ETA: 53s[Evaluating] 42/81 [==============>...............] - ETA: 51s  [ loss=0.1232 ][Evaluating] 42/81 [==============>...............] - ETA: 51s[Evaluating] 43/81 [==============>...............] - ETA: 50s  [ loss=0.1354 ][Evaluating] 43/81 [==============>...............] - ETA: 50s[Evaluating] 44/81 [===============>..............] - ETA: 49s  [ loss=0.0858 ][Evaluating] 44/81 [===============>..............] - ETA: 49s[Evaluating] 45/81 [===============>..............] - ETA: 47s  [ loss=0.1159 ][Evaluating] 45/81 [===============>..............] - ETA: 47s[Evaluating] 46/81 [================>.............] - ETA: 46s  [ loss=0.1141 ][Evaluating] 46/81 [================>.............] - ETA: 46s[Evaluating] 47/81 [================>.............] - ETA: 45s  [ loss=0.1236 ][Evaluating] 47/81 [================>.............] - ETA: 45s[Evaluating] 48/81 [================>.............] - ETA: 43s  [ loss=0.1179 ][Evaluating] 48/81 [================>.............] - ETA: 43s[Evaluating] 49/81 [=================>............] - ETA: 42s  [ loss=0.1082 ][Evaluating] 49/81 [=================>............] - ETA: 42s[Evaluating] 50/81 [=================>............] - ETA: 41s  [ loss=0.1108 ][Evaluating] 50/81 [=================>............] - ETA: 41s[Evaluating] 51/81 [=================>............] - ETA: 39s  [ loss=0.1795 ][Evaluating] 51/81 [=================>............] - ETA: 39s[Evaluating] 52/81 [==================>...........] - ETA: 38s  [ loss=0.0870 ][Evaluating] 52/81 [==================>...........] - ETA: 38s[Evaluating] 53/81 [==================>...........] - ETA: 37s  [ loss=0.1485 ][Evaluating] 53/81 [==================>...........] - ETA: 37s[Evaluating] 54/81 [===================>..........] - ETA: 35s  [ loss=0.1299 ][Evaluating] 54/81 [===================>..........] - ETA: 35s[Evaluating] 55/81 [===================>..........] - ETA: 34s  [ loss=0.1225 ][Evaluating] 55/81 [===================>..........] - ETA: 34s[Evaluating] 56/81 [===================>..........] - ETA: 33s  [ loss=0.1134 ][Evaluating] 56/81 [===================>..........] - ETA: 33s[Evaluating] 57/81 [====================>.........] - ETA: 31s  [ loss=0.1247 ][Evaluating] 57/81 [====================>.........] - ETA: 31s[Evaluating] 58/81 [====================>.........] - ETA: 30s  [ loss=0.1004 ][Evaluating] 58/81 [====================>.........] - ETA: 30s[Evaluating] 59/81 [====================>.........] - ETA: 29s  [ loss=0.1559 ][Evaluating] 59/81 [====================>.........] - ETA: 29s[Evaluating] 60/81 [=====================>........] - ETA: 27s  [ loss=0.0991 ][Evaluating] 60/81 [=====================>........] - ETA: 27s[Evaluating] 61/81 [=====================>........] - ETA: 26s  [ loss=0.1313 ][Evaluating] 61/81 [=====================>........] - ETA: 26s[Evaluating] 62/81 [=====================>........] - ETA: 25s  [ loss=0.1110 ][Evaluating] 62/81 [=====================>........] - ETA: 25s[Evaluating] 63/81 [======================>.......] - ETA: 23s  [ loss=0.1203 ][Evaluating] 63/81 [======================>.......] - ETA: 23s[Evaluating] 64/81 [======================>.......] - ETA: 22s  [ loss=0.0708 ][Evaluating] 64/81 [======================>.......] - ETA: 22s[Evaluating] 65/81 [=======================>......] - ETA: 21s  [ loss=0.1456 ][Evaluating] 65/81 [=======================>......] - ETA: 21s[Evaluating] 66/81 [=======================>......] - ETA: 19s  [ loss=0.1283 ][Evaluating] 66/81 [=======================>......] - ETA: 19s[Evaluating] 67/81 [=======================>......] - ETA: 18s  [ loss=0.1358 ][Evaluating] 67/81 [=======================>......] - ETA: 18s[Evaluating] 68/81 [========================>.....] - ETA: 17s  [ loss=0.0944 ][Evaluating] 68/81 [========================>.....] - ETA: 17s[Evaluating] 69/81 [========================>.....] - ETA: 15s  [ loss=0.0911 ][Evaluating] 69/81 [========================>.....] - ETA: 15s[Evaluating] 70/81 [========================>.....] - ETA: 14s  [ loss=0.1285 ][Evaluating] 70/81 [========================>.....] - ETA: 14s[Evaluating] 71/81 [=========================>....] - ETA: 13s  [ loss=0.1544 ][Evaluating] 71/81 [=========================>....] - ETA: 13s[Evaluating] 72/81 [=========================>....] - ETA: 11s  [ loss=0.1952 ][Evaluating] 72/81 [=========================>....] - ETA: 11s[Evaluating] 73/81 [==========================>...] - ETA: 10s  [ loss=0.1146 ][Evaluating] 73/81 [==========================>...] - ETA: 10s[Evaluating] 74/81 [==========================>...] - ETA: 9s  [ loss=0.1057 ][Evaluating] 74/81 [==========================>...] - ETA: 9s[Evaluating] 75/81 [==========================>...] - ETA: 7s  [ loss=0.1519 ][Evaluating] 75/81 [==========================>...] - ETA: 7s[Evaluating] 76/81 [===========================>..] - ETA: 6s  [ loss=0.1423 ][Evaluating] 76/81 [===========================>..] - ETA: 6s[Evaluating] 77/81 [===========================>..] - ETA: 5s  [ loss=0.1118 ][Evaluating] 77/81 [===========================>..] - ETA: 5s[Evaluating] 78/81 [===========================>..] - ETA: 3s  [ loss=0.0746 ][Evaluating] 78/81 [===========================>..] - ETA: 3s[Evaluating] 79/81 [============================>.] - ETA: 2s  [ loss=0.1170 ][Evaluating] 79/81 [============================>.] - ETA: 2s[Evaluating] 80/81 [============================>.] - ETA: 1s  [ loss=0.1290 ][Evaluating] 80/81 [============================>.] - ETA: 1s[Evaluating] 81/81 [==============================] 1.3s/step  [ loss=0.1075 ]
[Evaluating] 81/81 [==============================] 1.3s/step
03/21/2023 11:21:50 - INFO - __main__ -   

03/21/2023 11:21:50 - INFO - __main__ -   ***** Eval results test last *****
03/21/2023 11:21:50 - INFO - __main__ -    acc: 0.7398 - recall: 0.7604 - f1: 0.7500 - loss: 0.1233 
03/21/2023 11:21:50 - INFO - __main__ -   ***** Entity results test last *****
03/21/2023 11:21:50 - INFO - __main__ -   ******* LOC results ********
03/21/2023 11:21:50 - INFO - __main__ -    acc: 0.8046 - recall: 0.8552 - f1: 0.8291 
03/21/2023 11:21:50 - INFO - __main__ -   ******* MISC results ********
03/21/2023 11:21:50 - INFO - __main__ -    acc: 0.4091 - recall: 0.3913 - f1: 0.4000 
03/21/2023 11:21:50 - INFO - __main__ -   ******* ORG results ********
03/21/2023 11:21:50 - INFO - __main__ -    acc: 0.6276 - recall: 0.6208 - f1: 0.6242 
03/21/2023 11:21:50 - INFO - __main__ -   ******* PER results ********
03/21/2023 11:21:50 - INFO - __main__ -    acc: 0.8476 - recall: 0.8824 - f1: 0.8647 
