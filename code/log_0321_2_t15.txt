nohup: ignoring input
03/21/2023 16:46:52 - INFO - __main__ -   label_list: ['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'X', '[START]', '[END]'], length: 12
The number of samples: 4000
The number of images: 4000
The number of samples: 1000
The number of images: 1000
The number of samples: 3257
The number of images: 3257
03/21/2023 16:46:52 - INFO - root -   Constructing vocabulary for image caption
03/21/2023 16:46:53 - INFO - __main__ -    The size of vocabulary = 4736
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
03/21/2023 16:47:06 - INFO - __main__ -   Finish loading model [236M] parameters
03/21/2023 16:47:12 - INFO - __main__ -   Args: Namespace(adam_epsilon=1e-08, alpha=0.001, bert_type='uncased', beta=0.001, cls_init=0, crf_dropout=0.5, crf_learning_rate=5e-05, crop_size=224, cross_dropout=0.2, data_dir='../data/twitter2015', device=device(type='cuda'), do_eval=True, do_predict=False, do_train=True, drop_last=True, eval_all_checkpoints=False, evaluate_during_training=True, gradient_accumulation_steps=1, hidden_size=768, id2label={0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC', 9: 'X', 10: '[START]', 11: '[END]'}, image_dir='../data/twitter2015_images', image_dropout=0.0, label2id={'O': 0, 'B-MISC': 1, 'I-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-LOC': 7, 'I-LOC': 8, 'X': 9, '[START]': 10, '[END]': 11}, learning_rate=5e-05, load_image_checkpoint=False, load_text_checkpoint=False, local_rank=-1, logging_steps=100, markup='bio', max_grad_norm=1.0, max_seq_length=64, n_gpu=1, num_layers=6, num_train_epochs=10, num_workers=8, output_dir='../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/', per_gpu_eval_batch_size=40, per_gpu_train_batch_size=40, predict_checkpoints=0, replace_end=3, replace_start=1, resnet_pretrained_dir='../models/resnet152-b121ed2d.pth', save_steps=100, seed=42, sigma=1.0, skip_connection=True, task='twitter15', test_batch_size=1, text_dropout=0.0, theta=0.1, ti_crop_size=32, train_batch_size=40, use_quantile=True, use_xlmr=False, warmup_proportion=0.1, weight_decay=0.01)
03/21/2023 16:47:12 - INFO - __main__ -   Summary dir: ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/summary_1679388432
/home/ubuntu/.conda/envs/muse/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
03/21/2023 16:47:12 - INFO - __main__ -   ***** Running training *****
03/21/2023 16:47:12 - INFO - __main__ -     Num examples = 4000
03/21/2023 16:47:12 - INFO - __main__ -     Num Epochs = 10
03/21/2023 16:47:12 - INFO - __main__ -     Gradient Accumulation steps = 1
03/21/2023 16:47:12 - INFO - __main__ -     Total optimization steps = 1000

Epoch: 0/10
/home/ubuntu/multimodal-fusion/MuSE/code/models.py:1235: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:333.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
/home/ubuntu/.conda/envs/muse/lib/python3.7/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
[Training] 1/100 [..............................] - ETA: 5:43  [ loss=2.2219 ][Training] 2/100 [..............................] - ETA: 5:01  [ loss=2.1839 ][Training] 3/100 [..............................] - ETA: 4:16  [ loss=2.1798 ][Training] 4/100 [>.............................] - ETA: 3:53  [ loss=2.2255 ][Training] 5/100 [>.............................] - ETA: 3:39  [ loss=2.0944 ][Training] 6/100 [>.............................] - ETA: 3:30  [ loss=2.0746 ][Training] 7/100 [=>............................] - ETA: 3:24  [ loss=2.0030 ][Training] 8/100 [=>............................] - ETA: 3:17  [ loss=1.7827 ][Training] 9/100 [=>............................] - ETA: 3:12  [ loss=1.7857 ][Training] 10/100 [==>...........................] - ETA: 3:08  [ loss=1.7277 ][Training] 11/100 [==>...........................] - ETA: 3:04  [ loss=1.6132 ][Training] 12/100 [==>...........................] - ETA: 3:00  [ loss=1.5123 ][Training] 13/100 [==>...........................] - ETA: 2:56  [ loss=1.3780 ][Training] 14/100 [===>..........................] - ETA: 2:53  [ loss=1.2645 ][Training] 15/100 [===>..........................] - ETA: 2:50  [ loss=1.2298 ][Training] 16/100 [===>..........................] - ETA: 2:48  [ loss=1.1408 ][Training] 17/100 [====>.........................] - ETA: 2:45  [ loss=1.2042 ][Training] 18/100 [====>.........................] - ETA: 2:42  [ loss=1.1455 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=1.0860 ][Training] 20/100 [=====>........................] - ETA: 2:38  [ loss=1.0914 ][Training] 21/100 [=====>........................] - ETA: 2:35  [ loss=1.0634 ][Training] 22/100 [=====>........................] - ETA: 2:33  [ loss=1.0939 ][Training] 23/100 [=====>........................] - ETA: 2:31  [ loss=1.0504 ][Training] 24/100 [======>.......................] - ETA: 2:28  [ loss=1.0196 ][Training] 25/100 [======>.......................] - ETA: 2:26  [ loss=0.9697 ][Training] 26/100 [======>.......................] - ETA: 2:24  [ loss=0.9103 ][Training] 27/100 [=======>......................] - ETA: 2:22  [ loss=0.9901 ][Training] 28/100 [=======>......................] - ETA: 2:20  [ loss=0.9406 ][Training] 29/100 [=======>......................] - ETA: 2:17  [ loss=0.9621 ][Training] 30/100 [========>.....................] - ETA: 2:15  [ loss=0.9371 ][Training] 31/100 [========>.....................] - ETA: 2:13  [ loss=0.8996 ][Training] 32/100 [========>.....................] - ETA: 2:11  [ loss=0.8633 ][Training] 33/100 [========>.....................] - ETA: 2:09  [ loss=0.7528 ][Training] 34/100 [=========>....................] - ETA: 2:07  [ loss=0.7964 ][Training] 35/100 [=========>....................] - ETA: 2:05  [ loss=0.7207 ][Training] 36/100 [=========>....................] - ETA: 2:03  [ loss=0.7175 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.7551 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.6596 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.6772 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.6455 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.6640 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.6149 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.6198 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.5868 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.5831 ][Training] 46/100 [============>.................] - ETA: 1:43  [ loss=0.5906 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.5910 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.5962 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.5725 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.5673 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.5395 ][Training] 52/100 [==============>...............] - ETA: 1:31  [ loss=0.5963 ][Training] 53/100 [==============>...............] - ETA: 1:29  [ loss=0.5342 ][Training] 54/100 [===============>..............] - ETA: 1:27  [ loss=0.5205 ][Training] 55/100 [===============>..............] - ETA: 1:25  [ loss=0.5217 ][Training] 56/100 [===============>..............] - ETA: 1:23  [ loss=0.4963 ][Training] 57/100 [================>.............] - ETA: 1:21  [ loss=0.5257 ][Training] 58/100 [================>.............] - ETA: 1:19  [ loss=0.5026 ][Training] 59/100 [================>.............] - ETA: 1:17  [ loss=0.5361 ][Training] 60/100 [=================>............] - ETA: 1:15  [ loss=0.4807 ][Training] 61/100 [=================>............] - ETA: 1:13  [ loss=0.4690 ][Training] 62/100 [=================>............] - ETA: 1:11  [ loss=0.5099 ][Training] 63/100 [=================>............] - ETA: 1:09  [ loss=0.4982 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.5213 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.5327 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.4486 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.4598 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.5180 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.4895 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.4834 ][Training] 71/100 [====================>.........] - ETA: 54s  [ loss=0.5230 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.4728 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.4848 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.4197 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.4769 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.4292 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.4374 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.4297 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.5326 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.4230 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.4923 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.3974 ][Training] 83/100 [=======================>......] - ETA: 31s  [ loss=0.4696 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.4066 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.4361 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.4023 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.4192 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.4822 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.4332 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.4104 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.4836 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.4314 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.4271 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.3824 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.4078 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.4273 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.3888 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.4021 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.4058 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.4552 ]
 
03/21/2023 16:50:20 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 16:50:20 - INFO - __main__ -     Num examples = 1000
03/21/2023 16:50:20 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 33s  [ loss=0.3810 ][Evaluating] 1/25 [>.............................] - ETA: 33s[Evaluating] 2/25 [=>............................] - ETA: 30s  [ loss=0.3631 ][Evaluating] 2/25 [=>............................] - ETA: 30s[Evaluating] 3/25 [==>...........................] - ETA: 28s  [ loss=0.3957 ][Evaluating] 3/25 [==>...........................] - ETA: 28s[Evaluating] 4/25 [===>..........................] - ETA: 27s  [ loss=0.3442 ][Evaluating] 4/25 [===>..........................] - ETA: 27s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.4510 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.3876 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.4342 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 23s  [ loss=0.3791 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 22s  [ loss=0.3790 ][Evaluating] 9/25 [=========>....................] - ETA: 22s[Evaluating] 10/25 [===========>..................] - ETA: 21s  [ loss=0.4219 ][Evaluating] 10/25 [===========>..................] - ETA: 21s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.4160 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 18s  [ loss=0.3516 ][Evaluating] 12/25 [=============>................] - ETA: 18s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.3778 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.3773 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.4050 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.4011 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.3736 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3830 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.4254 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.3978 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.4255 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.3356 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3852 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3971 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.4191 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 16:50:54 - INFO - __main__ -   

03/21/2023 16:50:54 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 16:50:54 - INFO - __main__ -    acc: 0.5822 - recall: 0.6022 - f1: 0.5920 - loss: 0.3923 
03/21/2023 16:50:54 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 16:50:54 - INFO - __main__ -   ******* LOC results ********
03/21/2023 16:50:54 - INFO - __main__ -    acc: 0.5221 - recall: 0.7701 - f1: 0.6223 
03/21/2023 16:50:54 - INFO - __main__ -   ******* MISC results ********
03/21/2023 16:50:54 - INFO - __main__ -    acc: 0.1818 - recall: 0.0091 - f1: 0.0173 
03/21/2023 16:50:54 - INFO - __main__ -   ******* ORG results ********
03/21/2023 16:50:54 - INFO - __main__ -    acc: 0.5256 - recall: 0.1660 - f1: 0.2523 
03/21/2023 16:50:54 - INFO - __main__ -   ******* PER results ********
03/21/2023 16:50:54 - INFO - __main__ -    acc: 0.6571 - recall: 0.8750 - f1: 0.7506 
03/21/2023 16:50:56 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-100
03/21/2023 16:50:59 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-100
03/21/2023 16:50:59 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:51:04 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:51:04 - INFO - __main__ -   Saving best eval loss model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:51:08 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:51:08 - INFO - __main__ -   


Epoch: 1/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 4:36  [ loss=0.4112 ][Training] 2/100 [..............................] - ETA: 3:45  [ loss=0.4159 ][Training] 3/100 [..............................] - ETA: 3:28  [ loss=0.4157 ][Training] 4/100 [>.............................] - ETA: 3:17  [ loss=0.3989 ][Training] 5/100 [>.............................] - ETA: 3:17  [ loss=0.3925 ][Training] 6/100 [>.............................] - ETA: 3:12  [ loss=0.3880 ][Training] 7/100 [=>............................] - ETA: 3:08  [ loss=0.4208 ][Training] 8/100 [=>............................] - ETA: 3:03  [ loss=0.4003 ][Training] 9/100 [=>............................] - ETA: 3:00  [ loss=0.3871 ][Training] 10/100 [==>...........................] - ETA: 2:56  [ loss=0.3579 ][Training] 11/100 [==>...........................] - ETA: 2:54  [ loss=0.4134 ][Training] 12/100 [==>...........................] - ETA: 2:53  [ loss=0.3571 ][Training] 13/100 [==>...........................] - ETA: 2:54  [ loss=0.3745 ][Training] 14/100 [===>..........................] - ETA: 2:51  [ loss=0.3844 ][Training] 15/100 [===>..........................] - ETA: 2:48  [ loss=0.4342 ][Training] 16/100 [===>..........................] - ETA: 2:45  [ loss=0.4012 ][Training] 17/100 [====>.........................] - ETA: 2:44  [ loss=0.3954 ][Training] 18/100 [====>.........................] - ETA: 2:42  [ loss=0.4166 ][Training] 19/100 [====>.........................] - ETA: 2:39  [ loss=0.3859 ][Training] 20/100 [=====>........................] - ETA: 2:37  [ loss=0.4514 ][Training] 21/100 [=====>........................] - ETA: 2:35  [ loss=0.3876 ][Training] 22/100 [=====>........................] - ETA: 2:33  [ loss=0.3643 ][Training] 23/100 [=====>........................] - ETA: 2:31  [ loss=0.3846 ][Training] 24/100 [======>.......................] - ETA: 2:28  [ loss=0.4018 ][Training] 25/100 [======>.......................] - ETA: 2:26  [ loss=0.3996 ][Training] 26/100 [======>.......................] - ETA: 2:24  [ loss=0.3424 ][Training] 27/100 [=======>......................] - ETA: 2:22  [ loss=0.3853 ][Training] 28/100 [=======>......................] - ETA: 2:19  [ loss=0.3973 ][Training] 29/100 [=======>......................] - ETA: 2:18  [ loss=0.4240 ][Training] 30/100 [========>.....................] - ETA: 2:15  [ loss=0.3665 ][Training] 31/100 [========>.....................] - ETA: 2:13  [ loss=0.4011 ][Training] 32/100 [========>.....................] - ETA: 2:11  [ loss=0.3873 ][Training] 33/100 [========>.....................] - ETA: 2:09  [ loss=0.3707 ][Training] 34/100 [=========>....................] - ETA: 2:07  [ loss=0.4122 ][Training] 35/100 [=========>....................] - ETA: 2:05  [ loss=0.3785 ][Training] 36/100 [=========>....................] - ETA: 2:03  [ loss=0.3405 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.3567 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.3881 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.3980 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.3741 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.3917 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.3516 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.3683 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.3891 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.3581 ][Training] 46/100 [============>.................] - ETA: 1:43  [ loss=0.3765 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.4008 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.3745 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.4045 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.3736 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.3521 ][Training] 52/100 [==============>...............] - ETA: 1:31  [ loss=0.3269 ][Training] 53/100 [==============>...............] - ETA: 1:29  [ loss=0.3718 ][Training] 54/100 [===============>..............] - ETA: 1:27  [ loss=0.3589 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.3659 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.3734 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.3317 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.3377 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.3763 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.3630 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.3082 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.3393 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.3886 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.3740 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.3530 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.4026 ][Training] 67/100 [===================>..........] - ETA: 1:03  [ loss=0.4011 ][Training] 68/100 [===================>..........] - ETA: 1:01  [ loss=0.3173 ][Training] 69/100 [===================>..........] - ETA: 59s  [ loss=0.3593 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.3745 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.3625 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.3823 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.3383 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.3343 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.3451 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.3314 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.3669 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.3325 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.3361 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.3810 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.3087 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.3553 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.3290 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.3410 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.3351 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.3227 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.3261 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.3745 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.3630 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.3505 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.3606 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.3507 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.3165 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.3748 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.3646 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.3790 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.3624 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.3840 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.3478 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.3624 ]
 
03/21/2023 16:54:17 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 16:54:17 - INFO - __main__ -     Num examples = 1000
03/21/2023 16:54:17 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 33s  [ loss=0.3229 ][Evaluating] 1/25 [>.............................] - ETA: 33s[Evaluating] 2/25 [=>............................] - ETA: 30s  [ loss=0.3045 ][Evaluating] 2/25 [=>............................] - ETA: 30s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.3428 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 27s  [ loss=0.2944 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 26s  [ loss=0.3800 ][Evaluating] 5/25 [=====>........................] - ETA: 26s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.3309 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.3697 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.3286 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.3291 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.3695 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.3566 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.3031 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.3273 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.3344 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.3608 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3480 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.3301 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3420 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3458 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.3422 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3676 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.2996 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3329 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3499 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.3642 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 16:54:52 - INFO - __main__ -   

03/21/2023 16:54:52 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 16:54:52 - INFO - __main__ -    acc: 0.7371 - recall: 0.6697 - f1: 0.7018 - loss: 0.3391 
03/21/2023 16:54:52 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 16:54:52 - INFO - __main__ -   ******* LOC results ********
03/21/2023 16:54:52 - INFO - __main__ -    acc: 0.8035 - recall: 0.7912 - f1: 0.7973 
03/21/2023 16:54:52 - INFO - __main__ -   ******* MISC results ********
03/21/2023 16:54:52 - INFO - __main__ -    acc: 0.3404 - recall: 0.1455 - f1: 0.2038 
03/21/2023 16:54:52 - INFO - __main__ -   ******* ORG results ********
03/21/2023 16:54:52 - INFO - __main__ -    acc: 0.5517 - recall: 0.4534 - f1: 0.4978 
03/21/2023 16:54:52 - INFO - __main__ -   ******* PER results ********
03/21/2023 16:54:52 - INFO - __main__ -    acc: 0.8065 - recall: 0.8605 - f1: 0.8326 
03/21/2023 16:54:53 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-200
03/21/2023 16:54:57 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-200
03/21/2023 16:54:57 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:55:16 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:55:16 - INFO - __main__ -   Saving best eval loss model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:55:47 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:55:47 - INFO - __main__ -   


Epoch: 2/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:59  [ loss=0.3696 ][Training] 2/100 [..............................] - ETA: 5:05  [ loss=0.3557 ][Training] 3/100 [..............................] - ETA: 4:24  [ loss=0.3457 ][Training] 4/100 [>.............................] - ETA: 4:06  [ loss=0.3690 ][Training] 5/100 [>.............................] - ETA: 3:53  [ loss=0.3374 ][Training] 6/100 [>.............................] - ETA: 3:40  [ loss=0.3155 ][Training] 7/100 [=>............................] - ETA: 3:29  [ loss=0.3504 ][Training] 8/100 [=>............................] - ETA: 3:22  [ loss=0.3250 ][Training] 9/100 [=>............................] - ETA: 3:15  [ loss=0.3522 ][Training] 10/100 [==>...........................] - ETA: 3:10  [ loss=0.3329 ][Training] 11/100 [==>...........................] - ETA: 3:05  [ loss=0.3092 ][Training] 12/100 [==>...........................] - ETA: 3:00  [ loss=0.3475 ][Training] 13/100 [==>...........................] - ETA: 2:57  [ loss=0.3394 ][Training] 14/100 [===>..........................] - ETA: 2:53  [ loss=0.3066 ][Training] 15/100 [===>..........................] - ETA: 2:50  [ loss=0.3156 ][Training] 16/100 [===>..........................] - ETA: 2:47  [ loss=0.3561 ][Training] 17/100 [====>.........................] - ETA: 2:44  [ loss=0.3273 ][Training] 18/100 [====>.........................] - ETA: 2:42  [ loss=0.3213 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=0.3202 ][Training] 20/100 [=====>........................] - ETA: 2:37  [ loss=0.3073 ][Training] 21/100 [=====>........................] - ETA: 2:35  [ loss=0.3333 ][Training] 22/100 [=====>........................] - ETA: 2:32  [ loss=0.3283 ][Training] 23/100 [=====>........................] - ETA: 2:30  [ loss=0.3302 ][Training] 24/100 [======>.......................] - ETA: 2:28  [ loss=0.3329 ][Training] 25/100 [======>.......................] - ETA: 2:26  [ loss=0.3233 ][Training] 26/100 [======>.......................] - ETA: 2:24  [ loss=0.3241 ][Training] 27/100 [=======>......................] - ETA: 2:23  [ loss=0.3433 ][Training] 28/100 [=======>......................] - ETA: 2:21  [ loss=0.3269 ][Training] 29/100 [=======>......................] - ETA: 2:19  [ loss=0.2937 ][Training] 30/100 [========>.....................] - ETA: 2:17  [ loss=0.3313 ][Training] 31/100 [========>.....................] - ETA: 2:15  [ loss=0.3377 ][Training] 32/100 [========>.....................] - ETA: 2:12  [ loss=0.3510 ][Training] 33/100 [========>.....................] - ETA: 2:10  [ loss=0.3139 ][Training] 34/100 [=========>....................] - ETA: 2:08  [ loss=0.3282 ][Training] 35/100 [=========>....................] - ETA: 2:06  [ loss=0.3261 ][Training] 36/100 [=========>....................] - ETA: 2:04  [ loss=0.3213 ][Training] 37/100 [==========>...................] - ETA: 2:02  [ loss=0.3256 ][Training] 38/100 [==========>...................] - ETA: 2:00  [ loss=0.3431 ][Training] 39/100 [==========>...................] - ETA: 1:58  [ loss=0.3372 ][Training] 40/100 [===========>..................] - ETA: 1:56  [ loss=0.3129 ][Training] 41/100 [===========>..................] - ETA: 1:54  [ loss=0.2893 ][Training] 42/100 [===========>..................] - ETA: 1:52  [ loss=0.3104 ][Training] 43/100 [===========>..................] - ETA: 1:50  [ loss=0.3244 ][Training] 44/100 [============>.................] - ETA: 1:48  [ loss=0.3218 ][Training] 45/100 [============>.................] - ETA: 1:46  [ loss=0.3405 ][Training] 46/100 [============>.................] - ETA: 1:44  [ loss=0.3628 ][Training] 47/100 [=============>................] - ETA: 1:42  [ loss=0.3290 ][Training] 48/100 [=============>................] - ETA: 1:40  [ loss=0.3104 ][Training] 49/100 [=============>................] - ETA: 1:38  [ loss=0.3452 ][Training] 50/100 [==============>...............] - ETA: 1:36  [ loss=0.3377 ][Training] 51/100 [==============>...............] - ETA: 1:34  [ loss=0.3633 ][Training] 52/100 [==============>...............] - ETA: 1:32  [ loss=0.3210 ][Training] 53/100 [==============>...............] - ETA: 1:30  [ loss=0.3155 ][Training] 54/100 [===============>..............] - ETA: 1:28  [ loss=0.3200 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.3202 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.3380 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.3095 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.3095 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.3149 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.3081 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.3026 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.3548 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.2877 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.3008 ][Training] 65/100 [==================>...........] - ETA: 1:07  [ loss=0.3227 ][Training] 66/100 [==================>...........] - ETA: 1:05  [ loss=0.3334 ][Training] 67/100 [===================>..........] - ETA: 1:03  [ loss=0.3205 ][Training] 68/100 [===================>..........] - ETA: 1:01  [ loss=0.3046 ][Training] 69/100 [===================>..........] - ETA: 59s  [ loss=0.3329 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.3544 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.3263 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.2957 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.3226 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.3209 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.3454 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.2909 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.3365 ][Training] 78/100 [======================>.......] - ETA: 42s  [ loss=0.3382 ][Training] 79/100 [======================>.......] - ETA: 40s  [ loss=0.3243 ][Training] 80/100 [=======================>......] - ETA: 38s  [ loss=0.3142 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.3212 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.3324 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.3214 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.3176 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.3070 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.2776 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.3181 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.3553 ][Training] 89/100 [=========================>....] - ETA: 21s  [ loss=0.3186 ][Training] 90/100 [==========================>...] - ETA: 19s  [ loss=0.3210 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.3379 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.3390 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2998 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2918 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.3361 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.2914 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.3051 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.3200 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.3513 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.3121 ]
 
03/21/2023 16:58:58 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 16:58:58 - INFO - __main__ -     Num examples = 1000
03/21/2023 16:58:58 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 32s  [ loss=0.3179 ][Evaluating] 1/25 [>.............................] - ETA: 33s[Evaluating] 2/25 [=>............................] - ETA: 30s  [ loss=0.2881 ][Evaluating] 2/25 [=>............................] - ETA: 30s[Evaluating] 3/25 [==>...........................] - ETA: 28s  [ loss=0.3353 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 27s  [ loss=0.2832 ][Evaluating] 4/25 [===>..........................] - ETA: 27s[Evaluating] 5/25 [=====>........................] - ETA: 26s  [ loss=0.3768 ][Evaluating] 5/25 [=====>........................] - ETA: 26s[Evaluating] 6/25 [======>.......................] - ETA: 24s  [ loss=0.3130 ][Evaluating] 6/25 [======>.......................] - ETA: 24s[Evaluating] 7/25 [=======>......................] - ETA: 23s  [ loss=0.3488 ][Evaluating] 7/25 [=======>......................] - ETA: 23s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.3201 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 20s  [ loss=0.3182 ][Evaluating] 9/25 [=========>....................] - ETA: 20s[Evaluating] 10/25 [===========>..................] - ETA: 19s  [ loss=0.3519 ][Evaluating] 10/25 [===========>..................] - ETA: 19s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.3450 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.2919 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 15s  [ loss=0.3198 ][Evaluating] 13/25 [==============>...............] - ETA: 15s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.3197 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.3570 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3387 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.3153 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3261 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 7s  [ loss=0.3263 ][Evaluating] 19/25 [=====================>........] - ETA: 7s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.3244 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3630 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 3s  [ loss=0.2926 ][Evaluating] 22/25 [=========================>....] - ETA: 3s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3264 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3369 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.3435 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 16:59:31 - INFO - __main__ -   

03/21/2023 16:59:31 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 16:59:31 - INFO - __main__ -    acc: 0.7200 - recall: 0.7326 - f1: 0.7263 - loss: 0.3272 
03/21/2023 16:59:31 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 16:59:31 - INFO - __main__ -   ******* LOC results ********
03/21/2023 16:59:31 - INFO - __main__ -    acc: 0.7695 - recall: 0.8314 - f1: 0.7993 
03/21/2023 16:59:31 - INFO - __main__ -   ******* MISC results ********
03/21/2023 16:59:31 - INFO - __main__ -    acc: 0.3931 - recall: 0.3091 - f1: 0.3461 
03/21/2023 16:59:31 - INFO - __main__ -   ******* ORG results ********
03/21/2023 16:59:31 - INFO - __main__ -    acc: 0.6227 - recall: 0.5547 - f1: 0.5867 
03/21/2023 16:59:31 - INFO - __main__ -   ******* PER results ********
03/21/2023 16:59:31 - INFO - __main__ -    acc: 0.8020 - recall: 0.8877 - f1: 0.8426 
03/21/2023 16:59:33 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-300
03/21/2023 16:59:36 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-300
03/21/2023 16:59:36 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:59:55 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 16:59:55 - INFO - __main__ -   Saving best eval loss model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:00:28 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:00:28 - INFO - __main__ -   


Epoch: 3/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Avoid using `tokenizers` before the fork if possible
To disable this warning, you can either:
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Avoid using `tokenizers` before the fork if possible
To disable this warning, you can either:
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
	- Avoid using `tokenizers` before the fork if possible
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
	- Avoid using `tokenizers` before the fork if possible
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:24  [ loss=0.3046 ][Training] 2/100 [..............................] - ETA: 4:09  [ loss=0.3047 ][Training] 3/100 [..............................] - ETA: 3:51  [ loss=0.2869 ][Training] 4/100 [>.............................] - ETA: 3:36  [ loss=0.3179 ][Training] 5/100 [>.............................] - ETA: 3:26  [ loss=0.2706 ][Training] 6/100 [>.............................] - ETA: 3:18  [ loss=0.3134 ][Training] 7/100 [=>............................] - ETA: 3:12  [ loss=0.3191 ][Training] 8/100 [=>............................] - ETA: 3:07  [ loss=0.3198 ][Training] 9/100 [=>............................] - ETA: 3:03  [ loss=0.3183 ][Training] 10/100 [==>...........................] - ETA: 3:00  [ loss=0.3336 ][Training] 11/100 [==>...........................] - ETA: 2:56  [ loss=0.2999 ][Training] 12/100 [==>...........................] - ETA: 2:53  [ loss=0.3246 ][Training] 13/100 [==>...........................] - ETA: 2:51  [ loss=0.2900 ][Training] 14/100 [===>..........................] - ETA: 2:49  [ loss=0.3237 ][Training] 15/100 [===>..........................] - ETA: 2:46  [ loss=0.2985 ][Training] 16/100 [===>..........................] - ETA: 2:44  [ loss=0.3052 ][Training] 17/100 [====>.........................] - ETA: 2:41  [ loss=0.2988 ][Training] 18/100 [====>.........................] - ETA: 2:39  [ loss=0.2842 ][Training] 19/100 [====>.........................] - ETA: 2:37  [ loss=0.2929 ][Training] 20/100 [=====>........................] - ETA: 2:34  [ loss=0.3161 ][Training] 21/100 [=====>........................] - ETA: 2:33  [ loss=0.2985 ][Training] 22/100 [=====>........................] - ETA: 2:31  [ loss=0.3278 ][Training] 23/100 [=====>........................] - ETA: 2:28  [ loss=0.2998 ][Training] 24/100 [======>.......................] - ETA: 2:26  [ loss=0.3089 ][Training] 25/100 [======>.......................] - ETA: 2:24  [ loss=0.3019 ][Training] 26/100 [======>.......................] - ETA: 2:22  [ loss=0.3106 ][Training] 27/100 [=======>......................] - ETA: 2:20  [ loss=0.3047 ][Training] 28/100 [=======>......................] - ETA: 2:18  [ loss=0.2976 ][Training] 29/100 [=======>......................] - ETA: 2:16  [ loss=0.3168 ][Training] 30/100 [========>.....................] - ETA: 2:14  [ loss=0.3172 ][Training] 31/100 [========>.....................] - ETA: 2:11  [ loss=0.3095 ][Training] 32/100 [========>.....................] - ETA: 2:10  [ loss=0.3080 ][Training] 33/100 [========>.....................] - ETA: 2:08  [ loss=0.3259 ][Training] 34/100 [=========>....................] - ETA: 2:06  [ loss=0.3173 ][Training] 35/100 [=========>....................] - ETA: 2:04  [ loss=0.2884 ][Training] 36/100 [=========>....................] - ETA: 2:02  [ loss=0.3040 ][Training] 37/100 [==========>...................] - ETA: 2:00  [ loss=0.2881 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.2856 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.3062 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.2862 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.2711 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.3089 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.2924 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.2514 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.2783 ][Training] 46/100 [============>.................] - ETA: 1:43  [ loss=0.3181 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.3229 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.3205 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.3089 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.3139 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.3228 ][Training] 52/100 [==============>...............] - ETA: 1:31  [ loss=0.3009 ][Training] 53/100 [==============>...............] - ETA: 1:29  [ loss=0.3102 ][Training] 54/100 [===============>..............] - ETA: 1:27  [ loss=0.3113 ][Training] 55/100 [===============>..............] - ETA: 1:25  [ loss=0.2852 ][Training] 56/100 [===============>..............] - ETA: 1:23  [ loss=0.2866 ][Training] 57/100 [================>.............] - ETA: 1:21  [ loss=0.3198 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.2973 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.2975 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.2705 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.2822 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.2729 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.3118 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.2846 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.2898 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.2972 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.2811 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.2867 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.2770 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.2983 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.3082 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.2981 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.2760 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.2898 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.3196 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.2907 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.3078 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.3162 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.3008 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.2813 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.2918 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.3107 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.2775 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.2804 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.2930 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.3084 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.3306 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.3127 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.2745 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.2766 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.3055 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2982 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.3313 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2987 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.2738 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.2823 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.3013 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.2979 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.3025 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.2447 ]
 
03/21/2023 17:03:37 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:03:37 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:03:37 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 36s  [ loss=0.3304 ][Evaluating] 1/25 [>.............................] - ETA: 36s[Evaluating] 2/25 [=>............................] - ETA: 33s  [ loss=0.2923 ][Evaluating] 2/25 [=>............................] - ETA: 33s[Evaluating] 3/25 [==>...........................] - ETA: 31s  [ loss=0.3369 ][Evaluating] 3/25 [==>...........................] - ETA: 31s[Evaluating] 4/25 [===>..........................] - ETA: 30s  [ loss=0.2887 ][Evaluating] 4/25 [===>..........................] - ETA: 30s[Evaluating] 5/25 [=====>........................] - ETA: 28s  [ loss=0.3867 ][Evaluating] 5/25 [=====>........................] - ETA: 28s[Evaluating] 6/25 [======>.......................] - ETA: 27s  [ loss=0.3098 ][Evaluating] 6/25 [======>.......................] - ETA: 27s[Evaluating] 7/25 [=======>......................] - ETA: 25s  [ loss=0.3589 ][Evaluating] 7/25 [=======>......................] - ETA: 25s[Evaluating] 8/25 [========>.....................] - ETA: 24s  [ loss=0.3259 ][Evaluating] 8/25 [========>.....................] - ETA: 24s[Evaluating] 9/25 [=========>....................] - ETA: 22s  [ loss=0.3227 ][Evaluating] 9/25 [=========>....................] - ETA: 22s[Evaluating] 10/25 [===========>..................] - ETA: 21s  [ loss=0.3533 ][Evaluating] 10/25 [===========>..................] - ETA: 21s[Evaluating] 11/25 [============>.................] - ETA: 20s  [ loss=0.3508 ][Evaluating] 11/25 [============>.................] - ETA: 20s[Evaluating] 12/25 [=============>................] - ETA: 18s  [ loss=0.2921 ][Evaluating] 12/25 [=============>................] - ETA: 18s[Evaluating] 13/25 [==============>...............] - ETA: 17s  [ loss=0.3157 ][Evaluating] 13/25 [==============>...............] - ETA: 17s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.3113 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 14s  [ loss=0.3653 ][Evaluating] 15/25 [=================>............] - ETA: 14s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3418 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 11s  [ loss=0.3379 ][Evaluating] 17/25 [===================>..........] - ETA: 11s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3125 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3279 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 7s  [ loss=0.3191 ][Evaluating] 20/25 [=======================>......] - ETA: 7s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3657 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.2942 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3320 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3469 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.3407 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 17:04:12 - INFO - __main__ -   

03/21/2023 17:04:12 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:04:12 - INFO - __main__ -    acc: 0.6949 - recall: 0.7404 - f1: 0.7169 - loss: 0.3304 
03/21/2023 17:04:12 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:04:12 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:04:12 - INFO - __main__ -    acc: 0.7635 - recall: 0.8410 - f1: 0.8004 
03/21/2023 17:04:12 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:04:12 - INFO - __main__ -    acc: 0.3441 - recall: 0.3864 - f1: 0.3640 
03/21/2023 17:04:12 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:04:12 - INFO - __main__ -    acc: 0.5855 - recall: 0.5547 - f1: 0.5696 
03/21/2023 17:04:12 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:04:12 - INFO - __main__ -    acc: 0.8191 - recall: 0.8696 - f1: 0.8436 
03/21/2023 17:04:14 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-400
03/21/2023 17:04:17 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-400
03/21/2023 17:04:18 - INFO - __main__ -   


Epoch: 4/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 4:51  [ loss=0.2792 ][Training] 2/100 [..............................] - ETA: 3:57  [ loss=0.2725 ][Training] 3/100 [..............................] - ETA: 3:37  [ loss=0.2704 ][Training] 4/100 [>.............................] - ETA: 3:26  [ loss=0.3160 ][Training] 5/100 [>.............................] - ETA: 3:20  [ loss=0.3149 ][Training] 6/100 [>.............................] - ETA: 3:14  [ loss=0.3056 ][Training] 7/100 [=>............................] - ETA: 3:10  [ loss=0.2733 ][Training] 8/100 [=>............................] - ETA: 3:06  [ loss=0.2591 ][Training] 9/100 [=>............................] - ETA: 3:03  [ loss=0.2949 ][Training] 10/100 [==>...........................] - ETA: 2:59  [ loss=0.2859 ][Training] 11/100 [==>...........................] - ETA: 2:56  [ loss=0.3049 ][Training] 12/100 [==>...........................] - ETA: 2:54  [ loss=0.2805 ][Training] 13/100 [==>...........................] - ETA: 2:51  [ loss=0.2925 ][Training] 14/100 [===>..........................] - ETA: 2:50  [ loss=0.3196 ][Training] 15/100 [===>..........................] - ETA: 2:47  [ loss=0.2772 ][Training] 16/100 [===>..........................] - ETA: 2:46  [ loss=0.2911 ][Training] 17/100 [====>.........................] - ETA: 2:44  [ loss=0.2917 ][Training] 18/100 [====>.........................] - ETA: 2:42  [ loss=0.2903 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=0.2903 ][Training] 20/100 [=====>........................] - ETA: 2:37  [ loss=0.2971 ][Training] 21/100 [=====>........................] - ETA: 2:35  [ loss=0.2806 ][Training] 22/100 [=====>........................] - ETA: 2:33  [ loss=0.2649 ][Training] 23/100 [=====>........................] - ETA: 2:30  [ loss=0.2688 ][Training] 24/100 [======>.......................] - ETA: 2:29  [ loss=0.2807 ][Training] 25/100 [======>.......................] - ETA: 2:27  [ loss=0.3009 ][Training] 26/100 [======>.......................] - ETA: 2:25  [ loss=0.2900 ][Training] 27/100 [=======>......................] - ETA: 2:23  [ loss=0.3014 ][Training] 28/100 [=======>......................] - ETA: 2:20  [ loss=0.2697 ][Training] 29/100 [=======>......................] - ETA: 2:18  [ loss=0.2870 ][Training] 30/100 [========>.....................] - ETA: 2:16  [ loss=0.2771 ][Training] 31/100 [========>.....................] - ETA: 2:14  [ loss=0.2767 ][Training] 32/100 [========>.....................] - ETA: 2:12  [ loss=0.2852 ][Training] 33/100 [========>.....................] - ETA: 2:10  [ loss=0.2834 ][Training] 34/100 [=========>....................] - ETA: 2:08  [ loss=0.2615 ][Training] 35/100 [=========>....................] - ETA: 2:06  [ loss=0.2925 ][Training] 36/100 [=========>....................] - ETA: 2:04  [ loss=0.2394 ][Training] 37/100 [==========>...................] - ETA: 2:02  [ loss=0.2635 ][Training] 38/100 [==========>...................] - ETA: 2:00  [ loss=0.3083 ][Training] 39/100 [==========>...................] - ETA: 1:58  [ loss=0.2751 ][Training] 40/100 [===========>..................] - ETA: 1:56  [ loss=0.2667 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.2803 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.3018 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.2783 ][Training] 44/100 [============>.................] - ETA: 1:48  [ loss=0.2931 ][Training] 45/100 [============>.................] - ETA: 1:46  [ loss=0.2987 ][Training] 46/100 [============>.................] - ETA: 1:44  [ loss=0.2944 ][Training] 47/100 [=============>................] - ETA: 1:42  [ loss=0.2878 ][Training] 48/100 [=============>................] - ETA: 1:40  [ loss=0.2927 ][Training] 49/100 [=============>................] - ETA: 1:38  [ loss=0.2981 ][Training] 50/100 [==============>...............] - ETA: 1:36  [ loss=0.2612 ][Training] 51/100 [==============>...............] - ETA: 1:34  [ loss=0.2879 ][Training] 52/100 [==============>...............] - ETA: 1:32  [ loss=0.2889 ][Training] 53/100 [==============>...............] - ETA: 1:30  [ loss=0.2823 ][Training] 54/100 [===============>..............] - ETA: 1:28  [ loss=0.2938 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.3061 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.2871 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.2838 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.2962 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.3087 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.2777 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.2783 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.2969 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.3042 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.2869 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.2881 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.2638 ][Training] 67/100 [===================>..........] - ETA: 1:03  [ loss=0.2706 ][Training] 68/100 [===================>..........] - ETA: 1:01  [ loss=0.2509 ][Training] 69/100 [===================>..........] - ETA: 59s  [ loss=0.2899 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.3137 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.2619 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.2771 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.2567 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.2749 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.2955 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.2669 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.2716 ][Training] 78/100 [======================>.......] - ETA: 42s  [ loss=0.3198 ][Training] 79/100 [======================>.......] - ETA: 40s  [ loss=0.2691 ][Training] 80/100 [=======================>......] - ETA: 38s  [ loss=0.2801 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.2902 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.2858 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.2918 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.2769 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.2546 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.2785 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.3004 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.2786 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.2838 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.2934 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.2881 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2920 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2621 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2665 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.3063 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.2770 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.2934 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.3136 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.2810 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.2748 ]
 
03/21/2023 17:07:28 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:07:28 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:07:28 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 33s  [ loss=0.3490 ][Evaluating] 1/25 [>.............................] - ETA: 34s[Evaluating] 2/25 [=>............................] - ETA: 31s  [ loss=0.2855 ][Evaluating] 2/25 [=>............................] - ETA: 31s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.3401 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.2979 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.3941 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.3152 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.3784 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.3260 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.3180 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.3603 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.3516 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.2925 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.3206 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.3212 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.3756 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3558 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 11s  [ loss=0.3233 ][Evaluating] 17/25 [===================>..........] - ETA: 11s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3301 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3276 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 7s  [ loss=0.3237 ][Evaluating] 20/25 [=======================>......] - ETA: 7s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3766 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.3050 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3260 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3512 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.3437 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 17:08:03 - INFO - __main__ -   

03/21/2023 17:08:03 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:08:03 - INFO - __main__ -    acc: 0.7199 - recall: 0.7190 - f1: 0.7195 - loss: 0.3356 
03/21/2023 17:08:03 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:08:03 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:08:03 - INFO - __main__ -    acc: 0.7993 - recall: 0.8391 - f1: 0.8187 
03/21/2023 17:08:03 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:08:03 - INFO - __main__ -    acc: 0.3422 - recall: 0.2909 - f1: 0.3145 
03/21/2023 17:08:03 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:08:03 - INFO - __main__ -    acc: 0.5941 - recall: 0.4858 - f1: 0.5345 
03/21/2023 17:08:03 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:08:03 - INFO - __main__ -    acc: 0.8073 - recall: 0.8804 - f1: 0.8423 
03/21/2023 17:08:05 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-500
03/21/2023 17:08:08 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-500
03/21/2023 17:08:08 - INFO - __main__ -   


Epoch: 5/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:19  [ loss=0.2856 ][Training] 2/100 [..............................] - ETA: 4:44  [ loss=0.2531 ][Training] 3/100 [..............................] - ETA: 4:10  [ loss=0.2672 ][Training] 4/100 [>.............................] - ETA: 3:51  [ loss=0.2775 ][Training] 5/100 [>.............................] - ETA: 3:39  [ loss=0.2845 ][Training] 6/100 [>.............................] - ETA: 3:33  [ loss=0.2826 ][Training] 7/100 [=>............................] - ETA: 3:26  [ loss=0.3024 ][Training] 8/100 [=>............................] - ETA: 3:21  [ loss=0.2562 ][Training] 9/100 [=>............................] - ETA: 3:17  [ loss=0.2805 ][Training] 10/100 [==>...........................] - ETA: 3:13  [ loss=0.2885 ][Training] 11/100 [==>...........................] - ETA: 3:10  [ loss=0.2881 ][Training] 12/100 [==>...........................] - ETA: 3:07  [ loss=0.2535 ][Training] 13/100 [==>...........................] - ETA: 3:03  [ loss=0.2692 ][Training] 14/100 [===>..........................] - ETA: 3:01  [ loss=0.3085 ][Training] 15/100 [===>..........................] - ETA: 2:58  [ loss=0.2789 ][Training] 16/100 [===>..........................] - ETA: 2:55  [ loss=0.2934 ][Training] 17/100 [====>.........................] - ETA: 2:52  [ loss=0.2443 ][Training] 18/100 [====>.........................] - ETA: 2:50  [ loss=0.2886 ][Training] 19/100 [====>.........................] - ETA: 2:47  [ loss=0.3086 ][Training] 20/100 [=====>........................] - ETA: 2:44  [ loss=0.2840 ][Training] 21/100 [=====>........................] - ETA: 2:42  [ loss=0.2824 ][Training] 22/100 [=====>........................] - ETA: 2:39  [ loss=0.2838 ][Training] 23/100 [=====>........................] - ETA: 2:37  [ loss=0.2593 ][Training] 24/100 [======>.......................] - ETA: 2:34  [ loss=0.2605 ][Training] 25/100 [======>.......................] - ETA: 2:32  [ loss=0.3115 ][Training] 26/100 [======>.......................] - ETA: 2:29  [ loss=0.2485 ][Training] 27/100 [=======>......................] - ETA: 2:27  [ loss=0.2782 ][Training] 28/100 [=======>......................] - ETA: 2:25  [ loss=0.2909 ][Training] 29/100 [=======>......................] - ETA: 2:23  [ loss=0.2739 ][Training] 30/100 [========>.....................] - ETA: 2:21  [ loss=0.2656 ][Training] 31/100 [========>.....................] - ETA: 2:19  [ loss=0.2849 ][Training] 32/100 [========>.....................] - ETA: 2:16  [ loss=0.2686 ][Training] 33/100 [========>.....................] - ETA: 2:14  [ loss=0.2824 ][Training] 34/100 [=========>....................] - ETA: 2:12  [ loss=0.2826 ][Training] 35/100 [=========>....................] - ETA: 2:10  [ loss=0.2769 ][Training] 36/100 [=========>....................] - ETA: 2:07  [ loss=0.2628 ][Training] 37/100 [==========>...................] - ETA: 2:05  [ loss=0.2921 ][Training] 38/100 [==========>...................] - ETA: 2:03  [ loss=0.2732 ][Training] 39/100 [==========>...................] - ETA: 2:01  [ loss=0.2748 ][Training] 40/100 [===========>..................] - ETA: 1:59  [ loss=0.2612 ][Training] 41/100 [===========>..................] - ETA: 1:56  [ loss=0.2983 ][Training] 42/100 [===========>..................] - ETA: 1:54  [ loss=0.2866 ][Training] 43/100 [===========>..................] - ETA: 1:52  [ loss=0.2781 ][Training] 44/100 [============>.................] - ETA: 1:50  [ loss=0.2612 ][Training] 45/100 [============>.................] - ETA: 1:48  [ loss=0.2968 ][Training] 46/100 [============>.................] - ETA: 1:46  [ loss=0.2491 ][Training] 47/100 [=============>................] - ETA: 1:44  [ loss=0.2767 ][Training] 48/100 [=============>................] - ETA: 1:42  [ loss=0.2857 ][Training] 49/100 [=============>................] - ETA: 1:40  [ loss=0.2821 ][Training] 50/100 [==============>...............] - ETA: 1:38  [ loss=0.2758 ][Training] 51/100 [==============>...............] - ETA: 1:36  [ loss=0.2787 ][Training] 52/100 [==============>...............] - ETA: 1:34  [ loss=0.2917 ][Training] 53/100 [==============>...............] - ETA: 1:32  [ loss=0.2558 ][Training] 54/100 [===============>..............] - ETA: 1:29  [ loss=0.2707 ][Training] 55/100 [===============>..............] - ETA: 1:27  [ loss=0.2743 ][Training] 56/100 [===============>..............] - ETA: 1:25  [ loss=0.2861 ][Training] 57/100 [================>.............] - ETA: 1:23  [ loss=0.2674 ][Training] 58/100 [================>.............] - ETA: 1:21  [ loss=0.2681 ][Training] 59/100 [================>.............] - ETA: 1:19  [ loss=0.2649 ][Training] 60/100 [=================>............] - ETA: 1:17  [ loss=0.2719 ][Training] 61/100 [=================>............] - ETA: 1:15  [ loss=0.3045 ][Training] 62/100 [=================>............] - ETA: 1:13  [ loss=0.2767 ][Training] 63/100 [=================>............] - ETA: 1:11  [ loss=0.2635 ][Training] 64/100 [==================>...........] - ETA: 1:09  [ loss=0.2678 ][Training] 65/100 [==================>...........] - ETA: 1:07  [ loss=0.2374 ][Training] 66/100 [==================>...........] - ETA: 1:05  [ loss=0.2738 ][Training] 67/100 [===================>..........] - ETA: 1:03  [ loss=0.2674 ][Training] 68/100 [===================>..........] - ETA: 1:01  [ loss=0.2784 ][Training] 69/100 [===================>..........] - ETA: 1:00  [ loss=0.2995 ][Training] 70/100 [====================>.........] - ETA: 58s  [ loss=0.3011 ][Training] 71/100 [====================>.........] - ETA: 56s  [ loss=0.2524 ][Training] 72/100 [====================>.........] - ETA: 54s  [ loss=0.2775 ][Training] 73/100 [====================>.........] - ETA: 52s  [ loss=0.2728 ][Training] 74/100 [=====================>........] - ETA: 50s  [ loss=0.2790 ][Training] 75/100 [=====================>........] - ETA: 48s  [ loss=0.2642 ][Training] 76/100 [=====================>........] - ETA: 46s  [ loss=0.2842 ][Training] 77/100 [======================>.......] - ETA: 44s  [ loss=0.2653 ][Training] 78/100 [======================>.......] - ETA: 42s  [ loss=0.3000 ][Training] 79/100 [======================>.......] - ETA: 40s  [ loss=0.2637 ][Training] 80/100 [=======================>......] - ETA: 38s  [ loss=0.3009 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.2812 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.2665 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.2750 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.2938 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.2638 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.2850 ][Training] 87/100 [=========================>....] - ETA: 25s  [ loss=0.2786 ][Training] 88/100 [=========================>....] - ETA: 23s  [ loss=0.2745 ][Training] 89/100 [=========================>....] - ETA: 21s  [ loss=0.2660 ][Training] 90/100 [==========================>...] - ETA: 19s  [ loss=0.2681 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.2410 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2945 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2677 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.3024 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.2674 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.3029 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.2935 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.2823 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.2691 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.2404 ]
 
03/21/2023 17:11:20 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:11:20 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:11:20 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 36s  [ loss=0.3333 ][Evaluating] 1/25 [>.............................] - ETA: 37s[Evaluating] 2/25 [=>............................] - ETA: 32s  [ loss=0.2851 ][Evaluating] 2/25 [=>............................] - ETA: 32s[Evaluating] 3/25 [==>...........................] - ETA: 31s  [ loss=0.3337 ][Evaluating] 3/25 [==>...........................] - ETA: 31s[Evaluating] 4/25 [===>..........................] - ETA: 29s  [ loss=0.2922 ][Evaluating] 4/25 [===>..........................] - ETA: 29s[Evaluating] 5/25 [=====>........................] - ETA: 28s  [ loss=0.3936 ][Evaluating] 5/25 [=====>........................] - ETA: 28s[Evaluating] 6/25 [======>.......................] - ETA: 26s  [ loss=0.3075 ][Evaluating] 6/25 [======>.......................] - ETA: 26s[Evaluating] 7/25 [=======>......................] - ETA: 25s  [ loss=0.3669 ][Evaluating] 7/25 [=======>......................] - ETA: 25s[Evaluating] 8/25 [========>.....................] - ETA: 23s  [ loss=0.3279 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 22s  [ loss=0.3204 ][Evaluating] 9/25 [=========>....................] - ETA: 22s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.3605 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.3468 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.2956 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.3177 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.3200 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.3645 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3442 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.3231 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3238 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3302 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.3132 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3695 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.2962 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3230 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3448 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.3381 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 17:11:54 - INFO - __main__ -   

03/21/2023 17:11:54 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:11:54 - INFO - __main__ -    acc: 0.7233 - recall: 0.7326 - f1: 0.7279 - loss: 0.3309 
03/21/2023 17:11:54 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:11:54 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:11:54 - INFO - __main__ -    acc: 0.7849 - recall: 0.8180 - f1: 0.8011 
03/21/2023 17:11:54 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:11:54 - INFO - __main__ -    acc: 0.3790 - recall: 0.3773 - f1: 0.3781 
03/21/2023 17:11:54 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:11:54 - INFO - __main__ -    acc: 0.6143 - recall: 0.5547 - f1: 0.5830 
03/21/2023 17:11:54 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:11:54 - INFO - __main__ -    acc: 0.8383 - recall: 0.8732 - f1: 0.8554 
03/21/2023 17:11:55 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-600
03/21/2023 17:11:58 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-600
03/21/2023 17:11:58 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:12:17 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:12:17 - INFO - __main__ -   


Epoch: 6/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:43  [ loss=0.2799 ][Training] 2/100 [..............................] - ETA: 4:21  [ loss=0.2617 ][Training] 3/100 [..............................] - ETA: 3:52  [ loss=0.2656 ][Training] 4/100 [>.............................] - ETA: 3:38  [ loss=0.2747 ][Training] 5/100 [>.............................] - ETA: 3:27  [ loss=0.2531 ][Training] 6/100 [>.............................] - ETA: 3:21  [ loss=0.2572 ][Training] 7/100 [=>............................] - ETA: 3:14  [ loss=0.2856 ][Training] 8/100 [=>............................] - ETA: 3:09  [ loss=0.2610 ][Training] 9/100 [=>............................] - ETA: 3:07  [ loss=0.2927 ][Training] 10/100 [==>...........................] - ETA: 3:03  [ loss=0.2907 ][Training] 11/100 [==>...........................] - ETA: 2:59  [ loss=0.2541 ][Training] 12/100 [==>...........................] - ETA: 2:56  [ loss=0.2770 ][Training] 13/100 [==>...........................] - ETA: 2:53  [ loss=0.2649 ][Training] 14/100 [===>..........................] - ETA: 2:50  [ loss=0.2608 ][Training] 15/100 [===>..........................] - ETA: 2:47  [ loss=0.3012 ][Training] 16/100 [===>..........................] - ETA: 2:45  [ loss=0.2302 ][Training] 17/100 [====>.........................] - ETA: 2:43  [ loss=0.2844 ][Training] 18/100 [====>.........................] - ETA: 2:40  [ loss=0.2954 ][Training] 19/100 [====>.........................] - ETA: 2:38  [ loss=0.2735 ][Training] 20/100 [=====>........................] - ETA: 2:36  [ loss=0.2755 ][Training] 21/100 [=====>........................] - ETA: 2:34  [ loss=0.2929 ][Training] 22/100 [=====>........................] - ETA: 2:31  [ loss=0.2706 ][Training] 23/100 [=====>........................] - ETA: 2:29  [ loss=0.2884 ][Training] 24/100 [======>.......................] - ETA: 2:27  [ loss=0.2771 ][Training] 25/100 [======>.......................] - ETA: 2:25  [ loss=0.2784 ][Training] 26/100 [======>.......................] - ETA: 2:23  [ loss=0.2653 ][Training] 27/100 [=======>......................] - ETA: 2:20  [ loss=0.2687 ][Training] 28/100 [=======>......................] - ETA: 2:18  [ loss=0.2642 ][Training] 29/100 [=======>......................] - ETA: 2:16  [ loss=0.2547 ][Training] 30/100 [========>.....................] - ETA: 2:14  [ loss=0.2546 ][Training] 31/100 [========>.....................] - ETA: 2:13  [ loss=0.2760 ][Training] 32/100 [========>.....................] - ETA: 2:11  [ loss=0.2635 ][Training] 33/100 [========>.....................] - ETA: 2:09  [ loss=0.2376 ][Training] 34/100 [=========>....................] - ETA: 2:07  [ loss=0.2548 ][Training] 35/100 [=========>....................] - ETA: 2:05  [ loss=0.2824 ][Training] 36/100 [=========>....................] - ETA: 2:03  [ loss=0.2537 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.2612 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.2570 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.2844 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.2580 ][Training] 41/100 [===========>..................] - ETA: 1:54  [ loss=0.2432 ][Training] 42/100 [===========>..................] - ETA: 1:52  [ loss=0.2658 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.2752 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.2503 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.2634 ][Training] 46/100 [============>.................] - ETA: 1:44  [ loss=0.2498 ][Training] 47/100 [=============>................] - ETA: 1:42  [ loss=0.2505 ][Training] 48/100 [=============>................] - ETA: 1:40  [ loss=0.2840 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.2619 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.2910 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.2818 ][Training] 52/100 [==============>...............] - ETA: 1:32  [ loss=0.2634 ][Training] 53/100 [==============>...............] - ETA: 1:30  [ loss=0.2909 ][Training] 54/100 [===============>..............] - ETA: 1:28  [ loss=0.2527 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.2954 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.2730 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.2479 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.2601 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.2809 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.2697 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.2582 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.2770 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.2670 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.2671 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.2736 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.2537 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.2687 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.2589 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.2779 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.2929 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.2904 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.2835 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.2709 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.2604 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.2644 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.2832 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.2730 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.2566 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.3006 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.2725 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.2892 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.2396 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.2970 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.2758 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.2834 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.2760 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.2723 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.3087 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.2893 ][Training] 90/100 [==========================>...] - ETA: 19s  [ loss=0.2863 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.2478 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2469 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2902 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2554 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.2439 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.3067 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.2664 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.2855 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.2496 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.3037 ]
 
03/21/2023 17:15:29 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:15:29 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:15:29 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 34s  [ loss=0.3387 ][Evaluating] 1/25 [>.............................] - ETA: 35s[Evaluating] 2/25 [=>............................] - ETA: 31s  [ loss=0.2864 ][Evaluating] 2/25 [=>............................] - ETA: 32s[Evaluating] 3/25 [==>...........................] - ETA: 30s  [ loss=0.3365 ][Evaluating] 3/25 [==>...........................] - ETA: 30s[Evaluating] 4/25 [===>..........................] - ETA: 29s  [ loss=0.2931 ][Evaluating] 4/25 [===>..........................] - ETA: 29s[Evaluating] 5/25 [=====>........................] - ETA: 28s  [ loss=0.4023 ][Evaluating] 5/25 [=====>........................] - ETA: 28s[Evaluating] 6/25 [======>.......................] - ETA: 26s  [ loss=0.3073 ][Evaluating] 6/25 [======>.......................] - ETA: 27s[Evaluating] 7/25 [=======>......................] - ETA: 25s  [ loss=0.3742 ][Evaluating] 7/25 [=======>......................] - ETA: 25s[Evaluating] 8/25 [========>.....................] - ETA: 24s  [ loss=0.3309 ][Evaluating] 8/25 [========>.....................] - ETA: 24s[Evaluating] 9/25 [=========>....................] - ETA: 22s  [ loss=0.3249 ][Evaluating] 9/25 [=========>....................] - ETA: 22s[Evaluating] 10/25 [===========>..................] - ETA: 21s  [ loss=0.3550 ][Evaluating] 10/25 [===========>..................] - ETA: 21s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.3511 ][Evaluating] 11/25 [============>.................] - ETA: 20s[Evaluating] 12/25 [=============>................] - ETA: 18s  [ loss=0.2954 ][Evaluating] 12/25 [=============>................] - ETA: 18s[Evaluating] 13/25 [==============>...............] - ETA: 17s  [ loss=0.3144 ][Evaluating] 13/25 [==============>...............] - ETA: 17s[Evaluating] 14/25 [===============>..............] - ETA: 15s  [ loss=0.3199 ][Evaluating] 14/25 [===============>..............] - ETA: 15s[Evaluating] 15/25 [=================>............] - ETA: 14s  [ loss=0.3668 ][Evaluating] 15/25 [=================>............] - ETA: 14s[Evaluating] 16/25 [==================>...........] - ETA: 13s  [ loss=0.3458 ][Evaluating] 16/25 [==================>...........] - ETA: 13s[Evaluating] 17/25 [===================>..........] - ETA: 11s  [ loss=0.3293 ][Evaluating] 17/25 [===================>..........] - ETA: 11s[Evaluating] 18/25 [====================>.........] - ETA: 10s  [ loss=0.3198 ][Evaluating] 18/25 [====================>.........] - ETA: 10s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3309 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 7s  [ loss=0.3136 ][Evaluating] 20/25 [=======================>......] - ETA: 7s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3692 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.2944 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3263 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3455 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.4s/step  [ loss=0.3366 ]
[Evaluating] 25/25 [==============================] 1.4s/step
03/21/2023 17:16:05 - INFO - __main__ -   

03/21/2023 17:16:05 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:16:05 - INFO - __main__ -    acc: 0.7231 - recall: 0.7424 - f1: 0.7326 - loss: 0.3323 
03/21/2023 17:16:05 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:16:05 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:16:05 - INFO - __main__ -    acc: 0.7857 - recall: 0.8429 - f1: 0.8133 
03/21/2023 17:16:05 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:16:05 - INFO - __main__ -    acc: 0.3908 - recall: 0.3091 - f1: 0.3452 
03/21/2023 17:16:05 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:16:05 - INFO - __main__ -    acc: 0.5827 - recall: 0.5992 - f1: 0.5908 
03/21/2023 17:16:05 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:16:05 - INFO - __main__ -    acc: 0.8215 - recall: 0.8841 - f1: 0.8517 
03/21/2023 17:16:06 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-700
03/21/2023 17:16:09 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-700
03/21/2023 17:16:09 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:16:28 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:16:28 - INFO - __main__ -   


Epoch: 7/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 7:00  [ loss=0.2543 ][Training] 2/100 [..............................] - ETA: 5:04  [ loss=0.2670 ][Training] 3/100 [..............................] - ETA: 4:23  [ loss=0.2682 ][Training] 4/100 [>.............................] - ETA: 4:02  [ loss=0.2760 ][Training] 5/100 [>.............................] - ETA: 3:48  [ loss=0.2736 ][Training] 6/100 [>.............................] - ETA: 3:38  [ loss=0.2927 ][Training] 7/100 [=>............................] - ETA: 3:31  [ loss=0.2454 ][Training] 8/100 [=>............................] - ETA: 3:24  [ loss=0.2746 ][Training] 9/100 [=>............................] - ETA: 3:19  [ loss=0.2685 ][Training] 10/100 [==>...........................] - ETA: 3:14  [ loss=0.2763 ][Training] 11/100 [==>...........................] - ETA: 3:10  [ loss=0.2717 ][Training] 12/100 [==>...........................] - ETA: 3:08  [ loss=0.2592 ][Training] 13/100 [==>...........................] - ETA: 3:05  [ loss=0.2666 ][Training] 14/100 [===>..........................] - ETA: 3:02  [ loss=0.2672 ][Training] 15/100 [===>..........................] - ETA: 2:59  [ loss=0.2545 ][Training] 16/100 [===>..........................] - ETA: 2:57  [ loss=0.2707 ][Training] 17/100 [====>.........................] - ETA: 2:54  [ loss=0.2701 ][Training] 18/100 [====>.........................] - ETA: 2:51  [ loss=0.2897 ][Training] 19/100 [====>.........................] - ETA: 2:48  [ loss=0.2768 ][Training] 20/100 [=====>........................] - ETA: 2:46  [ loss=0.2760 ][Training] 21/100 [=====>........................] - ETA: 2:43  [ loss=0.2666 ][Training] 22/100 [=====>........................] - ETA: 2:41  [ loss=0.2991 ][Training] 23/100 [=====>........................] - ETA: 2:38  [ loss=0.2522 ][Training] 24/100 [======>.......................] - ETA: 2:36  [ loss=0.2714 ][Training] 25/100 [======>.......................] - ETA: 2:33  [ loss=0.2508 ][Training] 26/100 [======>.......................] - ETA: 2:31  [ loss=0.2256 ][Training] 27/100 [=======>......................] - ETA: 2:28  [ loss=0.2892 ][Training] 28/100 [=======>......................] - ETA: 2:26  [ loss=0.2539 ][Training] 29/100 [=======>......................] - ETA: 2:23  [ loss=0.2780 ][Training] 30/100 [========>.....................] - ETA: 2:21  [ loss=0.2782 ][Training] 31/100 [========>.....................] - ETA: 2:19  [ loss=0.2672 ][Training] 32/100 [========>.....................] - ETA: 2:17  [ loss=0.2561 ][Training] 33/100 [========>.....................] - ETA: 2:14  [ loss=0.2667 ][Training] 34/100 [=========>....................] - ETA: 2:12  [ loss=0.2861 ][Training] 35/100 [=========>....................] - ETA: 2:10  [ loss=0.2550 ][Training] 36/100 [=========>....................] - ETA: 2:08  [ loss=0.2698 ][Training] 37/100 [==========>...................] - ETA: 2:06  [ loss=0.2386 ][Training] 38/100 [==========>...................] - ETA: 2:04  [ loss=0.2692 ][Training] 39/100 [==========>...................] - ETA: 2:02  [ loss=0.2736 ][Training] 40/100 [===========>..................] - ETA: 2:00  [ loss=0.2841 ][Training] 41/100 [===========>..................] - ETA: 1:58  [ loss=0.2328 ][Training] 42/100 [===========>..................] - ETA: 1:55  [ loss=0.2767 ][Training] 43/100 [===========>..................] - ETA: 1:53  [ loss=0.2469 ][Training] 44/100 [============>.................] - ETA: 1:51  [ loss=0.2927 ][Training] 45/100 [============>.................] - ETA: 1:50  [ loss=0.2685 ][Training] 46/100 [============>.................] - ETA: 1:48  [ loss=0.2794 ][Training] 47/100 [=============>................] - ETA: 1:45  [ loss=0.2763 ][Training] 48/100 [=============>................] - ETA: 1:43  [ loss=0.2303 ][Training] 49/100 [=============>................] - ETA: 1:41  [ loss=0.2749 ][Training] 50/100 [==============>...............] - ETA: 1:39  [ loss=0.2616 ][Training] 51/100 [==============>...............] - ETA: 1:37  [ loss=0.2471 ][Training] 52/100 [==============>...............] - ETA: 1:35  [ loss=0.2749 ][Training] 53/100 [==============>...............] - ETA: 1:33  [ loss=0.2716 ][Training] 54/100 [===============>..............] - ETA: 1:31  [ loss=0.2579 ][Training] 55/100 [===============>..............] - ETA: 1:29  [ loss=0.2594 ][Training] 56/100 [===============>..............] - ETA: 1:27  [ loss=0.2417 ][Training] 57/100 [================>.............] - ETA: 1:25  [ loss=0.2894 ][Training] 58/100 [================>.............] - ETA: 1:23  [ loss=0.2518 ][Training] 59/100 [================>.............] - ETA: 1:21  [ loss=0.2685 ][Training] 60/100 [=================>............] - ETA: 1:19  [ loss=0.2592 ][Training] 61/100 [=================>............] - ETA: 1:17  [ loss=0.2397 ][Training] 62/100 [=================>............] - ETA: 1:15  [ loss=0.2844 ][Training] 63/100 [=================>............] - ETA: 1:13  [ loss=0.2587 ][Training] 64/100 [==================>...........] - ETA: 1:11  [ loss=0.2957 ][Training] 65/100 [==================>...........] - ETA: 1:09  [ loss=0.2681 ][Training] 66/100 [==================>...........] - ETA: 1:07  [ loss=0.2579 ][Training] 67/100 [===================>..........] - ETA: 1:05  [ loss=0.2561 ][Training] 68/100 [===================>..........] - ETA: 1:03  [ loss=0.2417 ][Training] 69/100 [===================>..........] - ETA: 1:01  [ loss=0.2640 ][Training] 70/100 [====================>.........] - ETA: 59s  [ loss=0.2911 ][Training] 71/100 [====================>.........] - ETA: 57s  [ loss=0.2659 ][Training] 72/100 [====================>.........] - ETA: 55s  [ loss=0.2806 ][Training] 73/100 [====================>.........] - ETA: 52s  [ loss=0.2571 ][Training] 74/100 [=====================>........] - ETA: 50s  [ loss=0.2632 ][Training] 75/100 [=====================>........] - ETA: 48s  [ loss=0.2637 ][Training] 76/100 [=====================>........] - ETA: 46s  [ loss=0.2834 ][Training] 77/100 [======================>.......] - ETA: 44s  [ loss=0.2542 ][Training] 78/100 [======================>.......] - ETA: 42s  [ loss=0.2792 ][Training] 79/100 [======================>.......] - ETA: 40s  [ loss=0.2849 ][Training] 80/100 [=======================>......] - ETA: 38s  [ loss=0.2757 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.2970 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.2718 ][Training] 83/100 [=======================>......] - ETA: 33s  [ loss=0.2706 ][Training] 84/100 [========================>.....] - ETA: 31s  [ loss=0.2612 ][Training] 85/100 [========================>.....] - ETA: 29s  [ loss=0.2690 ][Training] 86/100 [========================>.....] - ETA: 27s  [ loss=0.2658 ][Training] 87/100 [=========================>....] - ETA: 25s  [ loss=0.2870 ][Training] 88/100 [=========================>....] - ETA: 23s  [ loss=0.2833 ][Training] 89/100 [=========================>....] - ETA: 21s  [ loss=0.2623 ][Training] 90/100 [==========================>...] - ETA: 19s  [ loss=0.2321 ][Training] 91/100 [==========================>...] - ETA: 17s  [ loss=0.2423 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2761 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2536 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2914 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.2393 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.2609 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.2489 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.2886 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.2716 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.2687 ]
 
03/21/2023 17:19:40 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:19:40 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:19:40 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 31s  [ loss=0.3402 ][Evaluating] 1/25 [>.............................] - ETA: 31s[Evaluating] 2/25 [=>............................] - ETA: 29s  [ loss=0.2929 ][Evaluating] 2/25 [=>............................] - ETA: 29s[Evaluating] 3/25 [==>...........................] - ETA: 28s  [ loss=0.3400 ][Evaluating] 3/25 [==>...........................] - ETA: 28s[Evaluating] 4/25 [===>..........................] - ETA: 27s  [ loss=0.2893 ][Evaluating] 4/25 [===>..........................] - ETA: 27s[Evaluating] 5/25 [=====>........................] - ETA: 26s  [ loss=0.4035 ][Evaluating] 5/25 [=====>........................] - ETA: 26s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.3083 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 23s  [ loss=0.3759 ][Evaluating] 7/25 [=======>......................] - ETA: 23s[Evaluating] 8/25 [========>.....................] - ETA: 22s  [ loss=0.3325 ][Evaluating] 8/25 [========>.....................] - ETA: 22s[Evaluating] 9/25 [=========>....................] - ETA: 20s  [ loss=0.3315 ][Evaluating] 9/25 [=========>....................] - ETA: 20s[Evaluating] 10/25 [===========>..................] - ETA: 19s  [ loss=0.3578 ][Evaluating] 10/25 [===========>..................] - ETA: 19s[Evaluating] 11/25 [============>.................] - ETA: 18s  [ loss=0.3504 ][Evaluating] 11/25 [============>.................] - ETA: 18s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.2977 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 15s  [ loss=0.3231 ][Evaluating] 13/25 [==============>...............] - ETA: 15s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.3159 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.3723 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3506 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.3348 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3177 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3398 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.3154 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3748 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.3018 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3369 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3527 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.3372 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 17:20:13 - INFO - __main__ -   

03/21/2023 17:20:13 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:20:13 - INFO - __main__ -    acc: 0.7233 - recall: 0.7482 - f1: 0.7356 - loss: 0.3357 
03/21/2023 17:20:13 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:20:13 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:20:13 - INFO - __main__ -    acc: 0.7845 - recall: 0.8506 - f1: 0.8162 
03/21/2023 17:20:13 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:20:13 - INFO - __main__ -    acc: 0.3956 - recall: 0.3273 - f1: 0.3582 
03/21/2023 17:20:13 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:20:13 - INFO - __main__ -    acc: 0.5870 - recall: 0.5870 - f1: 0.5870 
03/21/2023 17:20:13 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:20:13 - INFO - __main__ -    acc: 0.8214 - recall: 0.8913 - f1: 0.8549 
03/21/2023 17:20:15 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-800
03/21/2023 17:20:18 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-800
03/21/2023 17:20:18 - INFO - __main__ -   Saving best eval result model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:20:37 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:20:37 - INFO - __main__ -   


Epoch: 8/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 6:15  [ loss=0.2631 ][Training] 2/100 [..............................] - ETA: 4:47  [ loss=0.2910 ][Training] 3/100 [..............................] - ETA: 4:12  [ loss=0.2233 ][Training] 4/100 [>.............................] - ETA: 3:52  [ loss=0.2652 ][Training] 5/100 [>.............................] - ETA: 3:39  [ loss=0.2755 ][Training] 6/100 [>.............................] - ETA: 3:30  [ loss=0.2791 ][Training] 7/100 [=>............................] - ETA: 3:24  [ loss=0.2678 ][Training] 8/100 [=>............................] - ETA: 3:18  [ loss=0.2714 ][Training] 9/100 [=>............................] - ETA: 3:14  [ loss=0.2627 ][Training] 10/100 [==>...........................] - ETA: 3:09  [ loss=0.2431 ][Training] 11/100 [==>...........................] - ETA: 3:06  [ loss=0.2597 ][Training] 12/100 [==>...........................] - ETA: 3:02  [ loss=0.2850 ][Training] 13/100 [==>...........................] - ETA: 2:58  [ loss=0.2381 ][Training] 14/100 [===>..........................] - ETA: 2:55  [ loss=0.2830 ][Training] 15/100 [===>..........................] - ETA: 2:52  [ loss=0.2721 ][Training] 16/100 [===>..........................] - ETA: 2:49  [ loss=0.2831 ][Training] 17/100 [====>.........................] - ETA: 2:46  [ loss=0.2698 ][Training] 18/100 [====>.........................] - ETA: 2:43  [ loss=0.2796 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=0.2819 ][Training] 20/100 [=====>........................] - ETA: 2:38  [ loss=0.2559 ][Training] 21/100 [=====>........................] - ETA: 2:36  [ loss=0.2661 ][Training] 22/100 [=====>........................] - ETA: 2:34  [ loss=0.2463 ][Training] 23/100 [=====>........................] - ETA: 2:32  [ loss=0.2860 ][Training] 24/100 [======>.......................] - ETA: 2:29  [ loss=0.2506 ][Training] 25/100 [======>.......................] - ETA: 2:27  [ loss=0.2650 ][Training] 26/100 [======>.......................] - ETA: 2:25  [ loss=0.2803 ][Training] 27/100 [=======>......................] - ETA: 2:22  [ loss=0.2506 ][Training] 28/100 [=======>......................] - ETA: 2:20  [ loss=0.2709 ][Training] 29/100 [=======>......................] - ETA: 2:18  [ loss=0.2541 ][Training] 30/100 [========>.....................] - ETA: 2:15  [ loss=0.2642 ][Training] 31/100 [========>.....................] - ETA: 2:13  [ loss=0.2737 ][Training] 32/100 [========>.....................] - ETA: 2:11  [ loss=0.2699 ][Training] 33/100 [========>.....................] - ETA: 2:09  [ loss=0.2980 ][Training] 34/100 [=========>....................] - ETA: 2:07  [ loss=0.2348 ][Training] 35/100 [=========>....................] - ETA: 2:05  [ loss=0.2732 ][Training] 36/100 [=========>....................] - ETA: 2:03  [ loss=0.2529 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.2912 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.2482 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.2625 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.2839 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.2399 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.2574 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.2802 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.2535 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.2612 ][Training] 46/100 [============>.................] - ETA: 1:43  [ loss=0.2863 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.2331 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.2676 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.2599 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.2680 ][Training] 51/100 [==============>...............] - ETA: 1:33  [ loss=0.2627 ][Training] 52/100 [==============>...............] - ETA: 1:31  [ loss=0.2510 ][Training] 53/100 [==============>...............] - ETA: 1:29  [ loss=0.2284 ][Training] 54/100 [===============>..............] - ETA: 1:27  [ loss=0.2483 ][Training] 55/100 [===============>..............] - ETA: 1:25  [ loss=0.2520 ][Training] 56/100 [===============>..............] - ETA: 1:23  [ loss=0.2892 ][Training] 57/100 [================>.............] - ETA: 1:21  [ loss=0.2490 ][Training] 58/100 [================>.............] - ETA: 1:19  [ loss=0.2517 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.2500 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.2817 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.2811 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.2875 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.2612 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.2500 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.2562 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.2943 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.2656 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.2703 ][Training] 69/100 [===================>..........] - ETA: 58s  [ loss=0.2733 ][Training] 70/100 [====================>.........] - ETA: 56s  [ loss=0.2635 ][Training] 71/100 [====================>.........] - ETA: 54s  [ loss=0.2777 ][Training] 72/100 [====================>.........] - ETA: 52s  [ loss=0.2702 ][Training] 73/100 [====================>.........] - ETA: 50s  [ loss=0.2561 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.2475 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.2951 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.2628 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.2675 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.2472 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.2591 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.2641 ][Training] 81/100 [=======================>......] - ETA: 35s  [ loss=0.2458 ][Training] 82/100 [=======================>......] - ETA: 33s  [ loss=0.2730 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.2503 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.2360 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.2591 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.2780 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.2608 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.2539 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.2683 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.2778 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.2480 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2466 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2828 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2670 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.2727 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.2712 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.2811 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.2947 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.2475 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.2541 ]
 
03/21/2023 17:23:45 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:23:45 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:23:45 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 32s  [ loss=0.3433 ][Evaluating] 1/25 [>.............................] - ETA: 33s[Evaluating] 2/25 [=>............................] - ETA: 30s  [ loss=0.2917 ][Evaluating] 2/25 [=>............................] - ETA: 30s[Evaluating] 3/25 [==>...........................] - ETA: 29s  [ loss=0.3385 ][Evaluating] 3/25 [==>...........................] - ETA: 29s[Evaluating] 4/25 [===>..........................] - ETA: 28s  [ loss=0.2952 ][Evaluating] 4/25 [===>..........................] - ETA: 28s[Evaluating] 5/25 [=====>........................] - ETA: 27s  [ loss=0.4048 ][Evaluating] 5/25 [=====>........................] - ETA: 27s[Evaluating] 6/25 [======>.......................] - ETA: 25s  [ loss=0.3092 ][Evaluating] 6/25 [======>.......................] - ETA: 25s[Evaluating] 7/25 [=======>......................] - ETA: 24s  [ loss=0.3786 ][Evaluating] 7/25 [=======>......................] - ETA: 24s[Evaluating] 8/25 [========>.....................] - ETA: 23s  [ loss=0.3343 ][Evaluating] 8/25 [========>.....................] - ETA: 23s[Evaluating] 9/25 [=========>....................] - ETA: 21s  [ loss=0.3256 ][Evaluating] 9/25 [=========>....................] - ETA: 21s[Evaluating] 10/25 [===========>..................] - ETA: 20s  [ loss=0.3579 ][Evaluating] 10/25 [===========>..................] - ETA: 20s[Evaluating] 11/25 [============>.................] - ETA: 19s  [ loss=0.3508 ][Evaluating] 11/25 [============>.................] - ETA: 19s[Evaluating] 12/25 [=============>................] - ETA: 17s  [ loss=0.2951 ][Evaluating] 12/25 [=============>................] - ETA: 17s[Evaluating] 13/25 [==============>...............] - ETA: 16s  [ loss=0.3229 ][Evaluating] 13/25 [==============>...............] - ETA: 16s[Evaluating] 14/25 [===============>..............] - ETA: 14s  [ loss=0.3180 ][Evaluating] 14/25 [===============>..............] - ETA: 14s[Evaluating] 15/25 [=================>............] - ETA: 13s  [ loss=0.3722 ][Evaluating] 15/25 [=================>............] - ETA: 13s[Evaluating] 16/25 [==================>...........] - ETA: 12s  [ loss=0.3505 ][Evaluating] 16/25 [==================>...........] - ETA: 12s[Evaluating] 17/25 [===================>..........] - ETA: 10s  [ loss=0.3289 ][Evaluating] 17/25 [===================>..........] - ETA: 10s[Evaluating] 18/25 [====================>.........] - ETA: 9s  [ loss=0.3212 ][Evaluating] 18/25 [====================>.........] - ETA: 9s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3397 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 6s  [ loss=0.3154 ][Evaluating] 20/25 [=======================>......] - ETA: 6s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3712 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 3s  [ loss=0.3025 ][Evaluating] 22/25 [=========================>....] - ETA: 3s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3355 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3520 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.3s/step  [ loss=0.3410 ]
[Evaluating] 25/25 [==============================] 1.3s/step
03/21/2023 17:24:18 - INFO - __main__ -   

03/21/2023 17:24:18 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:24:18 - INFO - __main__ -    acc: 0.7225 - recall: 0.7450 - f1: 0.7335 - loss: 0.3358 
03/21/2023 17:24:18 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:24:18 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:24:18 - INFO - __main__ -    acc: 0.7833 - recall: 0.8448 - f1: 0.8129 
03/21/2023 17:24:18 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:24:18 - INFO - __main__ -    acc: 0.3822 - recall: 0.3318 - f1: 0.3552 
03/21/2023 17:24:18 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:24:18 - INFO - __main__ -    acc: 0.6067 - recall: 0.5870 - f1: 0.5967 
03/21/2023 17:24:18 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:24:18 - INFO - __main__ -    acc: 0.8205 - recall: 0.8859 - f1: 0.8519 
03/21/2023 17:24:20 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-900
03/21/2023 17:24:23 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-900
03/21/2023 17:24:23 - INFO - __main__ -   


Epoch: 9/10
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[Training] 1/100 [..............................] - ETA: 5:47  [ loss=0.2705 ][Training] 2/100 [..............................] - ETA: 4:33  [ loss=0.2720 ][Training] 3/100 [..............................] - ETA: 3:59  [ loss=0.2734 ][Training] 4/100 [>.............................] - ETA: 3:40  [ loss=0.2407 ][Training] 5/100 [>.............................] - ETA: 3:33  [ loss=0.2601 ][Training] 6/100 [>.............................] - ETA: 3:27  [ loss=0.2350 ][Training] 7/100 [=>............................] - ETA: 3:23  [ loss=0.2492 ][Training] 8/100 [=>............................] - ETA: 3:16  [ loss=0.2913 ][Training] 9/100 [=>............................] - ETA: 3:10  [ loss=0.2855 ][Training] 10/100 [==>...........................] - ETA: 3:06  [ loss=0.2586 ][Training] 11/100 [==>...........................] - ETA: 3:02  [ loss=0.2329 ][Training] 12/100 [==>...........................] - ETA: 2:59  [ loss=0.2275 ][Training] 13/100 [==>...........................] - ETA: 2:55  [ loss=0.2537 ][Training] 14/100 [===>..........................] - ETA: 2:52  [ loss=0.2991 ][Training] 15/100 [===>..........................] - ETA: 2:49  [ loss=0.2376 ][Training] 16/100 [===>..........................] - ETA: 2:46  [ loss=0.2492 ][Training] 17/100 [====>.........................] - ETA: 2:44  [ loss=0.2349 ][Training] 18/100 [====>.........................] - ETA: 2:42  [ loss=0.2529 ][Training] 19/100 [====>.........................] - ETA: 2:40  [ loss=0.2680 ][Training] 20/100 [=====>........................] - ETA: 2:38  [ loss=0.2683 ][Training] 21/100 [=====>........................] - ETA: 2:36  [ loss=0.2687 ][Training] 22/100 [=====>........................] - ETA: 2:33  [ loss=0.2620 ][Training] 23/100 [=====>........................] - ETA: 2:31  [ loss=0.2703 ][Training] 24/100 [======>.......................] - ETA: 2:29  [ loss=0.2510 ][Training] 25/100 [======>.......................] - ETA: 2:27  [ loss=0.2520 ][Training] 26/100 [======>.......................] - ETA: 2:25  [ loss=0.2702 ][Training] 27/100 [=======>......................] - ETA: 2:23  [ loss=0.2910 ][Training] 28/100 [=======>......................] - ETA: 2:20  [ loss=0.2745 ][Training] 29/100 [=======>......................] - ETA: 2:18  [ loss=0.2469 ][Training] 30/100 [========>.....................] - ETA: 2:16  [ loss=0.2828 ][Training] 31/100 [========>.....................] - ETA: 2:14  [ loss=0.2733 ][Training] 32/100 [========>.....................] - ETA: 2:12  [ loss=0.2696 ][Training] 33/100 [========>.....................] - ETA: 2:10  [ loss=0.2608 ][Training] 34/100 [=========>....................] - ETA: 2:08  [ loss=0.2676 ][Training] 35/100 [=========>....................] - ETA: 2:05  [ loss=0.2647 ][Training] 36/100 [=========>....................] - ETA: 2:03  [ loss=0.2748 ][Training] 37/100 [==========>...................] - ETA: 2:01  [ loss=0.2859 ][Training] 38/100 [==========>...................] - ETA: 1:59  [ loss=0.2364 ][Training] 39/100 [==========>...................] - ETA: 1:57  [ loss=0.2526 ][Training] 40/100 [===========>..................] - ETA: 1:55  [ loss=0.2498 ][Training] 41/100 [===========>..................] - ETA: 1:53  [ loss=0.2689 ][Training] 42/100 [===========>..................] - ETA: 1:51  [ loss=0.2688 ][Training] 43/100 [===========>..................] - ETA: 1:49  [ loss=0.2581 ][Training] 44/100 [============>.................] - ETA: 1:47  [ loss=0.2627 ][Training] 45/100 [============>.................] - ETA: 1:45  [ loss=0.2620 ][Training] 46/100 [============>.................] - ETA: 1:43  [ loss=0.2836 ][Training] 47/100 [=============>................] - ETA: 1:41  [ loss=0.2762 ][Training] 48/100 [=============>................] - ETA: 1:39  [ loss=0.2641 ][Training] 49/100 [=============>................] - ETA: 1:37  [ loss=0.2748 ][Training] 50/100 [==============>...............] - ETA: 1:35  [ loss=0.2507 ][Training] 51/100 [==============>...............] - ETA: 1:34  [ loss=0.2783 ][Training] 52/100 [==============>...............] - ETA: 1:32  [ loss=0.2572 ][Training] 53/100 [==============>...............] - ETA: 1:30  [ loss=0.2586 ][Training] 54/100 [===============>..............] - ETA: 1:28  [ loss=0.2642 ][Training] 55/100 [===============>..............] - ETA: 1:26  [ loss=0.2505 ][Training] 56/100 [===============>..............] - ETA: 1:24  [ loss=0.2589 ][Training] 57/100 [================>.............] - ETA: 1:22  [ loss=0.2829 ][Training] 58/100 [================>.............] - ETA: 1:20  [ loss=0.2618 ][Training] 59/100 [================>.............] - ETA: 1:18  [ loss=0.2446 ][Training] 60/100 [=================>............] - ETA: 1:16  [ loss=0.2338 ][Training] 61/100 [=================>............] - ETA: 1:14  [ loss=0.2770 ][Training] 62/100 [=================>............] - ETA: 1:12  [ loss=0.2749 ][Training] 63/100 [=================>............] - ETA: 1:10  [ loss=0.2765 ][Training] 64/100 [==================>...........] - ETA: 1:08  [ loss=0.2704 ][Training] 65/100 [==================>...........] - ETA: 1:06  [ loss=0.2403 ][Training] 66/100 [==================>...........] - ETA: 1:04  [ loss=0.2782 ][Training] 67/100 [===================>..........] - ETA: 1:02  [ loss=0.2670 ][Training] 68/100 [===================>..........] - ETA: 1:00  [ loss=0.2721 ][Training] 69/100 [===================>..........] - ETA: 59s  [ loss=0.2788 ][Training] 70/100 [====================>.........] - ETA: 57s  [ loss=0.2747 ][Training] 71/100 [====================>.........] - ETA: 55s  [ loss=0.2752 ][Training] 72/100 [====================>.........] - ETA: 53s  [ loss=0.2772 ][Training] 73/100 [====================>.........] - ETA: 51s  [ loss=0.2676 ][Training] 74/100 [=====================>........] - ETA: 49s  [ loss=0.2589 ][Training] 75/100 [=====================>........] - ETA: 47s  [ loss=0.2572 ][Training] 76/100 [=====================>........] - ETA: 45s  [ loss=0.2532 ][Training] 77/100 [======================>.......] - ETA: 43s  [ loss=0.2659 ][Training] 78/100 [======================>.......] - ETA: 41s  [ loss=0.2729 ][Training] 79/100 [======================>.......] - ETA: 39s  [ loss=0.2670 ][Training] 80/100 [=======================>......] - ETA: 37s  [ loss=0.2641 ][Training] 81/100 [=======================>......] - ETA: 36s  [ loss=0.2507 ][Training] 82/100 [=======================>......] - ETA: 34s  [ loss=0.2675 ][Training] 83/100 [=======================>......] - ETA: 32s  [ loss=0.2617 ][Training] 84/100 [========================>.....] - ETA: 30s  [ loss=0.2416 ][Training] 85/100 [========================>.....] - ETA: 28s  [ loss=0.2843 ][Training] 86/100 [========================>.....] - ETA: 26s  [ loss=0.2248 ][Training] 87/100 [=========================>....] - ETA: 24s  [ loss=0.2962 ][Training] 88/100 [=========================>....] - ETA: 22s  [ loss=0.2310 ][Training] 89/100 [=========================>....] - ETA: 20s  [ loss=0.2925 ][Training] 90/100 [==========================>...] - ETA: 18s  [ loss=0.2656 ][Training] 91/100 [==========================>...] - ETA: 16s  [ loss=0.2667 ][Training] 92/100 [==========================>...] - ETA: 15s  [ loss=0.2420 ][Training] 93/100 [==========================>...] - ETA: 13s  [ loss=0.2709 ][Training] 94/100 [===========================>..] - ETA: 11s  [ loss=0.2541 ][Training] 95/100 [===========================>..] - ETA: 9s  [ loss=0.2942 ][Training] 96/100 [===========================>..] - ETA: 7s  [ loss=0.2785 ][Training] 97/100 [============================>.] - ETA: 5s  [ loss=0.2679 ][Training] 98/100 [============================>.] - ETA: 3s  [ loss=0.2555 ][Training] 99/100 [============================>.] - ETA: 1s  [ loss=0.2607 ][Training] 100/100 [==============================] 1.9s/step  [ loss=0.2273 ]
 
03/21/2023 17:27:32 - INFO - __main__ -   ***** Running evaluation  *****
03/21/2023 17:27:32 - INFO - __main__ -     Num examples = 1000
03/21/2023 17:27:32 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/25 [>.............................] - ETA: 37s  [ loss=0.3461 ][Evaluating] 1/25 [>.............................] - ETA: 37s[Evaluating] 2/25 [=>............................] - ETA: 34s  [ loss=0.2925 ][Evaluating] 2/25 [=>............................] - ETA: 34s[Evaluating] 3/25 [==>...........................] - ETA: 33s  [ loss=0.3393 ][Evaluating] 3/25 [==>...........................] - ETA: 33s[Evaluating] 4/25 [===>..........................] - ETA: 31s  [ loss=0.2964 ][Evaluating] 4/25 [===>..........................] - ETA: 31s[Evaluating] 5/25 [=====>........................] - ETA: 30s  [ loss=0.4080 ][Evaluating] 5/25 [=====>........................] - ETA: 30s[Evaluating] 6/25 [======>.......................] - ETA: 28s  [ loss=0.3121 ][Evaluating] 6/25 [======>.......................] - ETA: 28s[Evaluating] 7/25 [=======>......................] - ETA: 26s  [ loss=0.3831 ][Evaluating] 7/25 [=======>......................] - ETA: 26s[Evaluating] 8/25 [========>.....................] - ETA: 25s  [ loss=0.3338 ][Evaluating] 8/25 [========>.....................] - ETA: 25s[Evaluating] 9/25 [=========>....................] - ETA: 24s  [ loss=0.3272 ][Evaluating] 9/25 [=========>....................] - ETA: 24s[Evaluating] 10/25 [===========>..................] - ETA: 22s  [ loss=0.3600 ][Evaluating] 10/25 [===========>..................] - ETA: 22s[Evaluating] 11/25 [============>.................] - ETA: 20s  [ loss=0.3525 ][Evaluating] 11/25 [============>.................] - ETA: 20s[Evaluating] 12/25 [=============>................] - ETA: 19s  [ loss=0.2942 ][Evaluating] 12/25 [=============>................] - ETA: 19s[Evaluating] 13/25 [==============>...............] - ETA: 17s  [ loss=0.3252 ][Evaluating] 13/25 [==============>...............] - ETA: 17s[Evaluating] 14/25 [===============>..............] - ETA: 16s  [ loss=0.3211 ][Evaluating] 14/25 [===============>..............] - ETA: 16s[Evaluating] 15/25 [=================>............] - ETA: 14s  [ loss=0.3764 ][Evaluating] 15/25 [=================>............] - ETA: 14s[Evaluating] 16/25 [==================>...........] - ETA: 13s  [ loss=0.3528 ][Evaluating] 16/25 [==================>...........] - ETA: 13s[Evaluating] 17/25 [===================>..........] - ETA: 11s  [ loss=0.3298 ][Evaluating] 17/25 [===================>..........] - ETA: 11s[Evaluating] 18/25 [====================>.........] - ETA: 10s  [ loss=0.3211 ][Evaluating] 18/25 [====================>.........] - ETA: 10s[Evaluating] 19/25 [=====================>........] - ETA: 8s  [ loss=0.3421 ][Evaluating] 19/25 [=====================>........] - ETA: 8s[Evaluating] 20/25 [=======================>......] - ETA: 7s  [ loss=0.3166 ][Evaluating] 20/25 [=======================>......] - ETA: 7s[Evaluating] 21/25 [========================>.....] - ETA: 5s  [ loss=0.3744 ][Evaluating] 21/25 [========================>.....] - ETA: 5s[Evaluating] 22/25 [=========================>....] - ETA: 4s  [ loss=0.3025 ][Evaluating] 22/25 [=========================>....] - ETA: 4s[Evaluating] 23/25 [==========================>...] - ETA: 2s  [ loss=0.3373 ][Evaluating] 23/25 [==========================>...] - ETA: 2s[Evaluating] 24/25 [===========================>..] - ETA: 1s  [ loss=0.3547 ][Evaluating] 24/25 [===========================>..] - ETA: 1s[Evaluating] 25/25 [==============================] 1.5s/step  [ loss=0.3402 ]
[Evaluating] 25/25 [==============================] 1.5s/step
03/21/2023 17:28:10 - INFO - __main__ -   

03/21/2023 17:28:10 - INFO - __main__ -   ***** Eval results  *****
03/21/2023 17:28:10 - INFO - __main__ -    acc: 0.7236 - recall: 0.7424 - f1: 0.7329 - loss: 0.3376 
03/21/2023 17:28:10 - INFO - __main__ -   ***** Entity results  *****
03/21/2023 17:28:10 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:28:10 - INFO - __main__ -    acc: 0.7782 - recall: 0.8467 - f1: 0.8110 
03/21/2023 17:28:10 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:28:10 - INFO - __main__ -    acc: 0.3770 - recall: 0.3136 - f1: 0.3424 
03/21/2023 17:28:10 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:28:10 - INFO - __main__ -    acc: 0.6186 - recall: 0.5911 - f1: 0.6046 
03/21/2023 17:28:10 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:28:10 - INFO - __main__ -    acc: 0.8199 - recall: 0.8822 - f1: 0.8499 
03/21/2023 17:28:12 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-1000
03/21/2023 17:28:16 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/checkpoint-1000
03/21/2023 17:28:16 - INFO - __main__ -   

03/21/2023 17:28:16 - INFO - __main__ -   Saving model checkpoint to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:28:21 - INFO - __main__ -   Saving optimizer and scheduler states to ../outputs/twitter15_output/alpha0.001_beta0.001_theta0.1_sigma1.0_rs1_re3_cls0_l6_lr5e-5_clr5e-5_uncased_cd0.2_last/
03/21/2023 17:28:22 - INFO - __main__ -   Test on best eval model
03/21/2023 17:28:24 - INFO - __main__ -   ***** Running evaluation test best *****
03/21/2023 17:28:24 - INFO - __main__ -     Num examples = 3257
03/21/2023 17:28:24 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/81 [..............................] - ETA: 2:16  [ loss=0.3566 ][Evaluating] 1/81 [..............................] - ETA: 2:17[Evaluating] 2/81 [..............................] - ETA: 2:01  [ loss=0.3158 ][Evaluating] 2/81 [..............................] - ETA: 2:01[Evaluating] 3/81 [>.............................] - ETA: 1:54  [ loss=0.3512 ][Evaluating] 3/81 [>.............................] - ETA: 1:55[Evaluating] 4/81 [>.............................] - ETA: 1:50  [ loss=0.3201 ][Evaluating] 4/81 [>.............................] - ETA: 1:50[Evaluating] 5/81 [>.............................] - ETA: 1:47  [ loss=0.3180 ][Evaluating] 5/81 [>.............................] - ETA: 1:47[Evaluating] 6/81 [=>............................] - ETA: 1:45  [ loss=0.3580 ][Evaluating] 6/81 [=>............................] - ETA: 1:45[Evaluating] 7/81 [=>............................] - ETA: 1:44  [ loss=0.3533 ][Evaluating] 7/81 [=>............................] - ETA: 1:44[Evaluating] 8/81 [=>............................] - ETA: 1:42  [ loss=0.2918 ][Evaluating] 8/81 [=>............................] - ETA: 1:42[Evaluating] 9/81 [==>...........................] - ETA: 1:40  [ loss=0.3328 ][Evaluating] 9/81 [==>...........................] - ETA: 1:40[Evaluating] 10/81 [==>...........................] - ETA: 1:38  [ loss=0.3577 ][Evaluating] 10/81 [==>...........................] - ETA: 1:38[Evaluating] 11/81 [===>..........................] - ETA: 1:37  [ loss=0.3678 ][Evaluating] 11/81 [===>..........................] - ETA: 1:37[Evaluating] 12/81 [===>..........................] - ETA: 1:35  [ loss=0.3496 ][Evaluating] 12/81 [===>..........................] - ETA: 1:35[Evaluating] 13/81 [===>..........................] - ETA: 1:33  [ loss=0.2959 ][Evaluating] 13/81 [===>..........................] - ETA: 1:33[Evaluating] 14/81 [====>.........................] - ETA: 1:32  [ loss=0.3496 ][Evaluating] 14/81 [====>.........................] - ETA: 1:32[Evaluating] 15/81 [====>.........................] - ETA: 1:31  [ loss=0.3062 ][Evaluating] 15/81 [====>.........................] - ETA: 1:31[Evaluating] 16/81 [====>.........................] - ETA: 1:30  [ loss=0.3625 ][Evaluating] 16/81 [====>.........................] - ETA: 1:30[Evaluating] 17/81 [=====>........................] - ETA: 1:28  [ loss=0.3579 ][Evaluating] 17/81 [=====>........................] - ETA: 1:28[Evaluating] 18/81 [=====>........................] - ETA: 1:27  [ loss=0.3102 ][Evaluating] 18/81 [=====>........................] - ETA: 1:27[Evaluating] 19/81 [======>.......................] - ETA: 1:25  [ loss=0.3198 ][Evaluating] 19/81 [======>.......................] - ETA: 1:27[Evaluating] 20/81 [======>.......................] - ETA: 1:25  [ loss=0.3179 ][Evaluating] 20/81 [======>.......................] - ETA: 1:25[Evaluating] 21/81 [======>.......................] - ETA: 1:24  [ loss=0.3369 ][Evaluating] 21/81 [======>.......................] - ETA: 1:24[Evaluating] 22/81 [=======>......................] - ETA: 1:22  [ loss=0.3335 ][Evaluating] 22/81 [=======>......................] - ETA: 1:22[Evaluating] 23/81 [=======>......................] - ETA: 1:20  [ loss=0.3221 ][Evaluating] 23/81 [=======>......................] - ETA: 1:20[Evaluating] 24/81 [=======>......................] - ETA: 1:19  [ loss=0.3829 ][Evaluating] 24/81 [=======>......................] - ETA: 1:19[Evaluating] 25/81 [========>.....................] - ETA: 1:17  [ loss=0.3462 ][Evaluating] 25/81 [========>.....................] - ETA: 1:17[Evaluating] 26/81 [========>.....................] - ETA: 1:16  [ loss=0.3256 ][Evaluating] 26/81 [========>.....................] - ETA: 1:16[Evaluating] 27/81 [=========>....................] - ETA: 1:14  [ loss=0.3294 ][Evaluating] 27/81 [=========>....................] - ETA: 1:14[Evaluating] 28/81 [=========>....................] - ETA: 1:12  [ loss=0.3287 ][Evaluating] 28/81 [=========>....................] - ETA: 1:12[Evaluating] 29/81 [=========>....................] - ETA: 1:11  [ loss=0.3132 ][Evaluating] 29/81 [=========>....................] - ETA: 1:11[Evaluating] 30/81 [==========>...................] - ETA: 1:09  [ loss=0.3445 ][Evaluating] 30/81 [==========>...................] - ETA: 1:09[Evaluating] 31/81 [==========>...................] - ETA: 1:08  [ loss=0.3338 ][Evaluating] 31/81 [==========>...................] - ETA: 1:08[Evaluating] 32/81 [==========>...................] - ETA: 1:06  [ loss=0.3061 ][Evaluating] 32/81 [==========>...................] - ETA: 1:06[Evaluating] 33/81 [===========>..................] - ETA: 1:05  [ loss=0.3309 ][Evaluating] 33/81 [===========>..................] - ETA: 1:05[Evaluating] 34/81 [===========>..................] - ETA: 1:03  [ loss=0.3413 ][Evaluating] 34/81 [===========>..................] - ETA: 1:03[Evaluating] 35/81 [===========>..................] - ETA: 1:02  [ loss=0.3300 ][Evaluating] 35/81 [===========>..................] - ETA: 1:02[Evaluating] 36/81 [============>.................] - ETA: 1:00  [ loss=0.3721 ][Evaluating] 36/81 [============>.................] - ETA: 1:00[Evaluating] 37/81 [============>.................] - ETA: 59s  [ loss=0.3419 ][Evaluating] 37/81 [============>.................] - ETA: 59s[Evaluating] 38/81 [=============>................] - ETA: 57s  [ loss=0.3223 ][Evaluating] 38/81 [=============>................] - ETA: 57s[Evaluating] 39/81 [=============>................] - ETA: 56s  [ loss=0.3676 ][Evaluating] 39/81 [=============>................] - ETA: 56s[Evaluating] 40/81 [=============>................] - ETA: 55s  [ loss=0.3373 ][Evaluating] 40/81 [=============>................] - ETA: 55s[Evaluating] 41/81 [==============>...............] - ETA: 53s  [ loss=0.3194 ][Evaluating] 41/81 [==============>...............] - ETA: 53s[Evaluating] 42/81 [==============>...............] - ETA: 52s  [ loss=0.3300 ][Evaluating] 42/81 [==============>...............] - ETA: 52s[Evaluating] 43/81 [==============>...............] - ETA: 51s  [ loss=0.3688 ][Evaluating] 43/81 [==============>...............] - ETA: 51s[Evaluating] 44/81 [===============>..............] - ETA: 49s  [ loss=0.2724 ][Evaluating] 44/81 [===============>..............] - ETA: 49s[Evaluating] 45/81 [===============>..............] - ETA: 48s  [ loss=0.3133 ][Evaluating] 45/81 [===============>..............] - ETA: 48s[Evaluating] 46/81 [================>.............] - ETA: 46s  [ loss=0.3279 ][Evaluating] 46/81 [================>.............] - ETA: 46s[Evaluating] 47/81 [================>.............] - ETA: 45s  [ loss=0.3430 ][Evaluating] 47/81 [================>.............] - ETA: 45s[Evaluating] 48/81 [================>.............] - ETA: 44s  [ loss=0.3657 ][Evaluating] 48/81 [================>.............] - ETA: 44s[Evaluating] 49/81 [=================>............] - ETA: 42s  [ loss=0.3245 ][Evaluating] 49/81 [=================>............] - ETA: 42s[Evaluating] 50/81 [=================>............] - ETA: 41s  [ loss=0.3387 ][Evaluating] 50/81 [=================>............] - ETA: 41s[Evaluating] 51/81 [=================>............] - ETA: 40s  [ loss=0.3729 ][Evaluating] 51/81 [=================>............] - ETA: 40s[Evaluating] 52/81 [==================>...........] - ETA: 38s  [ loss=0.3162 ][Evaluating] 52/81 [==================>...........] - ETA: 38s[Evaluating] 53/81 [==================>...........] - ETA: 37s  [ loss=0.3302 ][Evaluating] 53/81 [==================>...........] - ETA: 37s[Evaluating] 54/81 [===================>..........] - ETA: 36s  [ loss=0.3373 ][Evaluating] 54/81 [===================>..........] - ETA: 36s[Evaluating] 55/81 [===================>..........] - ETA: 34s  [ loss=0.3418 ][Evaluating] 55/81 [===================>..........] - ETA: 34s[Evaluating] 56/81 [===================>..........] - ETA: 33s  [ loss=0.3412 ][Evaluating] 56/81 [===================>..........] - ETA: 33s[Evaluating] 57/81 [====================>.........] - ETA: 32s  [ loss=0.3330 ][Evaluating] 57/81 [====================>.........] - ETA: 32s[Evaluating] 58/81 [====================>.........] - ETA: 30s  [ loss=0.3308 ][Evaluating] 58/81 [====================>.........] - ETA: 30s[Evaluating] 59/81 [====================>.........] - ETA: 29s  [ loss=0.3145 ][Evaluating] 59/81 [====================>.........] - ETA: 29s[Evaluating] 60/81 [=====================>........] - ETA: 28s  [ loss=0.3050 ][Evaluating] 60/81 [=====================>........] - ETA: 28s[Evaluating] 61/81 [=====================>........] - ETA: 26s  [ loss=0.3396 ][Evaluating] 61/81 [=====================>........] - ETA: 26s[Evaluating] 62/81 [=====================>........] - ETA: 25s  [ loss=0.3606 ][Evaluating] 62/81 [=====================>........] - ETA: 25s[Evaluating] 63/81 [======================>.......] - ETA: 24s  [ loss=0.2940 ][Evaluating] 63/81 [======================>.......] - ETA: 24s[Evaluating] 64/81 [======================>.......] - ETA: 22s  [ loss=0.2983 ][Evaluating] 64/81 [======================>.......] - ETA: 22s[Evaluating] 65/81 [=======================>......] - ETA: 21s  [ loss=0.3511 ][Evaluating] 65/81 [=======================>......] - ETA: 21s[Evaluating] 66/81 [=======================>......] - ETA: 20s  [ loss=0.3742 ][Evaluating] 66/81 [=======================>......] - ETA: 20s[Evaluating] 67/81 [=======================>......] - ETA: 18s  [ loss=0.3736 ][Evaluating] 67/81 [=======================>......] - ETA: 18s[Evaluating] 68/81 [========================>.....] - ETA: 17s  [ loss=0.3349 ][Evaluating] 68/81 [========================>.....] - ETA: 17s[Evaluating] 69/81 [========================>.....] - ETA: 16s  [ loss=0.3137 ][Evaluating] 69/81 [========================>.....] - ETA: 16s[Evaluating] 70/81 [========================>.....] - ETA: 14s  [ loss=0.3373 ][Evaluating] 70/81 [========================>.....] - ETA: 14s[Evaluating] 71/81 [=========================>....] - ETA: 13s  [ loss=0.3889 ][Evaluating] 71/81 [=========================>....] - ETA: 13s[Evaluating] 72/81 [=========================>....] - ETA: 12s  [ loss=0.3922 ][Evaluating] 72/81 [=========================>....] - ETA: 12s[Evaluating] 73/81 [==========================>...] - ETA: 10s  [ loss=0.3383 ][Evaluating] 73/81 [==========================>...] - ETA: 10s[Evaluating] 74/81 [==========================>...] - ETA: 9s  [ loss=0.3177 ][Evaluating] 74/81 [==========================>...] - ETA: 9s[Evaluating] 75/81 [==========================>...] - ETA: 8s  [ loss=0.3551 ][Evaluating] 75/81 [==========================>...] - ETA: 8s[Evaluating] 76/81 [===========================>..] - ETA: 6s  [ loss=0.3407 ][Evaluating] 76/81 [===========================>..] - ETA: 6s[Evaluating] 77/81 [===========================>..] - ETA: 5s  [ loss=0.2930 ][Evaluating] 77/81 [===========================>..] - ETA: 5s[Evaluating] 78/81 [===========================>..] - ETA: 4s  [ loss=0.2700 ][Evaluating] 78/81 [===========================>..] - ETA: 4s[Evaluating] 79/81 [============================>.] - ETA: 2s  [ loss=0.3169 ][Evaluating] 79/81 [============================>.] - ETA: 2s[Evaluating] 80/81 [============================>.] - ETA: 1s  [ loss=0.3274 ][Evaluating] 80/81 [============================>.] - ETA: 1s[Evaluating] 81/81 [==============================] 1.4s/step  [ loss=0.3222 ]
[Evaluating] 81/81 [==============================] 1.4s/step
03/21/2023 17:30:14 - INFO - __main__ -   

03/21/2023 17:30:14 - INFO - __main__ -   ***** Eval results test best *****
03/21/2023 17:30:14 - INFO - __main__ -    acc: 0.7282 - recall: 0.7592 - f1: 0.7434 - loss: 0.3346 
03/21/2023 17:30:14 - INFO - __main__ -   ***** Entity results test best *****
03/21/2023 17:30:14 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:30:14 - INFO - __main__ -    acc: 0.7980 - recall: 0.8700 - f1: 0.8325 
03/21/2023 17:30:14 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:30:14 - INFO - __main__ -    acc: 0.3901 - recall: 0.3212 - f1: 0.3523 
03/21/2023 17:30:14 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:30:14 - INFO - __main__ -    acc: 0.6050 - recall: 0.6340 - f1: 0.6192 
03/21/2023 17:30:14 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:30:14 - INFO - __main__ -    acc: 0.8196 - recall: 0.8869 - f1: 0.8519 
03/21/2023 17:30:14 - INFO - __main__ -   Test on best eval loss model
03/21/2023 17:30:15 - INFO - __main__ -   ***** Running evaluation test best_loss *****
03/21/2023 17:30:15 - INFO - __main__ -     Num examples = 3257
03/21/2023 17:30:15 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/81 [..............................] - ETA: 1:56  [ loss=0.3400 ][Evaluating] 1/81 [..............................] - ETA: 1:57[Evaluating] 2/81 [..............................] - ETA: 1:50  [ loss=0.2965 ][Evaluating] 2/81 [..............................] - ETA: 1:51[Evaluating] 3/81 [>.............................] - ETA: 1:49  [ loss=0.3274 ][Evaluating] 3/81 [>.............................] - ETA: 1:49[Evaluating] 4/81 [>.............................] - ETA: 1:46  [ loss=0.3208 ][Evaluating] 4/81 [>.............................] - ETA: 1:46[Evaluating] 5/81 [>.............................] - ETA: 1:44  [ loss=0.3116 ][Evaluating] 5/81 [>.............................] - ETA: 1:44[Evaluating] 6/81 [=>............................] - ETA: 1:43  [ loss=0.3495 ][Evaluating] 6/81 [=>............................] - ETA: 1:43[Evaluating] 7/81 [=>............................] - ETA: 1:41  [ loss=0.3274 ][Evaluating] 7/81 [=>............................] - ETA: 1:41[Evaluating] 8/81 [=>............................] - ETA: 1:40  [ loss=0.2945 ][Evaluating] 8/81 [=>............................] - ETA: 1:40[Evaluating] 9/81 [==>...........................] - ETA: 1:38  [ loss=0.3231 ][Evaluating] 9/81 [==>...........................] - ETA: 1:38[Evaluating] 10/81 [==>...........................] - ETA: 1:36  [ loss=0.3485 ][Evaluating] 10/81 [==>...........................] - ETA: 1:36[Evaluating] 11/81 [===>..........................] - ETA: 1:35  [ loss=0.3418 ][Evaluating] 11/81 [===>..........................] - ETA: 1:35[Evaluating] 12/81 [===>..........................] - ETA: 1:33  [ loss=0.3433 ][Evaluating] 12/81 [===>..........................] - ETA: 1:33[Evaluating] 13/81 [===>..........................] - ETA: 1:32  [ loss=0.2807 ][Evaluating] 13/81 [===>..........................] - ETA: 1:32[Evaluating] 14/81 [====>.........................] - ETA: 1:31  [ loss=0.3464 ][Evaluating] 14/81 [====>.........................] - ETA: 1:31[Evaluating] 15/81 [====>.........................] - ETA: 1:29  [ loss=0.3025 ][Evaluating] 15/81 [====>.........................] - ETA: 1:30[Evaluating] 16/81 [====>.........................] - ETA: 1:28  [ loss=0.3506 ][Evaluating] 16/81 [====>.........................] - ETA: 1:28[Evaluating] 17/81 [=====>........................] - ETA: 1:27  [ loss=0.3409 ][Evaluating] 17/81 [=====>........................] - ETA: 1:27[Evaluating] 18/81 [=====>........................] - ETA: 1:26  [ loss=0.3075 ][Evaluating] 18/81 [=====>........................] - ETA: 1:26[Evaluating] 19/81 [======>.......................] - ETA: 1:24  [ loss=0.3029 ][Evaluating] 19/81 [======>.......................] - ETA: 1:24[Evaluating] 20/81 [======>.......................] - ETA: 1:23  [ loss=0.3097 ][Evaluating] 20/81 [======>.......................] - ETA: 1:23[Evaluating] 21/81 [======>.......................] - ETA: 1:22  [ loss=0.3236 ][Evaluating] 21/81 [======>.......................] - ETA: 1:22[Evaluating] 22/81 [=======>......................] - ETA: 1:20  [ loss=0.3160 ][Evaluating] 22/81 [=======>......................] - ETA: 1:20[Evaluating] 23/81 [=======>......................] - ETA: 1:19  [ loss=0.3208 ][Evaluating] 23/81 [=======>......................] - ETA: 1:19[Evaluating] 24/81 [=======>......................] - ETA: 1:17  [ loss=0.3539 ][Evaluating] 24/81 [=======>......................] - ETA: 1:18[Evaluating] 25/81 [========>.....................] - ETA: 1:16  [ loss=0.3420 ][Evaluating] 25/81 [========>.....................] - ETA: 1:16[Evaluating] 26/81 [========>.....................] - ETA: 1:15  [ loss=0.3158 ][Evaluating] 26/81 [========>.....................] - ETA: 1:15[Evaluating] 27/81 [=========>....................] - ETA: 1:13  [ loss=0.3311 ][Evaluating] 27/81 [=========>....................] - ETA: 1:13[Evaluating] 28/81 [=========>....................] - ETA: 1:12  [ loss=0.3257 ][Evaluating] 28/81 [=========>....................] - ETA: 1:12[Evaluating] 29/81 [=========>....................] - ETA: 1:10  [ loss=0.3242 ][Evaluating] 29/81 [=========>....................] - ETA: 1:10[Evaluating] 30/81 [==========>...................] - ETA: 1:09  [ loss=0.3335 ][Evaluating] 30/81 [==========>...................] - ETA: 1:09[Evaluating] 31/81 [==========>...................] - ETA: 1:08  [ loss=0.3321 ][Evaluating] 31/81 [==========>...................] - ETA: 1:08[Evaluating] 32/81 [==========>...................] - ETA: 1:07  [ loss=0.3083 ][Evaluating] 32/81 [==========>...................] - ETA: 1:07[Evaluating] 33/81 [===========>..................] - ETA: 1:05  [ loss=0.3286 ][Evaluating] 33/81 [===========>..................] - ETA: 1:05[Evaluating] 34/81 [===========>..................] - ETA: 1:04  [ loss=0.3390 ][Evaluating] 34/81 [===========>..................] - ETA: 1:04[Evaluating] 35/81 [===========>..................] - ETA: 1:03  [ loss=0.3149 ][Evaluating] 35/81 [===========>..................] - ETA: 1:03[Evaluating] 36/81 [============>.................] - ETA: 1:01  [ loss=0.3552 ][Evaluating] 36/81 [============>.................] - ETA: 1:01[Evaluating] 37/81 [============>.................] - ETA: 1:00  [ loss=0.3395 ][Evaluating] 37/81 [============>.................] - ETA: 1:00[Evaluating] 38/81 [=============>................] - ETA: 58s  [ loss=0.3187 ][Evaluating] 38/81 [=============>................] - ETA: 58s[Evaluating] 39/81 [=============>................] - ETA: 57s  [ loss=0.3379 ][Evaluating] 39/81 [=============>................] - ETA: 57s[Evaluating] 40/81 [=============>................] - ETA: 56s  [ loss=0.3264 ][Evaluating] 40/81 [=============>................] - ETA: 56s[Evaluating] 41/81 [==============>...............] - ETA: 54s  [ loss=0.3278 ][Evaluating] 41/81 [==============>...............] - ETA: 54s[Evaluating] 42/81 [==============>...............] - ETA: 53s  [ loss=0.3370 ][Evaluating] 42/81 [==============>...............] - ETA: 53s[Evaluating] 43/81 [==============>...............] - ETA: 51s  [ loss=0.3560 ][Evaluating] 43/81 [==============>...............] - ETA: 51s[Evaluating] 44/81 [===============>..............] - ETA: 50s  [ loss=0.2737 ][Evaluating] 44/81 [===============>..............] - ETA: 50s[Evaluating] 45/81 [===============>..............] - ETA: 49s  [ loss=0.3130 ][Evaluating] 45/81 [===============>..............] - ETA: 49s[Evaluating] 46/81 [================>.............] - ETA: 47s  [ loss=0.3187 ][Evaluating] 46/81 [================>.............] - ETA: 47s[Evaluating] 47/81 [================>.............] - ETA: 46s  [ loss=0.3369 ][Evaluating] 47/81 [================>.............] - ETA: 46s[Evaluating] 48/81 [================>.............] - ETA: 45s  [ loss=0.3685 ][Evaluating] 48/81 [================>.............] - ETA: 45s[Evaluating] 49/81 [=================>............] - ETA: 43s  [ loss=0.3264 ][Evaluating] 49/81 [=================>............] - ETA: 43s[Evaluating] 50/81 [=================>............] - ETA: 42s  [ loss=0.3306 ][Evaluating] 50/81 [=================>............] - ETA: 42s[Evaluating] 51/81 [=================>............] - ETA: 41s  [ loss=0.3558 ][Evaluating] 51/81 [=================>............] - ETA: 41s[Evaluating] 52/81 [==================>...........] - ETA: 39s  [ loss=0.3143 ][Evaluating] 52/81 [==================>...........] - ETA: 39s[Evaluating] 53/81 [==================>...........] - ETA: 38s  [ loss=0.3193 ][Evaluating] 53/81 [==================>...........] - ETA: 38s[Evaluating] 54/81 [===================>..........] - ETA: 36s  [ loss=0.3195 ][Evaluating] 54/81 [===================>..........] - ETA: 36s[Evaluating] 55/81 [===================>..........] - ETA: 35s  [ loss=0.3313 ][Evaluating] 55/81 [===================>..........] - ETA: 35s[Evaluating] 56/81 [===================>..........] - ETA: 34s  [ loss=0.3297 ][Evaluating] 56/81 [===================>..........] - ETA: 34s[Evaluating] 57/81 [====================>.........] - ETA: 32s  [ loss=0.3234 ][Evaluating] 57/81 [====================>.........] - ETA: 32s[Evaluating] 58/81 [====================>.........] - ETA: 31s  [ loss=0.3348 ][Evaluating] 58/81 [====================>.........] - ETA: 31s[Evaluating] 59/81 [====================>.........] - ETA: 30s  [ loss=0.2970 ][Evaluating] 59/81 [====================>.........] - ETA: 30s[Evaluating] 60/81 [=====================>........] - ETA: 28s  [ loss=0.3053 ][Evaluating] 60/81 [=====================>........] - ETA: 28s[Evaluating] 61/81 [=====================>........] - ETA: 27s  [ loss=0.3289 ][Evaluating] 61/81 [=====================>........] - ETA: 27s[Evaluating] 62/81 [=====================>........] - ETA: 26s  [ loss=0.3689 ][Evaluating] 62/81 [=====================>........] - ETA: 26s[Evaluating] 63/81 [======================>.......] - ETA: 24s  [ loss=0.2842 ][Evaluating] 63/81 [======================>.......] - ETA: 24s[Evaluating] 64/81 [======================>.......] - ETA: 23s  [ loss=0.2934 ][Evaluating] 64/81 [======================>.......] - ETA: 23s[Evaluating] 65/81 [=======================>......] - ETA: 21s  [ loss=0.3331 ][Evaluating] 65/81 [=======================>......] - ETA: 21s[Evaluating] 66/81 [=======================>......] - ETA: 20s  [ loss=0.3568 ][Evaluating] 66/81 [=======================>......] - ETA: 20s[Evaluating] 67/81 [=======================>......] - ETA: 19s  [ loss=0.3649 ][Evaluating] 67/81 [=======================>......] - ETA: 19s[Evaluating] 68/81 [========================>.....] - ETA: 17s  [ loss=0.3356 ][Evaluating] 68/81 [========================>.....] - ETA: 17s[Evaluating] 69/81 [========================>.....] - ETA: 16s  [ loss=0.3168 ][Evaluating] 69/81 [========================>.....] - ETA: 16s[Evaluating] 70/81 [========================>.....] - ETA: 15s  [ loss=0.3144 ][Evaluating] 70/81 [========================>.....] - ETA: 15s[Evaluating] 71/81 [=========================>....] - ETA: 13s  [ loss=0.3719 ][Evaluating] 71/81 [=========================>....] - ETA: 13s[Evaluating] 72/81 [=========================>....] - ETA: 12s  [ loss=0.3670 ][Evaluating] 72/81 [=========================>....] - ETA: 12s[Evaluating] 73/81 [==========================>...] - ETA: 11s  [ loss=0.3311 ][Evaluating] 73/81 [==========================>...] - ETA: 11s[Evaluating] 74/81 [==========================>...] - ETA: 9s  [ loss=0.3158 ][Evaluating] 74/81 [==========================>...] - ETA: 9s[Evaluating] 75/81 [==========================>...] - ETA: 8s  [ loss=0.3338 ][Evaluating] 75/81 [==========================>...] - ETA: 8s[Evaluating] 76/81 [===========================>..] - ETA: 6s  [ loss=0.3236 ][Evaluating] 76/81 [===========================>..] - ETA: 6s[Evaluating] 77/81 [===========================>..] - ETA: 5s  [ loss=0.2880 ][Evaluating] 77/81 [===========================>..] - ETA: 5s[Evaluating] 78/81 [===========================>..] - ETA: 4s  [ loss=0.2750 ][Evaluating] 78/81 [===========================>..] - ETA: 4s[Evaluating] 79/81 [============================>.] - ETA: 2s  [ loss=0.3013 ][Evaluating] 79/81 [============================>.] - ETA: 2s[Evaluating] 80/81 [============================>.] - ETA: 1s  [ loss=0.3162 ][Evaluating] 80/81 [============================>.] - ETA: 1s[Evaluating] 81/81 [==============================] 1.4s/step  [ loss=0.3251 ]
[Evaluating] 81/81 [==============================] 1.4s/step
03/21/2023 17:32:07 - INFO - __main__ -   

03/21/2023 17:32:07 - INFO - __main__ -   ***** Eval results test best_loss *****
03/21/2023 17:32:07 - INFO - __main__ -    acc: 0.7250 - recall: 0.7373 - f1: 0.7311 - loss: 0.3261 
03/21/2023 17:32:07 - INFO - __main__ -   ***** Entity results test best_loss *****
03/21/2023 17:32:07 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:32:07 - INFO - __main__ -    acc: 0.7885 - recall: 0.8499 - f1: 0.8181 
03/21/2023 17:32:07 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:32:07 - INFO - __main__ -    acc: 0.3588 - recall: 0.2833 - f1: 0.3166 
03/21/2023 17:32:07 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:32:07 - INFO - __main__ -    acc: 0.6292 - recall: 0.5622 - f1: 0.5938 
03/21/2023 17:32:07 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:32:07 - INFO - __main__ -    acc: 0.8062 - recall: 0.8930 - f1: 0.8474 
03/21/2023 17:32:07 - INFO - __main__ -   Test on last eval model
03/21/2023 17:32:08 - INFO - __main__ -   ***** Running evaluation test last *****
03/21/2023 17:32:08 - INFO - __main__ -     Num examples = 3257
03/21/2023 17:32:08 - INFO - __main__ -     Batch size = 40
[Evaluating] 1/81 [..............................] - ETA: 1:49  [ loss=0.3595 ][Evaluating] 1/81 [..............................] - ETA: 1:50[Evaluating] 2/81 [..............................] - ETA: 1:48  [ loss=0.3137 ][Evaluating] 2/81 [..............................] - ETA: 1:48[Evaluating] 3/81 [>.............................] - ETA: 1:45  [ loss=0.3589 ][Evaluating] 3/81 [>.............................] - ETA: 1:45[Evaluating] 4/81 [>.............................] - ETA: 1:45  [ loss=0.3188 ][Evaluating] 4/81 [>.............................] - ETA: 1:45[Evaluating] 5/81 [>.............................] - ETA: 1:45  [ loss=0.3161 ][Evaluating] 5/81 [>.............................] - ETA: 1:45[Evaluating] 6/81 [=>............................] - ETA: 1:43  [ loss=0.3584 ][Evaluating] 6/81 [=>............................] - ETA: 1:43[Evaluating] 7/81 [=>............................] - ETA: 1:42  [ loss=0.3605 ][Evaluating] 7/81 [=>............................] - ETA: 1:42[Evaluating] 8/81 [=>............................] - ETA: 1:40  [ loss=0.2922 ][Evaluating] 8/81 [=>............................] - ETA: 1:40[Evaluating] 9/81 [==>...........................] - ETA: 1:39  [ loss=0.3346 ][Evaluating] 9/81 [==>...........................] - ETA: 1:39[Evaluating] 10/81 [==>...........................] - ETA: 1:38  [ loss=0.3608 ][Evaluating] 10/81 [==>...........................] - ETA: 1:38[Evaluating] 11/81 [===>..........................] - ETA: 1:37  [ loss=0.3750 ][Evaluating] 11/81 [===>..........................] - ETA: 1:37[Evaluating] 12/81 [===>..........................] - ETA: 1:35  [ loss=0.3501 ][Evaluating] 12/81 [===>..........................] - ETA: 1:35[Evaluating] 13/81 [===>..........................] - ETA: 1:34  [ loss=0.2954 ][Evaluating] 13/81 [===>..........................] - ETA: 1:34[Evaluating] 14/81 [====>.........................] - ETA: 1:32  [ loss=0.3568 ][Evaluating] 14/81 [====>.........................] - ETA: 1:32[Evaluating] 15/81 [====>.........................] - ETA: 1:30  [ loss=0.3036 ][Evaluating] 15/81 [====>.........................] - ETA: 1:30[Evaluating] 16/81 [====>.........................] - ETA: 1:29  [ loss=0.3616 ][Evaluating] 16/81 [====>.........................] - ETA: 1:29[Evaluating] 17/81 [=====>........................] - ETA: 1:27  [ loss=0.3563 ][Evaluating] 17/81 [=====>........................] - ETA: 1:27[Evaluating] 18/81 [=====>........................] - ETA: 1:26  [ loss=0.3031 ][Evaluating] 18/81 [=====>........................] - ETA: 1:26[Evaluating] 19/81 [======>.......................] - ETA: 1:25  [ loss=0.3227 ][Evaluating] 19/81 [======>.......................] - ETA: 1:25[Evaluating] 20/81 [======>.......................] - ETA: 1:23  [ loss=0.3193 ][Evaluating] 20/81 [======>.......................] - ETA: 1:23[Evaluating] 21/81 [======>.......................] - ETA: 1:22  [ loss=0.3353 ][Evaluating] 21/81 [======>.......................] - ETA: 1:22[Evaluating] 22/81 [=======>......................] - ETA: 1:21  [ loss=0.3327 ][Evaluating] 22/81 [=======>......................] - ETA: 1:21[Evaluating] 23/81 [=======>......................] - ETA: 1:19  [ loss=0.3207 ][Evaluating] 23/81 [=======>......................] - ETA: 1:19[Evaluating] 24/81 [=======>......................] - ETA: 1:18  [ loss=0.3846 ][Evaluating] 24/81 [=======>......................] - ETA: 1:18[Evaluating] 25/81 [========>.....................] - ETA: 1:17  [ loss=0.3540 ][Evaluating] 25/81 [========>.....................] - ETA: 1:17[Evaluating] 26/81 [========>.....................] - ETA: 1:15  [ loss=0.3231 ][Evaluating] 26/81 [========>.....................] - ETA: 1:15[Evaluating] 27/81 [=========>....................] - ETA: 1:14  [ loss=0.3300 ][Evaluating] 27/81 [=========>....................] - ETA: 1:14[Evaluating] 28/81 [=========>....................] - ETA: 1:13  [ loss=0.3279 ][Evaluating] 28/81 [=========>....................] - ETA: 1:13[Evaluating] 29/81 [=========>....................] - ETA: 1:11  [ loss=0.3130 ][Evaluating] 29/81 [=========>....................] - ETA: 1:11[Evaluating] 30/81 [==========>...................] - ETA: 1:10  [ loss=0.3442 ][Evaluating] 30/81 [==========>...................] - ETA: 1:10[Evaluating] 31/81 [==========>...................] - ETA: 1:09  [ loss=0.3425 ][Evaluating] 31/81 [==========>...................] - ETA: 1:09[Evaluating] 32/81 [==========>...................] - ETA: 1:07  [ loss=0.3041 ][Evaluating] 32/81 [==========>...................] - ETA: 1:07[Evaluating] 33/81 [===========>..................] - ETA: 1:06  [ loss=0.3323 ][Evaluating] 33/81 [===========>..................] - ETA: 1:06[Evaluating] 34/81 [===========>..................] - ETA: 1:05  [ loss=0.3418 ][Evaluating] 34/81 [===========>..................] - ETA: 1:05[Evaluating] 35/81 [===========>..................] - ETA: 1:03  [ loss=0.3342 ][Evaluating] 35/81 [===========>..................] - ETA: 1:03[Evaluating] 36/81 [============>.................] - ETA: 1:02  [ loss=0.3795 ][Evaluating] 36/81 [============>.................] - ETA: 1:02[Evaluating] 37/81 [============>.................] - ETA: 1:01  [ loss=0.3523 ][Evaluating] 37/81 [============>.................] - ETA: 1:01[Evaluating] 38/81 [=============>................] - ETA: 59s  [ loss=0.3180 ][Evaluating] 38/81 [=============>................] - ETA: 59s[Evaluating] 39/81 [=============>................] - ETA: 58s  [ loss=0.3661 ][Evaluating] 39/81 [=============>................] - ETA: 58s[Evaluating] 40/81 [=============>................] - ETA: 57s  [ loss=0.3414 ][Evaluating] 40/81 [=============>................] - ETA: 57s[Evaluating] 41/81 [==============>...............] - ETA: 55s  [ loss=0.3168 ][Evaluating] 41/81 [==============>...............] - ETA: 55s[Evaluating] 42/81 [==============>...............] - ETA: 54s  [ loss=0.3316 ][Evaluating] 42/81 [==============>...............] - ETA: 54s[Evaluating] 43/81 [==============>...............] - ETA: 53s  [ loss=0.3698 ][Evaluating] 43/81 [==============>...............] - ETA: 53s[Evaluating] 44/81 [===============>..............] - ETA: 52s  [ loss=0.2680 ][Evaluating] 44/81 [===============>..............] - ETA: 52s[Evaluating] 45/81 [===============>..............] - ETA: 50s  [ loss=0.3143 ][Evaluating] 45/81 [===============>..............] - ETA: 50s[Evaluating] 46/81 [================>.............] - ETA: 49s  [ loss=0.3243 ][Evaluating] 46/81 [================>.............] - ETA: 49s[Evaluating] 47/81 [================>.............] - ETA: 48s  [ loss=0.3461 ][Evaluating] 47/81 [================>.............] - ETA: 48s[Evaluating] 48/81 [================>.............] - ETA: 46s  [ loss=0.3681 ][Evaluating] 48/81 [================>.............] - ETA: 46s[Evaluating] 49/81 [=================>............] - ETA: 45s  [ loss=0.3270 ][Evaluating] 49/81 [=================>............] - ETA: 45s[Evaluating] 50/81 [=================>............] - ETA: 44s  [ loss=0.3444 ][Evaluating] 50/81 [=================>............] - ETA: 44s[Evaluating] 51/81 [=================>............] - ETA: 42s  [ loss=0.3800 ][Evaluating] 51/81 [=================>............] - ETA: 42s[Evaluating] 52/81 [==================>...........] - ETA: 41s  [ loss=0.3165 ][Evaluating] 52/81 [==================>...........] - ETA: 41s[Evaluating] 53/81 [==================>...........] - ETA: 39s  [ loss=0.3332 ][Evaluating] 53/81 [==================>...........] - ETA: 39s[Evaluating] 54/81 [===================>..........] - ETA: 38s  [ loss=0.3367 ][Evaluating] 54/81 [===================>..........] - ETA: 38s[Evaluating] 55/81 [===================>..........] - ETA: 36s  [ loss=0.3407 ][Evaluating] 55/81 [===================>..........] - ETA: 36s[Evaluating] 56/81 [===================>..........] - ETA: 35s  [ loss=0.3374 ][Evaluating] 56/81 [===================>..........] - ETA: 35s[Evaluating] 57/81 [====================>.........] - ETA: 34s  [ loss=0.3359 ][Evaluating] 57/81 [====================>.........] - ETA: 34s[Evaluating] 58/81 [====================>.........] - ETA: 32s  [ loss=0.3289 ][Evaluating] 58/81 [====================>.........] - ETA: 32s[Evaluating] 59/81 [====================>.........] - ETA: 31s  [ loss=0.3246 ][Evaluating] 59/81 [====================>.........] - ETA: 31s[Evaluating] 60/81 [=====================>........] - ETA: 29s  [ loss=0.3025 ][Evaluating] 60/81 [=====================>........] - ETA: 29s[Evaluating] 61/81 [=====================>........] - ETA: 28s  [ loss=0.3439 ][Evaluating] 61/81 [=====================>........] - ETA: 28s[Evaluating] 62/81 [=====================>........] - ETA: 27s  [ loss=0.3639 ][Evaluating] 62/81 [=====================>........] - ETA: 27s[Evaluating] 63/81 [======================>.......] - ETA: 25s  [ loss=0.2991 ][Evaluating] 63/81 [======================>.......] - ETA: 25s[Evaluating] 64/81 [======================>.......] - ETA: 24s  [ loss=0.3003 ][Evaluating] 64/81 [======================>.......] - ETA: 24s[Evaluating] 65/81 [=======================>......] - ETA: 22s  [ loss=0.3503 ][Evaluating] 65/81 [=======================>......] - ETA: 22s[Evaluating] 66/81 [=======================>......] - ETA: 21s  [ loss=0.3802 ][Evaluating] 66/81 [=======================>......] - ETA: 21s[Evaluating] 67/81 [=======================>......] - ETA: 19s  [ loss=0.3720 ][Evaluating] 67/81 [=======================>......] - ETA: 19s[Evaluating] 68/81 [========================>.....] - ETA: 18s  [ loss=0.3328 ][Evaluating] 68/81 [========================>.....] - ETA: 18s[Evaluating] 69/81 [========================>.....] - ETA: 17s  [ loss=0.3127 ][Evaluating] 69/81 [========================>.....] - ETA: 17s[Evaluating] 70/81 [========================>.....] - ETA: 15s  [ loss=0.3359 ][Evaluating] 70/81 [========================>.....] - ETA: 15s[Evaluating] 71/81 [=========================>....] - ETA: 14s  [ loss=0.3931 ][Evaluating] 71/81 [=========================>....] - ETA: 14s[Evaluating] 72/81 [=========================>....] - ETA: 12s  [ loss=0.3954 ][Evaluating] 72/81 [=========================>....] - ETA: 12s[Evaluating] 73/81 [==========================>...] - ETA: 11s  [ loss=0.3368 ][Evaluating] 73/81 [==========================>...] - ETA: 11s[Evaluating] 74/81 [==========================>...] - ETA: 10s  [ loss=0.3235 ][Evaluating] 74/81 [==========================>...] - ETA: 10s[Evaluating] 75/81 [==========================>...] - ETA: 8s  [ loss=0.3558 ][Evaluating] 75/81 [==========================>...] - ETA: 8s[Evaluating] 76/81 [===========================>..] - ETA: 7s  [ loss=0.3468 ][Evaluating] 76/81 [===========================>..] - ETA: 7s[Evaluating] 77/81 [===========================>..] - ETA: 5s  [ loss=0.2912 ][Evaluating] 77/81 [===========================>..] - ETA: 5s[Evaluating] 78/81 [===========================>..] - ETA: 4s  [ loss=0.2710 ][Evaluating] 78/81 [===========================>..] - ETA: 4s[Evaluating] 79/81 [============================>.] - ETA: 2s  [ loss=0.3187 ][Evaluating] 79/81 [============================>.] - ETA: 2s[Evaluating] 80/81 [============================>.] - ETA: 1s  [ loss=0.3242 ][Evaluating] 80/81 [============================>.] - ETA: 1s[Evaluating] 81/81 [==============================] 1.4s/step  [ loss=0.3220 ]
[Evaluating] 81/81 [==============================] 1.4s/step
03/21/2023 17:34:05 - INFO - __main__ -   

03/21/2023 17:34:05 - INFO - __main__ -   ***** Eval results test last *****
03/21/2023 17:34:05 - INFO - __main__ -    acc: 0.7346 - recall: 0.7550 - f1: 0.7447 - loss: 0.3359 
03/21/2023 17:34:05 - INFO - __main__ -   ***** Entity results test last *****
03/21/2023 17:34:05 - INFO - __main__ -   ******* LOC results ********
03/21/2023 17:34:05 - INFO - __main__ -    acc: 0.7936 - recall: 0.8718 - f1: 0.8309 
03/21/2023 17:34:05 - INFO - __main__ -   ******* MISC results ********
03/21/2023 17:34:05 - INFO - __main__ -    acc: 0.4010 - recall: 0.3268 - f1: 0.3601 
03/21/2023 17:34:05 - INFO - __main__ -   ******* ORG results ********
03/21/2023 17:34:05 - INFO - __main__ -    acc: 0.6148 - recall: 0.6148 - f1: 0.6148 
03/21/2023 17:34:05 - INFO - __main__ -   ******* PER results ********
03/21/2023 17:34:05 - INFO - __main__ -    acc: 0.8313 - recall: 0.8802 - f1: 0.8551 
